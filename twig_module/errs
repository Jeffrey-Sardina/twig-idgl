With empty_cache

(pyenv) root@6c855b221ba1:/workspace/twig_module# ./twig.py --do_your_job TwigJob.yml > twig_out
/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  dtype=np.int):
/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=np.finfo(np.float).eps,
/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,
/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,
/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=np.finfo(np.float).eps, positive=False):
/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1095: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,
/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1340: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,
/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1476: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=np.finfo(np.float).eps, copy_X=True, positive=False):
/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  precompute=False, eps=np.finfo(np.float).eps,
/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=np.finfo(np.float).eps, random_state=None,
/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=4 * np.finfo(np.float).eps, n_jobs=None,
./twig.py:60: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  config = yaml.load(config_file)
/workspace/NAS_module/sample.py:36: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  self.idgl_conf = yaml.load(conf)
WARNING:hpbandster:job (0, 0, 2) failed with exception
Traceback (most recent call last):
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/workspace/NAS_module/sample.py", line 64, in compute
    res = GNN_run(self.idgl_conf)
  File "/workspace/GNN_module/src/main.py", line 29, in main
    model.train()
  File "/workspace/GNN_module/src/core/model_handler.py", line 156, in train
    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])
  File "/workspace/GNN_module/src/core/model_handler.py", line 904, in _scalable_run_whole_epoch
    cur_node_anchor_adj = network.learn_graph(network.graph_learner2, node_vec, anchor_features=anchor_vec)
  File "/workspace/GNN_module/src/core/models/graph_clf.py", line 90, in learn_graph
    node_anchor_adj = graph_learner(node_features, anchor_features)
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/GNN_module/src/core/layers/scalable_graphlearn.py", line 90, in forward
    attention = torch.matmul(context_norm, anchors_norm.transpose(-1, -2)).mean(0)
RuntimeError: CUDA out of memory. Tried to allocate 374.00 MiB (GPU 0; 12.00 GiB total capacity; 9.46 GiB already allocated; 0 bytes free; 9.51 GiB reserved in total by PyTorch)

WARNING:hpbandster:job (0, 0, 3) failed with exception
Traceback (most recent call last):
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/workspace/NAS_module/sample.py", line 64, in compute
    res = GNN_run(self.idgl_conf)
  File "/workspace/GNN_module/src/main.py", line 29, in main
    model.train()
  File "/workspace/GNN_module/src/core/model_handler.py", line 156, in train
    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])
  File "/workspace/GNN_module/src/core/model_handler.py", line 957, in _scalable_run_whole_epoch
    loss += self.add_graph_loss(cur_anchor_adj, init_anchor_vec)
  File "/workspace/GNN_module/src/core/model_handler.py", line 1116, in add_graph_loss
    L = torch.diagflat(torch.sum(out_adj, -1)) - out_adj
RuntimeError: CUDA out of memory. Tried to allocate 28.00 MiB (GPU 0; 12.00 GiB total capacity; 9.66 GiB already allocated; 0 bytes free; 9.69 GiB reserved in total by PyTorch)

WARNING:hpbandster:job (0, 0, 4) failed with exception
Traceback (most recent call last):
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/workspace/NAS_module/sample.py", line 64, in compute
    res = GNN_run(self.idgl_conf)
  File "/workspace/GNN_module/src/main.py", line 29, in main
    model.train()
  File "/workspace/GNN_module/src/core/model_handler.py", line 156, in train
    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])
  File "/workspace/GNN_module/src/core/model_handler.py", line 930, in _scalable_run_whole_epoch
    mid_first_agg_vecc = encoder(node_vec, first_node_anchor_adj, anchor_mp=True, batch_norm=False)
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/GNN_module/src/core/layers/anchor.py", line 84, in forward
    node_norm = node_anchor_adj / torch.clamp(torch.sum(node_anchor_adj, dim=-2, keepdim=True), min=VERY_SMALL_NUMBER)
RuntimeError: CUDA out of memory. Tried to allocate 58.00 MiB (GPU 0; 12.00 GiB total capacity; 9.47 GiB already allocated; 0 bytes free; 9.68 GiB reserved in total by PyTorch)

WARNING:hpbandster:job (0, 0, 5) failed with exception
Traceback (most recent call last):
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/workspace/NAS_module/sample.py", line 64, in compute
    res = GNN_run(self.idgl_conf)
  File "/workspace/GNN_module/src/main.py", line 29, in main
    model.train()
  File "/workspace/GNN_module/src/core/model_handler.py", line 156, in train
    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])
  File "/workspace/GNN_module/src/core/model_handler.py", line 904, in _scalable_run_whole_epoch
    cur_node_anchor_adj = network.learn_graph(network.graph_learner2, node_vec, anchor_features=anchor_vec)
  File "/workspace/GNN_module/src/core/models/graph_clf.py", line 90, in learn_graph
    node_anchor_adj = graph_learner(node_features, anchor_features)
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/GNN_module/src/core/layers/scalable_graphlearn.py", line 90, in forward
    attention = torch.matmul(context_norm, anchors_norm.transpose(-1, -2)).mean(0)
RuntimeError: CUDA out of memory. Tried to allocate 280.00 MiB (GPU 0; 12.00 GiB total capacity; 9.57 GiB already allocated; 0 bytes free; 9.66 GiB reserved in total by PyTorch)

WARNING:hpbandster:job (0, 0, 6) failed with exception
Traceback (most recent call last):
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/workspace/NAS_module/sample.py", line 64, in compute
    res = GNN_run(self.idgl_conf)
  File "/workspace/GNN_module/src/main.py", line 29, in main
    model.train()
  File "/workspace/GNN_module/src/core/model_handler.py", line 156, in train
    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])
  File "/workspace/GNN_module/src/core/model_handler.py", line 928, in _scalable_run_whole_epoch
    mid_cur_agg_vec = encoder(node_vec, cur_node_anchor_adj, anchor_mp=True, batch_norm=False)
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/GNN_module/src/core/layers/anchor.py", line 85, in forward
    anchor_norm = node_anchor_adj / torch.clamp(torch.sum(node_anchor_adj, dim=-1, keepdim=True), min=VERY_SMALL_NUMBER)
RuntimeError: CUDA out of memory. Tried to allocate 28.00 MiB (GPU 0; 12.00 GiB total capacity; 9.28 GiB already allocated; 0 bytes free; 9.70 GiB reserved in total by PyTorch)

WARNING:hpbandster:job (0, 0, 7) failed with exception
Traceback (most recent call last):
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/workspace/NAS_module/sample.py", line 64, in compute
    res = GNN_run(self.idgl_conf)
  File "/workspace/GNN_module/src/main.py", line 29, in main
    model.train()
  File "/workspace/GNN_module/src/core/model_handler.py", line 156, in train
    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])
  File "/workspace/GNN_module/src/core/model_handler.py", line 928, in _scalable_run_whole_epoch
    mid_cur_agg_vec = encoder(node_vec, cur_node_anchor_adj, anchor_mp=True, batch_norm=False)
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/GNN_module/src/core/layers/anchor.py", line 84, in forward
    node_norm = node_anchor_adj / torch.clamp(torch.sum(node_anchor_adj, dim=-2, keepdim=True), min=VERY_SMALL_NUMBER)
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 12.00 GiB total capacity; 9.69 GiB already allocated; 0 bytes free; 9.71 GiB reserved in total by PyTorch)

WARNING:hpbandster:job (0, 0, 8) failed with exception
Traceback (most recent call last):
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/workspace/NAS_module/sample.py", line 64, in compute
    res = GNN_run(self.idgl_conf)
  File "/workspace/GNN_module/src/main.py", line 29, in main
    model.train()
  File "/workspace/GNN_module/src/core/model_handler.py", line 156, in train
    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])
  File "/workspace/GNN_module/src/core/model_handler.py", line 930, in _scalable_run_whole_epoch
    mid_first_agg_vecc = encoder(node_vec, first_node_anchor_adj, anchor_mp=True, batch_norm=False)
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/GNN_module/src/core/layers/anchor.py", line 84, in forward
    node_norm = node_anchor_adj / torch.clamp(torch.sum(node_anchor_adj, dim=-2, keepdim=True), min=VERY_SMALL_NUMBER)
RuntimeError: CUDA out of memory. Tried to allocate 58.00 MiB (GPU 0; 12.00 GiB total capacity; 9.44 GiB already allocated; 0 bytes free; 9.67 GiB reserved in total by PyTorch)

WARNING:hpbandster:job (0, 0, 9) failed with exception
Traceback (most recent call last):
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/workspace/NAS_module/sample.py", line 64, in compute
    res = GNN_run(self.idgl_conf)
  File "/workspace/GNN_module/src/main.py", line 29, in main
    model.train()
  File "/workspace/GNN_module/src/core/model_handler.py", line 156, in train
    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])
  File "/workspace/GNN_module/src/core/model_handler.py", line 930, in _scalable_run_whole_epoch
    mid_first_agg_vecc = encoder(node_vec, first_node_anchor_adj, anchor_mp=True, batch_norm=False)
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/GNN_module/src/core/layers/anchor.py", line 86, in forward
    output = torch.matmul(anchor_norm, torch.matmul(node_norm.transpose(-1, -2), support))
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.67 GiB already allocated; 0 bytes free; 9.71 GiB reserved in total by PyTorch)

WARNING:hpbandster:job (0, 0, 12) failed with exception
Traceback (most recent call last):
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/workspace/NAS_module/sample.py", line 64, in compute
    res = GNN_run(self.idgl_conf)
  File "/workspace/GNN_module/src/main.py", line 29, in main
    model.train()
  File "/workspace/GNN_module/src/core/model_handler.py", line 156, in train
    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])
  File "/workspace/GNN_module/src/core/model_handler.py", line 904, in _scalable_run_whole_epoch
    cur_node_anchor_adj = network.learn_graph(network.graph_learner2, node_vec, anchor_features=anchor_vec)
  File "/workspace/GNN_module/src/core/models/graph_clf.py", line 90, in learn_graph
    node_anchor_adj = graph_learner(node_features, anchor_features)
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/GNN_module/src/core/layers/scalable_graphlearn.py", line 90, in forward
    attention = torch.matmul(context_norm, anchors_norm.transpose(-1, -2)).mean(0)
RuntimeError: CUDA out of memory. Tried to allocate 188.00 MiB (GPU 0; 12.00 GiB total capacity; 9.19 GiB already allocated; 0 bytes free; 9.60 GiB reserved in total by PyTorch)

WARNING:hpbandster:job (0, 0, 13) failed with exception
Traceback (most recent call last):
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/workspace/NAS_module/sample.py", line 64, in compute
    res = GNN_run(self.idgl_conf)
  File "/workspace/GNN_module/src/main.py", line 29, in main
    model.train()
  File "/workspace/GNN_module/src/core/model_handler.py", line 156, in train
    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])
  File "/workspace/GNN_module/src/core/model_handler.py", line 928, in _scalable_run_whole_epoch
    mid_cur_agg_vec = encoder(node_vec, cur_node_anchor_adj, anchor_mp=True, batch_norm=False)
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/GNN_module/src/core/layers/anchor.py", line 84, in forward
    node_norm = node_anchor_adj / torch.clamp(torch.sum(node_anchor_adj, dim=-2, keepdim=True), min=VERY_SMALL_NUMBER)
RuntimeError: CUDA out of memory. Tried to allocate 58.00 MiB (GPU 0; 12.00 GiB total capacity; 9.64 GiB already allocated; 0 bytes free; 9.67 GiB reserved in total by PyTorch)

WARNING:hpbandster:job (0, 0, 15) failed with exception
Traceback (most recent call last):
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/workspace/NAS_module/sample.py", line 64, in compute
    res = GNN_run(self.idgl_conf)
  File "/workspace/GNN_module/src/main.py", line 29, in main
    model.train()
  File "/workspace/GNN_module/src/core/model_handler.py", line 156, in train
    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])
  File "/workspace/GNN_module/src/core/model_handler.py", line 904, in _scalable_run_whole_epoch
    cur_node_anchor_adj = network.learn_graph(network.graph_learner2, node_vec, anchor_features=anchor_vec)
  File "/workspace/GNN_module/src/core/models/graph_clf.py", line 90, in learn_graph
    node_anchor_adj = graph_learner(node_features, anchor_features)
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/GNN_module/src/core/layers/scalable_graphlearn.py", line 90, in forward
    attention = torch.matmul(context_norm, anchors_norm.transpose(-1, -2)).mean(0)
RuntimeError: CUDA out of memory. Tried to allocate 532.00 MiB (GPU 0; 12.00 GiB total capacity; 9.12 GiB already allocated; 166.38 MiB free; 9.30 GiB reserved in total by PyTorch)

WARNING:hpbandster:job (0, 0, 16) failed with exception
Traceback (most recent call last):
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/workspace/NAS_module/sample.py", line 64, in compute
    res = GNN_run(self.idgl_conf)
  File "/workspace/GNN_module/src/main.py", line 29, in main
    model.train()
  File "/workspace/GNN_module/src/core/model_handler.py", line 156, in train
    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])
  File "/workspace/GNN_module/src/core/model_handler.py", line 904, in _scalable_run_whole_epoch
    cur_node_anchor_adj = network.learn_graph(network.graph_learner2, node_vec, anchor_features=anchor_vec)
  File "/workspace/GNN_module/src/core/models/graph_clf.py", line 90, in learn_graph
    node_anchor_adj = graph_learner(node_features, anchor_features)
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/GNN_module/src/core/layers/scalable_graphlearn.py", line 90, in forward
    attention = torch.matmul(context_norm, anchors_norm.transpose(-1, -2)).mean(0)
RuntimeError: CUDA out of memory. Tried to allocate 28.00 MiB (GPU 0; 12.00 GiB total capacity; 9.68 GiB already allocated; 0 bytes free; 9.71 GiB reserved in total by PyTorch)

WARNING:hpbandster:job (0, 0, 17) failed with exception
Traceback (most recent call last):
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/workspace/NAS_module/sample.py", line 64, in compute
    res = GNN_run(self.idgl_conf)
  File "/workspace/GNN_module/src/main.py", line 29, in main
    model.train()
  File "/workspace/GNN_module/src/core/model_handler.py", line 156, in train
    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])
  File "/workspace/GNN_module/src/core/model_handler.py", line 904, in _scalable_run_whole_epoch
    cur_node_anchor_adj = network.learn_graph(network.graph_learner2, node_vec, anchor_features=anchor_vec)
  File "/workspace/GNN_module/src/core/models/graph_clf.py", line 90, in learn_graph
    node_anchor_adj = graph_learner(node_features, anchor_features)
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/GNN_module/src/core/layers/scalable_graphlearn.py", line 90, in forward
    attention = torch.matmul(context_norm, anchors_norm.transpose(-1, -2)).mean(0)
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 12.00 GiB total capacity; 9.04 GiB already allocated; 128.38 MiB free; 9.34 GiB reserved in total by PyTorch)

WARNING:hpbandster:job (0, 0, 19) failed with exception
Traceback (most recent call last):
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/workspace/NAS_module/sample.py", line 64, in compute
    res = GNN_run(self.idgl_conf)
  File "/workspace/GNN_module/src/main.py", line 29, in main
    model.train()
  File "/workspace/GNN_module/src/core/model_handler.py", line 156, in train
    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])
  File "/workspace/GNN_module/src/core/model_handler.py", line 946, in _scalable_run_whole_epoch
    first_agg_vec = network.encoder.graph_encoders[-1](node_vec, first_node_anchor_adj, anchor_mp=True, batch_norm=False)
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/GNN_module/src/core/layers/anchor.py", line 84, in forward
    node_norm = node_anchor_adj / torch.clamp(torch.sum(node_anchor_adj, dim=-2, keepdim=True), min=VERY_SMALL_NUMBER)
RuntimeError: CUDA out of memory. Tried to allocate 58.00 MiB (GPU 0; 12.00 GiB total capacity; 9.64 GiB already allocated; 0 bytes free; 9.69 GiB reserved in total by PyTorch)

WARNING:hpbandster:job (0, 0, 21) failed with exception
Traceback (most recent call last):
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/workspace/NAS_module/sample.py", line 64, in compute
    res = GNN_run(self.idgl_conf)
  File "/workspace/GNN_module/src/main.py", line 29, in main
    model.train()
  File "/workspace/GNN_module/src/core/model_handler.py", line 156, in train
    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])
  File "/workspace/GNN_module/src/core/model_handler.py", line 928, in _scalable_run_whole_epoch
    mid_cur_agg_vec = encoder(node_vec, cur_node_anchor_adj, anchor_mp=True, batch_norm=False)
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/GNN_module/src/core/layers/anchor.py", line 84, in forward
    node_norm = node_anchor_adj / torch.clamp(torch.sum(node_anchor_adj, dim=-2, keepdim=True), min=VERY_SMALL_NUMBER)
RuntimeError: CUDA out of memory. Tried to allocate 58.00 MiB (GPU 0; 12.00 GiB total capacity; 9.50 GiB already allocated; 0 bytes free; 9.71 GiB reserved in total by PyTorch)

WARNING:hpbandster:job (0, 0, 26) failed with exception
Traceback (most recent call last):
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/workspace/NAS_module/sample.py", line 64, in compute
    res = GNN_run(self.idgl_conf)
  File "/workspace/GNN_module/src/main.py", line 29, in main
    model.train()
  File "/workspace/GNN_module/src/core/model_handler.py", line 156, in train
    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])
  File "/workspace/GNN_module/src/core/model_handler.py", line 930, in _scalable_run_whole_epoch
    mid_first_agg_vecc = encoder(node_vec, first_node_anchor_adj, anchor_mp=True, batch_norm=False)
  File "/root/miniconda3/envs/pyenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/GNN_module/src/core/layers/anchor.py", line 84, in forward
    node_norm = node_anchor_adj / torch.clamp(torch.sum(node_anchor_adj, dim=-2, keepdim=True), min=VERY_SMALL_NUMBER)
RuntimeError: CUDA out of memory. Tried to allocate 58.00 MiB (GPU 0; 12.00 GiB total capacity; 9.36 GiB already allocated; 0 bytes free; 9.71 GiB reserved in total by PyTorch)