Hello, I am Twig. I do my job!
Loading job details...success
Doing my job!
=========================NAS Starting=========================
{'run_id': 'twig_run', 'n_iterations': 1, 'host_addr': '127.0.0.1', 'min_budget': 10, 'max_budget': 300, 'idgl_config_file': '/workspace/GNN_module/src/config/cora/idgl_anchor.yml', 'idgl_working_dir': '/workspace/GNN_module/src/', 'idgl_params': [None], 'hyperparameters': {'learning_rate': {'min': 0, 'max': 10, 'type': 'uniform_float'}, 'weight_decay': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'lr_reduce_factor': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'lr_patience': {'min': 1, 'max': 10, 'type': 'uniform_integer'}, 'grad_accumulated_steps': {'min': 1, 'max': 10, 'type': 'uniform_integer'}, 'dropout': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'feat_adj_dropout': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'gl_dropout': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'num_anchors': {'min': 1, 'max': 10000, 'type': 'uniform_integer'}, 'hidden_size': {'min': 1, 'max': 200, 'type': 'uniform_integer'}, 'graph_skip_conn': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'update_adj_ratio': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'smoothness_ratio': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'degree_ratio': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'sparsity_ratio': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'graph_learn_hidden_size': {'min': 1, 'max': 200, 'type': 'uniform_integer'}, 'graph_learn_num_pers': {'min': 1, 'max': 20, 'type': 'uniform_integer'}, 'graph_hops': {'min': 1, 'max': 10, 'type': 'uniform_integer'}}}
{'min': 0, 'max': 10, 'type': 'uniform_float'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 1, 'max': 10, 'type': 'uniform_integer'}
{'min': 1, 'max': 10, 'type': 'uniform_integer'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 1, 'max': 10000, 'type': 'uniform_integer'}
{'min': 1, 'max': 200, 'type': 'uniform_integer'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 1, 'max': 200, 'type': 'uniform_integer'}
{'min': 1, 'max': 20, 'type': 'uniform_integer'}
{'min': 1, 'max': 10, 'type': 'uniform_integer'}
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5021574766234753
dropout                  -->   0.006553142927941291
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.9735061394020205
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.688440289774325
grad_accumulated_steps   -->   7
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   126
graph_learn_num_pers     -->   7
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.8143332558311542
graph_type               -->   dynamic
hidden_size              -->   143
learning_rate            -->   6.874613410324001
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.5195153434466094
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1972
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5058582403154138
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.5399186746332898
sparsity_ratio           -->   0.7647688642496404
task_type                -->   classification
update_adj_ratio         -->   0.8703382380594397
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8665040616490793
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 143])
encoder.graph_encoders.1.weight: torch.Size([143, 143])
encoder.graph_encoders.2.weight: torch.Size([143, 143])
encoder.graph_encoders.3.weight: torch.Size([143, 143])
encoder.graph_encoders.4.weight: torch.Size([143, 143])
encoder.graph_encoders.5.weight: torch.Size([143, 143])
encoder.graph_encoders.6.weight: torch.Size([143, 143])
encoder.graph_encoders.7.weight: torch.Size([143, 143])
encoder.graph_encoders.8.weight: torch.Size([143, 143])
encoder.graph_encoders.9.weight: torch.Size([143, 7])
graph_learner.weight_tensor: torch.Size([7, 1433])
graph_learner2.weight_tensor: torch.Size([7, 143])
#Parameters = 380544

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.2998642016811621
device                   -->   cuda:0
dropout                  -->   0.9402239342091114
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.9062385321472742
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.9299962171804248
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   196
graph_learn_num_pers     -->   20
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.7722561703826778
graph_type               -->   dynamic
hidden_size              -->   134
learning_rate            -->   9.257351124965583
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.746471341555328
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2281
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.9634580339875866
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.5970898421747965
sparsity_ratio           -->   0.042706155857682115
task_type                -->   classification
update_adj_ratio         -->   0.8209968632711321
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.7730473538036169
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 134])
encoder.graph_encoders.1.weight: torch.Size([134, 134])
encoder.graph_encoders.2.weight: torch.Size([134, 134])
encoder.graph_encoders.3.weight: torch.Size([134, 134])
encoder.graph_encoders.4.weight: torch.Size([134, 134])
encoder.graph_encoders.5.weight: torch.Size([134, 134])
encoder.graph_encoders.6.weight: torch.Size([134, 134])
encoder.graph_encoders.7.weight: torch.Size([134, 134])
encoder.graph_encoders.8.weight: torch.Size([134, 134])
encoder.graph_encoders.9.weight: torch.Size([134, 7])
graph_learner.weight_tensor: torch.Size([20, 1433])
graph_learner2.weight_tensor: torch.Size([20, 134])
#Parameters = 367948

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.813067896413216
device                   -->   cuda:0
dropout                  -->   0.2825490223081203
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6362577661890143
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.9205849503118447
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   167
graph_learn_num_pers     -->   3
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.3822120581366395
graph_type               -->   dynamic
hidden_size              -->   164
learning_rate            -->   3.842670515612011
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.47600632232522044
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2123
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5677012604581888
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.06622142817571808
sparsity_ratio           -->   0.5964539852842743
task_type                -->   classification
update_adj_ratio         -->   0.062113203979307974
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.847926352463851
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 164])
encoder.graph_encoders.1.weight: torch.Size([164, 164])
encoder.graph_encoders.2.weight: torch.Size([164, 7])
graph_learner.weight_tensor: torch.Size([3, 1433])
graph_learner2.weight_tensor: torch.Size([3, 164])
#Parameters = 267847

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 05s <> <> <>
Finished Training: /tmp/iteration_id_0.5677012604581888
Training time: 5.7

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 8; 
NLOSS = -49.72226
ACC = 0.14800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5677012604581888/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5677012604581888/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -50.99374 | ACC = 0.15000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5677012604581888
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.06036513423105805
device                   -->   cuda:0
dropout                  -->   0.14819224241747364
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.29109444215793767
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.24292658924066035
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   3
graph_learn_num_pers     -->   4
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.12758047608507128
graph_type               -->   dynamic
hidden_size              -->   32
learning_rate            -->   8.331600163128327
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.6817712524272681
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   3786
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.12686392584778416
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.11976460298718905
sparsity_ratio           -->   0.3336959391009203
task_type                -->   classification
update_adj_ratio         -->   0.613942378933758
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.7018066762392483
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 4 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 4 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 32])
encoder.graph_encoders.1.weight: torch.Size([32, 32])
encoder.graph_encoders.2.weight: torch.Size([32, 32])
encoder.graph_encoders.3.weight: torch.Size([32, 32])
encoder.graph_encoders.4.weight: torch.Size([32, 32])
encoder.graph_encoders.5.weight: torch.Size([32, 32])
encoder.graph_encoders.6.weight: torch.Size([32, 32])
encoder.graph_encoders.7.weight: torch.Size([32, 32])
encoder.graph_encoders.8.weight: torch.Size([32, 32])
encoder.graph_encoders.9.weight: torch.Size([32, 7])
graph_learner.weight_tensor: torch.Size([4, 1433])
graph_learner2.weight_tensor: torch.Size([4, 32])
#Parameters = 60132

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.8605701274791137
device                   -->   cuda:0
dropout                  -->   0.9577464981368904
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5713299225501838
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.8473196820351415
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   159
graph_learn_num_pers     -->   17
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.9547052395093425
graph_type               -->   dynamic
hidden_size              -->   105
learning_rate            -->   0.5839088653738267
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.4831102013033388
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   729
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.3370411353333468
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.48893025354845043
sparsity_ratio           -->   0.2887803288300883
task_type                -->   classification
update_adj_ratio         -->   0.9571407560945916
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.41766059342878226
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 105])
encoder.graph_encoders.1.weight: torch.Size([105, 105])
encoder.graph_encoders.2.weight: torch.Size([105, 7])
graph_learner.weight_tensor: torch.Size([17, 1433])
graph_learner2.weight_tensor: torch.Size([17, 105])
#Parameters = 188371

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 07s <> <> <>
Finished Training: /tmp/iteration_id_0.3370411353333468
Training time: 7.37

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 6; 
NLOSS = 5.85835
ACC = 0.12000

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.3370411353333468/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.3370411353333468/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 5.83846 | ACC = 0.13500
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.3370411353333468
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.7782056969294642
device                   -->   cuda:0
dropout                  -->   0.8064968340201303
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.666273906552734
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.956736699708112
grad_accumulated_steps   -->   8
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   2
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.109387835917926
graph_type               -->   dynamic
hidden_size              -->   162
learning_rate            -->   2.15737943603614
logging                  -->   True
lr_patience              -->   10
lr_reduce_factor         -->   0.6747886576343612
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   483
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.35020132347747024
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9492237449148977
sparsity_ratio           -->   0.7429109236265068
task_type                -->   classification
update_adj_ratio         -->   0.5418501546851641
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.3214203077463784
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 162])
encoder.graph_encoders.1.weight: torch.Size([162, 162])
encoder.graph_encoders.2.weight: torch.Size([162, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 162])
#Parameters = 272284

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 05s <> <> <>
Finished Training: /tmp/iteration_id_0.35020132347747024
Training time: 5.26

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 8; 
NLOSS = -30.00023
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.35020132347747024/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.35020132347747024/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -29.83200 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.35020132347747024
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5274779784450757
device                   -->   cuda:0
dropout                  -->   0.6597538865147813
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.8642887054558677
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.9074099522771308
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   88
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.44199615458144603
graph_type               -->   dynamic
hidden_size              -->   72
learning_rate            -->   1.6190970023686968
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.3075268718066232
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   677
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.26033360045154075
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.3039264723316232
sparsity_ratio           -->   0.2892896940366373
task_type                -->   classification
update_adj_ratio         -->   0.02234331296871761
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9474927893709519
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 72])
encoder.graph_encoders.1.weight: torch.Size([72, 72])
encoder.graph_encoders.2.weight: torch.Size([72, 72])
encoder.graph_encoders.3.weight: torch.Size([72, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 72])
#Parameters = 126088

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 05s <> <> <>
Finished Training: /tmp/iteration_id_0.26033360045154075
Training time: 5.71

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 8; 
NLOSS = -1.13607
ACC = 0.11600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.26033360045154075/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.26033360045154075/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -1.14021 | ACC = 0.10300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.26033360045154075
Testing time: 0.07
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.24753626378880045
device                   -->   cuda:0
dropout                  -->   0.5165930891403899
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.07923904626323874
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.443413496138644
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   187
graph_learn_num_pers     -->   18
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.7922549704258502
graph_type               -->   dynamic
hidden_size              -->   191
learning_rate            -->   3.267684129973282
logging                  -->   True
lr_patience              -->   10
lr_reduce_factor         -->   0.2720606768907542
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5394
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.08026010265514105
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.4593689088704983
sparsity_ratio           -->   0.8224321852068573
task_type                -->   classification
update_adj_ratio         -->   0.34546187131525274
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6282752967378221
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 191])
encoder.graph_encoders.1.weight: torch.Size([191, 191])
encoder.graph_encoders.2.weight: torch.Size([191, 191])
encoder.graph_encoders.3.weight: torch.Size([191, 191])
encoder.graph_encoders.4.weight: torch.Size([191, 191])
encoder.graph_encoders.5.weight: torch.Size([191, 191])
encoder.graph_encoders.6.weight: torch.Size([191, 191])
encoder.graph_encoders.7.weight: torch.Size([191, 191])
encoder.graph_encoders.8.weight: torch.Size([191, 191])
encoder.graph_encoders.9.weight: torch.Size([191, 7])
graph_learner.weight_tensor: torch.Size([18, 1433])
graph_learner2.weight_tensor: torch.Size([18, 191])
#Parameters = 596120

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.53728965559878
device                   -->   cuda:0
dropout                  -->   0.8559240528992826
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.736061838303256
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.875098399047153
grad_accumulated_steps   -->   7
grad_clipping            -->   None
graph_hops               -->   7
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   114
graph_learn_num_pers     -->   3
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.4247279132666604
graph_type               -->   dynamic
hidden_size              -->   150
learning_rate            -->   2.7000568684643866
logging                  -->   True
lr_patience              -->   7
lr_reduce_factor         -->   0.18345563936548903
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   9558
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.3498314627553514
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.2909737199960881
sparsity_ratio           -->   0.6762077787790302
task_type                -->   classification
update_adj_ratio         -->   0.5677773402057337
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.39626608494111293
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 150])
encoder.graph_encoders.1.weight: torch.Size([150, 150])
encoder.graph_encoders.2.weight: torch.Size([150, 150])
encoder.graph_encoders.3.weight: torch.Size([150, 150])
encoder.graph_encoders.4.weight: torch.Size([150, 150])
encoder.graph_encoders.5.weight: torch.Size([150, 150])
encoder.graph_encoders.6.weight: torch.Size([150, 7])
graph_learner.weight_tensor: torch.Size([3, 1433])
graph_learner2.weight_tensor: torch.Size([3, 150])
#Parameters = 333249

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9143882041481333
device                   -->   cuda:0
dropout                  -->   0.08557555527241323
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.8176718706261453
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.9413968942290499
grad_accumulated_steps   -->   1
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   112
graph_learn_num_pers     -->   6
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5538553971677503
graph_type               -->   dynamic
hidden_size              -->   120
learning_rate            -->   4.70167828178622
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.6878026619642127
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8303
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.09847858365633222
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.10927344829890073
sparsity_ratio           -->   0.6677491093312355
task_type                -->   classification
update_adj_ratio         -->   0.4892639268932072
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.7346478609513294
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 6 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 6 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 120])
encoder.graph_encoders.1.weight: torch.Size([120, 120])
encoder.graph_encoders.2.weight: torch.Size([120, 120])
encoder.graph_encoders.3.weight: torch.Size([120, 120])
encoder.graph_encoders.4.weight: torch.Size([120, 120])
encoder.graph_encoders.5.weight: torch.Size([120, 120])
encoder.graph_encoders.6.weight: torch.Size([120, 120])
encoder.graph_encoders.7.weight: torch.Size([120, 120])
encoder.graph_encoders.8.weight: torch.Size([120, 120])
encoder.graph_encoders.9.weight: torch.Size([120, 7])
graph_learner.weight_tensor: torch.Size([6, 1433])
graph_learner2.weight_tensor: torch.Size([6, 120])
#Parameters = 297318

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.01891490411739072
device                   -->   cuda:0
dropout                  -->   0.03078696664305769
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.677317245129987
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.11053532486062012
grad_accumulated_steps   -->   7
grad_clipping            -->   None
graph_hops               -->   6
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   139
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5866150842157037
graph_type               -->   dynamic
hidden_size              -->   165
learning_rate            -->   5.03423656754689
logging                  -->   True
lr_patience              -->   7
lr_reduce_factor         -->   0.017878236335091335
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   3050
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.42671753512756183
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7930696802202851
sparsity_ratio           -->   0.17048504163615552
task_type                -->   classification
update_adj_ratio         -->   0.19370585049343758
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.22966401520642632
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 165])
encoder.graph_encoders.1.weight: torch.Size([165, 165])
encoder.graph_encoders.2.weight: torch.Size([165, 165])
encoder.graph_encoders.3.weight: torch.Size([165, 165])
encoder.graph_encoders.4.weight: torch.Size([165, 165])
encoder.graph_encoders.5.weight: torch.Size([165, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 165])
#Parameters = 359284

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.1406067641418839
device                   -->   cuda:0
dropout                  -->   0.7819146956334297
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.16779916120259486
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7154963373756383
grad_accumulated_steps   -->   10
grad_clipping            -->   None
graph_hops               -->   7
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   55
graph_learn_num_pers     -->   11
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.14117386605388837
graph_type               -->   dynamic
hidden_size              -->   93
learning_rate            -->   0.1250181289138319
logging                  -->   True
lr_patience              -->   9
lr_reduce_factor         -->   0.7208619389082667
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   9527
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.4071812629187842
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.08421948515514743
sparsity_ratio           -->   0.9835458538767784
task_type                -->   classification
update_adj_ratio         -->   0.09351763794988133
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8276675202936774
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 93])
encoder.graph_encoders.1.weight: torch.Size([93, 93])
encoder.graph_encoders.2.weight: torch.Size([93, 93])
encoder.graph_encoders.3.weight: torch.Size([93, 93])
encoder.graph_encoders.4.weight: torch.Size([93, 93])
encoder.graph_encoders.5.weight: torch.Size([93, 93])
encoder.graph_encoders.6.weight: torch.Size([93, 7])
graph_learner.weight_tensor: torch.Size([11, 1433])
graph_learner2.weight_tensor: torch.Size([11, 93])
#Parameters = 193951

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.075927543019634
device                   -->   cuda:0
dropout                  -->   0.7400026778680937
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5168877078997639
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.10212678502426042
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   5
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   113
graph_learn_num_pers     -->   2
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.23931646515369853
graph_type               -->   dynamic
hidden_size              -->   41
learning_rate            -->   0.8532347071309188
logging                  -->   True
lr_patience              -->   3
lr_reduce_factor         -->   0.11323486953308826
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8118
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6861661344303657
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.4139235743913928
sparsity_ratio           -->   0.7127723925675254
task_type                -->   classification
update_adj_ratio         -->   0.49966829860804474
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8207588441976487
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 41])
encoder.graph_encoders.1.weight: torch.Size([41, 41])
encoder.graph_encoders.2.weight: torch.Size([41, 41])
encoder.graph_encoders.3.weight: torch.Size([41, 41])
encoder.graph_encoders.4.weight: torch.Size([41, 7])
graph_learner.weight_tensor: torch.Size([2, 1433])
graph_learner2.weight_tensor: torch.Size([2, 41])
#Parameters = 67031

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 08s <> <> <>
Finished Training: /tmp/iteration_id_0.6861661344303657
Training time: 8.36

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 9; 
NLOSS = -3.56138
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6861661344303657/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6861661344303657/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -3.55910 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6861661344303657
Testing time: 0.13
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.28465471740555925
device                   -->   cuda:0
dropout                  -->   0.9152255212939466
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.14919551109489582
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.9657858742152438
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   69
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.10802350683090656
graph_type               -->   dynamic
hidden_size              -->   14
learning_rate            -->   6.867054487848263
logging                  -->   True
lr_patience              -->   8
lr_reduce_factor         -->   0.5229417629888682
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2140
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.2764990009190583
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.15094403124989675
sparsity_ratio           -->   0.7380232561254664
task_type                -->   classification
update_adj_ratio         -->   0.30371135815490935
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5167998592593814
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 14])
encoder.graph_encoders.1.weight: torch.Size([14, 14])
encoder.graph_encoders.2.weight: torch.Size([14, 14])
encoder.graph_encoders.3.weight: torch.Size([14, 14])
encoder.graph_encoders.4.weight: torch.Size([14, 14])
encoder.graph_encoders.5.weight: torch.Size([14, 14])
encoder.graph_encoders.6.weight: torch.Size([14, 14])
encoder.graph_encoders.7.weight: torch.Size([14, 14])
encoder.graph_encoders.8.weight: torch.Size([14, 14])
encoder.graph_encoders.9.weight: torch.Size([14, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 14])
#Parameters = 33304

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5311747883892582
device                   -->   cuda:0
dropout                  -->   0.6039587458399325
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.038414329537392544
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.2874404882602074
grad_accumulated_steps   -->   3
grad_clipping            -->   None
graph_hops               -->   5
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   95
graph_learn_num_pers     -->   17
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.08895898096047317
graph_type               -->   dynamic
hidden_size              -->   68
learning_rate            -->   0.881841198980915
logging                  -->   True
lr_patience              -->   7
lr_reduce_factor         -->   0.5104635246277287
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   7056
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8988318068405131
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.3090025127374044
sparsity_ratio           -->   0.5925197232704903
task_type                -->   classification
update_adj_ratio         -->   0.9336502826980537
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.677571027339874
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 68])
encoder.graph_encoders.1.weight: torch.Size([68, 68])
encoder.graph_encoders.2.weight: torch.Size([68, 68])
encoder.graph_encoders.3.weight: torch.Size([68, 68])
encoder.graph_encoders.4.weight: torch.Size([68, 7])
graph_learner.weight_tensor: torch.Size([17, 1433])
graph_learner2.weight_tensor: torch.Size([17, 68])
#Parameters = 137309

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5397323756733847
device                   -->   cuda:0
dropout                  -->   0.05725889976388843
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.4754680436931893
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.4974547318097142
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   14
graph_learn_num_pers     -->   10
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.3506586859920844
graph_type               -->   dynamic
hidden_size              -->   57
learning_rate            -->   1.8928455607350947
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.5794992170194675
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2450
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.06875993785931256
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.6186600248900239
sparsity_ratio           -->   0.5783822996245557
task_type                -->   classification
update_adj_ratio         -->   0.5762570448244836
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9231537782065852
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 10 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 10 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 57])
encoder.graph_encoders.1.weight: torch.Size([57, 57])
encoder.graph_encoders.2.weight: torch.Size([57, 57])
encoder.graph_encoders.3.weight: torch.Size([57, 57])
encoder.graph_encoders.4.weight: torch.Size([57, 57])
encoder.graph_encoders.5.weight: torch.Size([57, 57])
encoder.graph_encoders.6.weight: torch.Size([57, 57])
encoder.graph_encoders.7.weight: torch.Size([57, 57])
encoder.graph_encoders.8.weight: torch.Size([57, 57])
encoder.graph_encoders.9.weight: torch.Size([57, 7])
graph_learner.weight_tensor: torch.Size([10, 1433])
graph_learner2.weight_tensor: torch.Size([10, 57])
#Parameters = 122972

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.7901723948118722
device                   -->   cuda:0
dropout                  -->   0.8694388402768332
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.19933446981752823
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.24365437699593495
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   13
graph_learn_num_pers     -->   4
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.9272620598531074
graph_type               -->   dynamic
hidden_size              -->   161
learning_rate            -->   4.2272626997420035
logging                  -->   True
lr_patience              -->   7
lr_reduce_factor         -->   0.8190368508576114
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8665
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.3243082147887715
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9717172571301924
sparsity_ratio           -->   0.10348127623012515
task_type                -->   classification
update_adj_ratio         -->   0.43575234762549164
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.7300104530081679
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 4 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 4 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 161])
encoder.graph_encoders.1.weight: torch.Size([161, 161])
encoder.graph_encoders.2.weight: torch.Size([161, 161])
encoder.graph_encoders.3.weight: torch.Size([161, 161])
encoder.graph_encoders.4.weight: torch.Size([161, 161])
encoder.graph_encoders.5.weight: torch.Size([161, 161])
encoder.graph_encoders.6.weight: torch.Size([161, 161])
encoder.graph_encoders.7.weight: torch.Size([161, 161])
encoder.graph_encoders.8.weight: torch.Size([161, 161])
encoder.graph_encoders.9.weight: torch.Size([161, 7])
graph_learner.weight_tensor: torch.Size([4, 1433])
graph_learner2.weight_tensor: torch.Size([4, 161])
#Parameters = 445584

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.09373487248301737
device                   -->   cuda:0
dropout                  -->   0.8322761251952858
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5857277077049853
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.09377307482200592
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   9
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   143
graph_learn_num_pers     -->   4
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.597293759037425
graph_type               -->   dynamic
hidden_size              -->   60
learning_rate            -->   9.566960008888369
logging                  -->   True
lr_patience              -->   8
lr_reduce_factor         -->   0.5886456020509461
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5561
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.18559129012844355
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9631667420214713
sparsity_ratio           -->   0.8030205537493112
task_type                -->   classification
update_adj_ratio         -->   0.604303637264152
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.4407292082134081
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 4 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 4 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 60])
encoder.graph_encoders.1.weight: torch.Size([60, 60])
encoder.graph_encoders.2.weight: torch.Size([60, 60])
encoder.graph_encoders.3.weight: torch.Size([60, 60])
encoder.graph_encoders.4.weight: torch.Size([60, 60])
encoder.graph_encoders.5.weight: torch.Size([60, 60])
encoder.graph_encoders.6.weight: torch.Size([60, 60])
encoder.graph_encoders.7.weight: torch.Size([60, 60])
encoder.graph_encoders.8.weight: torch.Size([60, 7])
graph_learner.weight_tensor: torch.Size([4, 1433])
graph_learner2.weight_tensor: torch.Size([4, 60])
#Parameters = 117572

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.07466695411514379
device                   -->   cuda:0
dropout                  -->   0.6890576850685863
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5527340840901123
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7758488367707436
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   38
graph_learn_num_pers     -->   2
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.05337804893542741
graph_type               -->   dynamic
hidden_size              -->   37
learning_rate            -->   7.400039053017739
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.7021469496896097
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   20
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5084857098354008
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.5033730078922876
sparsity_ratio           -->   0.5334922484364069
task_type                -->   classification
update_adj_ratio         -->   0.11514790368133943
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9305467893384739
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 37])
encoder.graph_encoders.1.weight: torch.Size([37, 37])
encoder.graph_encoders.2.weight: torch.Size([37, 37])
encoder.graph_encoders.3.weight: torch.Size([37, 37])
encoder.graph_encoders.4.weight: torch.Size([37, 37])
encoder.graph_encoders.5.weight: torch.Size([37, 37])
encoder.graph_encoders.6.weight: torch.Size([37, 37])
encoder.graph_encoders.7.weight: torch.Size([37, 37])
encoder.graph_encoders.8.weight: torch.Size([37, 37])
encoder.graph_encoders.9.weight: torch.Size([37, 7])
graph_learner.weight_tensor: torch.Size([2, 1433])
graph_learner2.weight_tensor: torch.Size([2, 37])
#Parameters = 67172

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 13s <> <> <>
Finished Training: /tmp/iteration_id_0.5084857098354008
Training time: 13.0

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 9; 
NLOSS = -30.01294
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5084857098354008/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5084857098354008/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -34.78688 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5084857098354008
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.6799451758942243
device                   -->   cuda:0
dropout                  -->   0.2698153794841702
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5369379085200391
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7210220625875873
grad_accumulated_steps   -->   7
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   81
graph_learn_num_pers     -->   3
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.14468883259325338
graph_type               -->   dynamic
hidden_size              -->   69
learning_rate            -->   4.79959516857738
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.8948434918529536
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8258
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.2742474613040641
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.22325023593545334
sparsity_ratio           -->   0.8464561487593576
task_type                -->   classification
update_adj_ratio         -->   0.0866594564911306
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.21996753864012475
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 69])
encoder.graph_encoders.1.weight: torch.Size([69, 69])
encoder.graph_encoders.2.weight: torch.Size([69, 69])
encoder.graph_encoders.3.weight: torch.Size([69, 7])
graph_learner.weight_tensor: torch.Size([3, 1433])
graph_learner2.weight_tensor: torch.Size([3, 69])
#Parameters = 113388

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 08s <> <> <>
Finished Training: /tmp/iteration_id_0.2742474613040641
Training time: 8.74

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 4.07032
ACC = 0.16200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.2742474613040641/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.2742474613040641/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 4.06325 | ACC = 0.14900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.2742474613040641
Testing time: 0.15
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.89903342711496
device                   -->   cuda:0
dropout                  -->   0.34139578240112844
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.17346514121846512
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.0674868710996066
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   67
graph_learn_num_pers     -->   2
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.9384253618795008
graph_type               -->   dynamic
hidden_size              -->   182
learning_rate            -->   8.48824930201235
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.631018094286951
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5179
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.2514612548163391
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.23494318055371688
sparsity_ratio           -->   0.8772764235660406
task_type                -->   classification
update_adj_ratio         -->   0.5602131072195287
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.08826414036027119
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 182])
encoder.graph_encoders.1.weight: torch.Size([182, 182])
encoder.graph_encoders.2.weight: torch.Size([182, 182])
encoder.graph_encoders.3.weight: torch.Size([182, 182])
encoder.graph_encoders.4.weight: torch.Size([182, 182])
encoder.graph_encoders.5.weight: torch.Size([182, 182])
encoder.graph_encoders.6.weight: torch.Size([182, 182])
encoder.graph_encoders.7.weight: torch.Size([182, 182])
encoder.graph_encoders.8.weight: torch.Size([182, 182])
encoder.graph_encoders.9.weight: torch.Size([182, 7])
graph_learner.weight_tensor: torch.Size([2, 1433])
graph_learner2.weight_tensor: torch.Size([2, 182])
#Parameters = 530302

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.274459009994124
device                   -->   cuda:0
dropout                  -->   0.7616167570584819
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.43668167021592086
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.13635962780053357
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   8
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   81
graph_learn_num_pers     -->   5
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.697804801247715
graph_type               -->   dynamic
hidden_size              -->   133
learning_rate            -->   9.863460336064165
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.44068150526242433
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1399
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.500735453197863
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.25444040594505646
sparsity_ratio           -->   0.04639587514964216
task_type                -->   classification
update_adj_ratio         -->   0.7654252331082501
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5917189067734359
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 5 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 5 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 133])
encoder.graph_encoders.1.weight: torch.Size([133, 133])
encoder.graph_encoders.2.weight: torch.Size([133, 133])
encoder.graph_encoders.3.weight: torch.Size([133, 133])
encoder.graph_encoders.4.weight: torch.Size([133, 133])
encoder.graph_encoders.5.weight: torch.Size([133, 133])
encoder.graph_encoders.6.weight: torch.Size([133, 133])
encoder.graph_encoders.7.weight: torch.Size([133, 7])
graph_learner.weight_tensor: torch.Size([5, 1433])
graph_learner2.weight_tensor: torch.Size([5, 133])
#Parameters = 305484

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.4771543170065844
device                   -->   cuda:0
dropout                  -->   0.5759203733487794
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7733807066023556
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7433776904293891
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   5
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   59
graph_learn_num_pers     -->   18
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.09300495695740418
graph_type               -->   dynamic
hidden_size              -->   134
learning_rate            -->   9.382010984328668
logging                  -->   True
lr_patience              -->   9
lr_reduce_factor         -->   0.3702118303867008
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   3989
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5580727208051496
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.43027155207256196
sparsity_ratio           -->   0.5648737452479584
task_type                -->   classification
update_adj_ratio         -->   0.8473161761871855
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5207735517136444
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 134])
encoder.graph_encoders.1.weight: torch.Size([134, 134])
encoder.graph_encoders.2.weight: torch.Size([134, 134])
encoder.graph_encoders.3.weight: torch.Size([134, 134])
encoder.graph_encoders.4.weight: torch.Size([134, 7])
graph_learner.weight_tensor: torch.Size([18, 1433])
graph_learner2.weight_tensor: torch.Size([18, 134])
#Parameters = 275034

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5213627528365847
device                   -->   cuda:0
dropout                  -->   0.36929037628033035
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6396077813799248
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.8692410802925256
grad_accumulated_steps   -->   9
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   52
graph_learn_num_pers     -->   12
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.3268419006720271
graph_type               -->   dynamic
hidden_size              -->   161
learning_rate            -->   9.728892851621675
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.32456667768444714
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8942
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6074845555694708
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.3205361795644537
sparsity_ratio           -->   0.39457897368920547
task_type                -->   classification
update_adj_ratio         -->   0.5154461753655715
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.480951499896621
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 12 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 12 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 161])
encoder.graph_encoders.1.weight: torch.Size([161, 7])
graph_learner.weight_tensor: torch.Size([12, 1433])
graph_learner2.weight_tensor: torch.Size([12, 161])
#Parameters = 250968

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 06s <> <> <>
Finished Training: /tmp/iteration_id_0.6074845555694708
Training time: 6.72

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 0.34735
ACC = 0.16200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6074845555694708/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 12 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 12 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6074845555694708/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.32333 | ACC = 0.15000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6074845555694708
Testing time: 0.14
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5105082763750957
device                   -->   cuda:0
dropout                  -->   0.6400966300172225
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.2669563727438301
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6174727831028325
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   9
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   182
graph_learn_num_pers     -->   20
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.32220616600445595
graph_type               -->   dynamic
hidden_size              -->   47
learning_rate            -->   0.9139683057407733
logging                  -->   True
lr_patience              -->   3
lr_reduce_factor         -->   0.22200064558074428
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   6448
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.3255198376220656
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.8205832338800992
sparsity_ratio           -->   0.46645796083187485
task_type                -->   classification
update_adj_ratio         -->   0.04295039756861285
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.39590112661930654
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 47])
encoder.graph_encoders.1.weight: torch.Size([47, 47])
encoder.graph_encoders.2.weight: torch.Size([47, 47])
encoder.graph_encoders.3.weight: torch.Size([47, 47])
encoder.graph_encoders.4.weight: torch.Size([47, 47])
encoder.graph_encoders.5.weight: torch.Size([47, 47])
encoder.graph_encoders.6.weight: torch.Size([47, 47])
encoder.graph_encoders.7.weight: torch.Size([47, 47])
encoder.graph_encoders.8.weight: torch.Size([47, 7])
graph_learner.weight_tensor: torch.Size([20, 1433])
graph_learner2.weight_tensor: torch.Size([20, 47])
#Parameters = 112743

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.27943340989153964
device                   -->   cuda:0
dropout                  -->   0.6393180865790568
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.21746696970721724
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.4414120642567686
grad_accumulated_steps   -->   8
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   95
graph_learn_num_pers     -->   16
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6049814187123257
graph_type               -->   dynamic
hidden_size              -->   1
learning_rate            -->   9.218169674887378
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.9523408161085126
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1967
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.2631584952830167
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.6092679565612814
sparsity_ratio           -->   0.045711737111537865
task_type                -->   classification
update_adj_ratio         -->   0.37011911054442626
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.08524617876748297
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 1])
encoder.graph_encoders.1.weight: torch.Size([1, 1])
encoder.graph_encoders.2.weight: torch.Size([1, 1])
encoder.graph_encoders.3.weight: torch.Size([1, 1])
encoder.graph_encoders.4.weight: torch.Size([1, 1])
encoder.graph_encoders.5.weight: torch.Size([1, 1])
encoder.graph_encoders.6.weight: torch.Size([1, 1])
encoder.graph_encoders.7.weight: torch.Size([1, 1])
encoder.graph_encoders.8.weight: torch.Size([1, 1])
encoder.graph_encoders.9.weight: torch.Size([1, 7])
graph_learner.weight_tensor: torch.Size([16, 1433])
graph_learner2.weight_tensor: torch.Size([16, 1])
#Parameters = 24392

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 05s <> <> <>
Finished Training: /tmp/iteration_id_0.2631584952830167
Training time: 5.39

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = -10.17337
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.2631584952830167/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.2631584952830167/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -10.17634 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.2631584952830167
Testing time: 0.14
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.935953822193219
device                   -->   cuda:0
dropout                  -->   0.2026495814961452
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6566561476638892
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.24404678317605732
grad_accumulated_steps   -->   1
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   40
graph_learn_num_pers     -->   2
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.8435648515262533
graph_type               -->   dynamic
hidden_size              -->   169
learning_rate            -->   8.234641638217767
logging                  -->   True
lr_patience              -->   7
lr_reduce_factor         -->   0.42044768864476123
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   6236
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.03126725517175888
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.23428137000972982
sparsity_ratio           -->   0.21221990179795824
task_type                -->   classification
update_adj_ratio         -->   0.32621222983932885
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.05986913931803395
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 169])
encoder.graph_encoders.1.weight: torch.Size([169, 7])
graph_learner.weight_tensor: torch.Size([2, 1433])
graph_learner2.weight_tensor: torch.Size([2, 169])
#Parameters = 246564

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 05s <> <> <>
Finished Training: /tmp/iteration_id_0.03126725517175888
Training time: 5.51

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 6; 
NLOSS = -0.00211
ACC = 0.10000

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.03126725517175888/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.03126725517175888/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -0.37813 | ACC = 0.10000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.03126725517175888
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.813067896413216
device                   -->   cuda:0
dropout                  -->   0.2825490223081203
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6362577661890143
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.9205849503118447
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   167
graph_learn_num_pers     -->   3
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.3822120581366395
graph_type               -->   dynamic
hidden_size              -->   164
learning_rate            -->   3.842670515612011
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.47600632232522044
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2123
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.014655061703990113
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.06622142817571808
sparsity_ratio           -->   0.5964539852842743
task_type                -->   classification
update_adj_ratio         -->   0.062113203979307974
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.847926352463851
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 164])
encoder.graph_encoders.1.weight: torch.Size([164, 164])
encoder.graph_encoders.2.weight: torch.Size([164, 7])
graph_learner.weight_tensor: torch.Size([3, 1433])
graph_learner2.weight_tensor: torch.Size([3, 164])
#Parameters = 267847

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 15s <> <> <>
Finished Training: /tmp/iteration_id_0.014655061703990113
Training time: 15.44

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 26; 
NLOSS = 1.13829
ACC = 0.17000

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.014655061703990113/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.014655061703990113/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.22582 | ACC = 0.15700
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.014655061703990113
Testing time: 0.09
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.8605701274791137
device                   -->   cuda:0
dropout                  -->   0.9577464981368904
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5713299225501838
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.8473196820351415
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   159
graph_learn_num_pers     -->   17
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.9547052395093425
graph_type               -->   dynamic
hidden_size              -->   105
learning_rate            -->   0.5839088653738267
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.4831102013033388
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   729
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5224434440142789
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.48893025354845043
sparsity_ratio           -->   0.2887803288300883
task_type                -->   classification
update_adj_ratio         -->   0.9571407560945916
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.41766059342878226
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 105])
encoder.graph_encoders.1.weight: torch.Size([105, 105])
encoder.graph_encoders.2.weight: torch.Size([105, 7])
graph_learner.weight_tensor: torch.Size([17, 1433])
graph_learner2.weight_tensor: torch.Size([17, 105])
#Parameters = 188371

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 16s <> <> <>
Finished Training: /tmp/iteration_id_0.5224434440142789
Training time: 16.03

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 6; 
NLOSS = 5.85835
ACC = 0.12000

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5224434440142789/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5224434440142789/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 5.87347 | ACC = 0.13500
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5224434440142789
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.7782056969294642
device                   -->   cuda:0
dropout                  -->   0.8064968340201303
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.666273906552734
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.956736699708112
grad_accumulated_steps   -->   8
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   2
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.109387835917926
graph_type               -->   dynamic
hidden_size              -->   162
learning_rate            -->   2.15737943603614
logging                  -->   True
lr_patience              -->   10
lr_reduce_factor         -->   0.6747886576343612
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   483
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.3624627512416425
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9492237449148977
sparsity_ratio           -->   0.7429109236265068
task_type                -->   classification
update_adj_ratio         -->   0.5418501546851641
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.3214203077463784
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 162])
encoder.graph_encoders.1.weight: torch.Size([162, 162])
encoder.graph_encoders.2.weight: torch.Size([162, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 162])
#Parameters = 272284

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 14s <> <> <>
Finished Training: /tmp/iteration_id_0.3624627512416425
Training time: 14.19

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 31; 
NLOSS = -18.57973
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.3624627512416425/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.3624627512416425/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -18.53409 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.3624627512416425
Testing time: 0.08
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5274779784450757
device                   -->   cuda:0
dropout                  -->   0.6597538865147813
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.8642887054558677
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.9074099522771308
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   88
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.44199615458144603
graph_type               -->   dynamic
hidden_size              -->   72
learning_rate            -->   1.6190970023686968
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.3075268718066232
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   677
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.03365287365749481
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.3039264723316232
sparsity_ratio           -->   0.2892896940366373
task_type                -->   classification
update_adj_ratio         -->   0.02234331296871761
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9474927893709519
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 72])
encoder.graph_encoders.1.weight: torch.Size([72, 72])
encoder.graph_encoders.2.weight: torch.Size([72, 72])
encoder.graph_encoders.3.weight: torch.Size([72, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 72])
#Parameters = 126088

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 18s <> <> <>
Finished Training: /tmp/iteration_id_0.03365287365749481
Training time: 18.56

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 8; 
NLOSS = -1.13607
ACC = 0.11600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.03365287365749481/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.03365287365749481/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -1.15041 | ACC = 0.10300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.03365287365749481
Testing time: 0.08
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.07466695411514379
device                   -->   cuda:0
dropout                  -->   0.6890576850685863
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5527340840901123
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7758488367707436
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   38
graph_learn_num_pers     -->   2
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.05337804893542741
graph_type               -->   dynamic
hidden_size              -->   37
learning_rate            -->   7.400039053017739
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.7021469496896097
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   20
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.09473845564096417
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.5033730078922876
sparsity_ratio           -->   0.5334922484364069
task_type                -->   classification
update_adj_ratio         -->   0.11514790368133943
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9305467893384739
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 37])
encoder.graph_encoders.1.weight: torch.Size([37, 37])
encoder.graph_encoders.2.weight: torch.Size([37, 37])
encoder.graph_encoders.3.weight: torch.Size([37, 37])
encoder.graph_encoders.4.weight: torch.Size([37, 37])
encoder.graph_encoders.5.weight: torch.Size([37, 37])
encoder.graph_encoders.6.weight: torch.Size([37, 37])
encoder.graph_encoders.7.weight: torch.Size([37, 37])
encoder.graph_encoders.8.weight: torch.Size([37, 37])
encoder.graph_encoders.9.weight: torch.Size([37, 7])
graph_learner.weight_tensor: torch.Size([2, 1433])
graph_learner2.weight_tensor: torch.Size([2, 37])
#Parameters = 67172

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 23s <> <> <>
Finished Training: /tmp/iteration_id_0.09473845564096417
Training time: 23.72

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 13; 
NLOSS = -28.69949
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.09473845564096417/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.09473845564096417/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -34.07756 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.09473845564096417
Testing time: 0.14
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.6799451758942243
device                   -->   cuda:0
dropout                  -->   0.2698153794841702
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5369379085200391
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7210220625875873
grad_accumulated_steps   -->   7
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   81
graph_learn_num_pers     -->   3
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.14468883259325338
graph_type               -->   dynamic
hidden_size              -->   69
learning_rate            -->   4.79959516857738
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.8948434918529536
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8258
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5038360083051661
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.22325023593545334
sparsity_ratio           -->   0.8464561487593576
task_type                -->   classification
update_adj_ratio         -->   0.0866594564911306
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.21996753864012475
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 69])
encoder.graph_encoders.1.weight: torch.Size([69, 69])
encoder.graph_encoders.2.weight: torch.Size([69, 69])
encoder.graph_encoders.3.weight: torch.Size([69, 7])
graph_learner.weight_tensor: torch.Size([3, 1433])
graph_learner2.weight_tensor: torch.Size([3, 69])
#Parameters = 113388

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5213627528365847
device                   -->   cuda:0
dropout                  -->   0.36929037628033035
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6396077813799248
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.8692410802925256
grad_accumulated_steps   -->   9
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   52
graph_learn_num_pers     -->   12
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.3268419006720271
graph_type               -->   dynamic
hidden_size              -->   161
learning_rate            -->   9.728892851621675
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.32456667768444714
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8942
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.14274921763839532
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.3205361795644537
sparsity_ratio           -->   0.39457897368920547
task_type                -->   classification
update_adj_ratio         -->   0.5154461753655715
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.480951499896621
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 12 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 12 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 161])
encoder.graph_encoders.1.weight: torch.Size([161, 7])
graph_learner.weight_tensor: torch.Size([12, 1433])
graph_learner2.weight_tensor: torch.Size([12, 161])
#Parameters = 250968

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 19s <> <> <>
Finished Training: /tmp/iteration_id_0.14274921763839532
Training time: 19.61

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 25; 
NLOSS = 1.89797
ACC = 0.16200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.14274921763839532/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 12 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 12 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.14274921763839532/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.85580 | ACC = 0.14900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.14274921763839532
Testing time: 0.17
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.27943340989153964
device                   -->   cuda:0
dropout                  -->   0.6393180865790568
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.21746696970721724
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.4414120642567686
grad_accumulated_steps   -->   8
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   95
graph_learn_num_pers     -->   16
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6049814187123257
graph_type               -->   dynamic
hidden_size              -->   1
learning_rate            -->   9.218169674887378
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.9523408161085126
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1967
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.39872202629541975
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.6092679565612814
sparsity_ratio           -->   0.045711737111537865
task_type                -->   classification
update_adj_ratio         -->   0.37011911054442626
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.08524617876748297
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 1])
encoder.graph_encoders.1.weight: torch.Size([1, 1])
encoder.graph_encoders.2.weight: torch.Size([1, 1])
encoder.graph_encoders.3.weight: torch.Size([1, 1])
encoder.graph_encoders.4.weight: torch.Size([1, 1])
encoder.graph_encoders.5.weight: torch.Size([1, 1])
encoder.graph_encoders.6.weight: torch.Size([1, 1])
encoder.graph_encoders.7.weight: torch.Size([1, 1])
encoder.graph_encoders.8.weight: torch.Size([1, 1])
encoder.graph_encoders.9.weight: torch.Size([1, 7])
graph_learner.weight_tensor: torch.Size([16, 1433])
graph_learner2.weight_tensor: torch.Size([16, 1])
#Parameters = 24392

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 14s <> <> <>
Finished Training: /tmp/iteration_id_0.39872202629541975
Training time: 14.65

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 30; 
NLOSS = -10.11224
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.39872202629541975/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.39872202629541975/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -10.11162 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.39872202629541975
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.935953822193219
device                   -->   cuda:0
dropout                  -->   0.2026495814961452
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6566561476638892
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.24404678317605732
grad_accumulated_steps   -->   1
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   40
graph_learn_num_pers     -->   2
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.8435648515262533
graph_type               -->   dynamic
hidden_size              -->   169
learning_rate            -->   8.234641638217767
logging                  -->   True
lr_patience              -->   7
lr_reduce_factor         -->   0.42044768864476123
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   6236
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8529019903660756
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.23428137000972982
sparsity_ratio           -->   0.21221990179795824
task_type                -->   classification
update_adj_ratio         -->   0.32621222983932885
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.05986913931803395
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 169])
encoder.graph_encoders.1.weight: torch.Size([169, 7])
graph_learner.weight_tensor: torch.Size([2, 1433])
graph_learner2.weight_tensor: torch.Size([2, 169])
#Parameters = 246564

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 14s <> <> <>
Finished Training: /tmp/iteration_id_0.8529019903660756
Training time: 14.84

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 26; 
NLOSS = 6.06659
ACC = 0.34800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.8529019903660756/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.8529019903660756/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 5.94106 | ACC = 0.32300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.8529019903660756
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5274779784450757
device                   -->   cuda:0
dropout                  -->   0.6597538865147813
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.8642887054558677
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.9074099522771308
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   88
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.44199615458144603
graph_type               -->   dynamic
hidden_size              -->   72
learning_rate            -->   1.6190970023686968
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.3075268718066232
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   677
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.2576323902976215
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.3039264723316232
sparsity_ratio           -->   0.2892896940366373
task_type                -->   classification
update_adj_ratio         -->   0.02234331296871761
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9474927893709519
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 72])
encoder.graph_encoders.1.weight: torch.Size([72, 72])
encoder.graph_encoders.2.weight: torch.Size([72, 72])
encoder.graph_encoders.3.weight: torch.Size([72, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 72])
#Parameters = 126088

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 51s <> <> <>
Finished Training: /tmp/iteration_id_0.2576323902976215
Training time: 51.39

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 8; 
NLOSS = -1.13607
ACC = 0.11600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.2576323902976215/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.2576323902976215/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -1.19032 | ACC = 0.10300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.2576323902976215
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.07466695411514379
device                   -->   cuda:0
dropout                  -->   0.6890576850685863
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5527340840901123
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7758488367707436
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   38
graph_learn_num_pers     -->   2
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.05337804893542741
graph_type               -->   dynamic
hidden_size              -->   37
learning_rate            -->   7.400039053017739
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.7021469496896097
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   20
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.46431459811454545
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.5033730078922876
sparsity_ratio           -->   0.5334922484364069
task_type                -->   classification
update_adj_ratio         -->   0.11514790368133943
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9305467893384739
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 37])
encoder.graph_encoders.1.weight: torch.Size([37, 37])
encoder.graph_encoders.2.weight: torch.Size([37, 37])
encoder.graph_encoders.3.weight: torch.Size([37, 37])
encoder.graph_encoders.4.weight: torch.Size([37, 37])
encoder.graph_encoders.5.weight: torch.Size([37, 37])
encoder.graph_encoders.6.weight: torch.Size([37, 37])
encoder.graph_encoders.7.weight: torch.Size([37, 37])
encoder.graph_encoders.8.weight: torch.Size([37, 37])
encoder.graph_encoders.9.weight: torch.Size([37, 7])
graph_learner.weight_tensor: torch.Size([2, 1433])
graph_learner2.weight_tensor: torch.Size([2, 37])
#Parameters = 67172

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 42s <> <> <>
Finished Training: /tmp/iteration_id_0.46431459811454545
Training time: 42.4

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 13; 
NLOSS = -28.69949
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.46431459811454545/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.46431459811454545/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -36.61015 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.46431459811454545
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.27943340989153964
device                   -->   cuda:0
dropout                  -->   0.6393180865790568
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.21746696970721724
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.4414120642567686
grad_accumulated_steps   -->   8
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   95
graph_learn_num_pers     -->   16
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6049814187123257
graph_type               -->   dynamic
hidden_size              -->   1
learning_rate            -->   9.218169674887378
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.9523408161085126
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1967
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5209449004734679
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.6092679565612814
sparsity_ratio           -->   0.045711737111537865
task_type                -->   classification
update_adj_ratio         -->   0.37011911054442626
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.08524617876748297
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 1])
encoder.graph_encoders.1.weight: torch.Size([1, 1])
encoder.graph_encoders.2.weight: torch.Size([1, 1])
encoder.graph_encoders.3.weight: torch.Size([1, 1])
encoder.graph_encoders.4.weight: torch.Size([1, 1])
encoder.graph_encoders.5.weight: torch.Size([1, 1])
encoder.graph_encoders.6.weight: torch.Size([1, 1])
encoder.graph_encoders.7.weight: torch.Size([1, 1])
encoder.graph_encoders.8.weight: torch.Size([1, 1])
encoder.graph_encoders.9.weight: torch.Size([1, 7])
graph_learner.weight_tensor: torch.Size([16, 1433])
graph_learner2.weight_tensor: torch.Size([16, 1])
#Parameters = 24392

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 43s <> <> <>
Finished Training: /tmp/iteration_id_0.5209449004734679
Training time: 43.16

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 93; 
NLOSS = -9.92966
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5209449004734679/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5209449004734679/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -9.92025 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5209449004734679
Testing time: 0.2
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5274779784450757
device                   -->   cuda:0
dropout                  -->   0.6597538865147813
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.8642887054558677
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.9074099522771308
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   88
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.44199615458144603
graph_type               -->   dynamic
hidden_size              -->   72
learning_rate            -->   1.6190970023686968
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.3075268718066232
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   677
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6564507894722645
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.3039264723316232
sparsity_ratio           -->   0.2892896940366373
task_type                -->   classification
update_adj_ratio         -->   0.02234331296871761
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9474927893709519
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 72])
encoder.graph_encoders.1.weight: torch.Size([72, 72])
encoder.graph_encoders.2.weight: torch.Size([72, 72])
encoder.graph_encoders.3.weight: torch.Size([72, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 72])
#Parameters = 126088

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 48s <> <> <>
Finished Training: /tmp/iteration_id_0.6564507894722645
Training time: 48.98

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 8; 
NLOSS = -1.13607
ACC = 0.11600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6564507894722645/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6564507894722645/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -1.16396 | ACC = 0.10300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6564507894722645
Testing time: 0.05
=========================
Best found configuration: {'degree_ratio': 0.5274779784450757, 'dropout': 0.6597538865147813, 'feat_adj_dropout': 0.8642887054558677, 'gl_dropout': 0.9074099522771308, 'grad_accumulated_steps': 2, 'graph_hops': 4, 'graph_learn_hidden_size': 88, 'graph_learn_num_pers': 8, 'graph_skip_conn': 0.44199615458144603, 'hidden_size': 72, 'learning_rate': 1.6190970023686968, 'lr_patience': 5, 'lr_reduce_factor': 0.3075268718066232, 'num_anchors': 677, 'smoothness_ratio': 0.3039264723316232, 'sparsity_ratio': 0.2892896940366373, 'update_adj_ratio': 0.02234331296871761, 'weight_decay': 0.9474927893709519}
A total of 27 unique configurations where sampled.
A total of 40 runs where executed.
Total budget corresponds to 4.0 full function evaluations.
=========================NAS Done=========================
NA: {'data_type': 'network', 'dataset_name': 'cora', 'data_dir': '../data/cora/', 'pretrained': None, 'task_type': 'classification', 'out_dir': '../out/cora/idgl_anchor', 'seed': 42, 'model_name': 'GraphClf', 'scalable_run': True, 'num_anchors': 677, 'hidden_size': 72, 'use_bert': False, 'dropout': 0.6597538865147813, 'feat_adj_dropout': 0.8642887054558677, 'gl_dropout': 0.9074099522771308, 'bignn': False, 'graph_module': 'gcn', 'graph_type': 'dynamic', 'graph_learn': True, 'graph_metric_type': 'weighted_cosine', 'graph_skip_conn': 0.44199615458144603, 'update_adj_ratio': 0.02234331296871761, 'graph_include_self': False, 'graph_learn_regularization': True, 'smoothness_ratio': 0.3039264723316232, 'degree_ratio': 0.5274779784450757, 'sparsity_ratio': 0.2892896940366373, 'graph_learn_ratio': 0, 'graph_learn_hidden_size': 88, 'graph_learn_epsilon': 0, 'graph_learn_topk': None, 'graph_learn_num_pers': 8, 'graph_hops': 4, 'gat_nhead': 8, 'gat_alpha': 0.2, 'optimizer': 'adam', 'learning_rate': 1.6190970023686968, 'weight_decay': 0.9474927893709519, 'lr_patience': 5, 'lr_reduce_factor': 0.3075268718066232, 'grad_clipping': None, 'grad_accumulated_steps': 2, 'eary_stop_metric': 'nloss', 'pretrain_epoch': 0, 'max_iter': 10, 'eps_adj': 8.5e-05, 'rl_ratio': 0, 'rl_ratio_power': 1, 'rl_start_epoch': 1, 'max_rl_ratio': 0.99, 'rl_reward_metric': 'acc', 'rl_wmd_ratio': 0, 'random_seed': 1234, 'shuffle': True, 'max_epochs': 10000, 'patience': 100, 'verbose': 20, 'print_every_epochs': 500, 'out_predictions': False, 'out_raw_learned_adj_path': 'cora_idgl_node_anchor_adj.npy', 'save_params': True, 'logging': True, 'no_cuda': False, 'cuda_id': 0}
=========================Training Starting=========================
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5274779784450757
dropout                  -->   0.6597538865147813
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.8642887054558677
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.9074099522771308
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   88
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.44199615458144603
graph_type               -->   dynamic
hidden_size              -->   72
learning_rate            -->   1.6190970023686968
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.3075268718066232
max_epochs               -->   10000
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   677
optimizer                -->   adam
out_dir                  -->   ../out/cora/idgl_anchor
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.3039264723316232
sparsity_ratio           -->   0.2892896940366373
task_type                -->   classification
update_adj_ratio         -->   0.02234331296871761
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9474927893709519
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 72])
encoder.graph_encoders.1.weight: torch.Size([72, 72])
encoder.graph_encoders.2.weight: torch.Size([72, 72])
encoder.graph_encoders.3.weight: torch.Size([72, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 72])
#Parameters = 126088

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 50s <> <> <>
Finished Training: ../out/cora/idgl_anchor
Training time: 50.5

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 8; 
NLOSS = -1.13607
ACC = 0.11600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model ../out/cora/idgl_anchor/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to ../out/cora/idgl_anchor/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -1.16396 | ACC = 0.10300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: ../out/cora/idgl_anchor
Testing time: 0.09
=========================Training Done=========================
results: 0.103
Job completed successfully!
