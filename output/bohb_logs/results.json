[[0, 0, 0], 11.11111111111111, {"submitted": 1636038325.2977197, "started": 1636038325.29799, "finished": 1636038350.4203942}, {"loss": 0.13, "info": 0.13}, null]
[[0, 0, 1], 11.11111111111111, {"submitted": 1636038350.436968, "started": 1636038350.4372077, "finished": 1636038353.6274927}, null, "Traceback (most recent call last):\n  File \"/root/miniconda3/envs/twig_env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/workspace/NAS_module/sample.py\", line 67, in compute\n    res = GNN_run(self.idgl_conf)\n  File \"/workspace/GNN_module/src/main.py\", line 29, in main\n    model.train()\n  File \"/workspace/GNN_module/src/core/model_handler.py\", line 156, in train\n    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])\n  File \"/workspace/GNN_module/src/core/model_handler.py\", line 944, in _scalable_run_whole_epoch\n    cur_agg_vec = network.encoder.graph_encoders[-1](node_vec, cur_node_anchor_adj, anchor_mp=True, batch_norm=False)\n  File \"/root/miniconda3/envs/twig_env/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/workspace/GNN_module/src/core/layers/anchor.py\", line 84, in forward\n    node_norm = node_anchor_adj / torch.clamp(torch.sum(node_anchor_adj, dim=-2, keepdim=True), min=VERY_SMALL_NUMBER)\nRuntimeError: CUDA out of memory. Tried to allocate 58.00 MiB (GPU 0; 12.00 GiB total capacity; 9.41 GiB already allocated; 0 bytes free; 9.69 GiB reserved in total by PyTorch)\n"]
[[0, 0, 2], 11.11111111111111, {"submitted": 1636038353.6487842, "started": 1636038353.649126, "finished": 1636038362.4534395}, {"loss": 0.13, "info": 0.13}, null]
[[0, 0, 3], 11.11111111111111, {"submitted": 1636038362.4727612, "started": 1636038362.473068, "finished": 1636038364.4129846}, null, "Traceback (most recent call last):\n  File \"/root/miniconda3/envs/twig_env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/workspace/NAS_module/sample.py\", line 67, in compute\n    res = GNN_run(self.idgl_conf)\n  File \"/workspace/GNN_module/src/main.py\", line 29, in main\n    model.train()\n  File \"/workspace/GNN_module/src/core/model_handler.py\", line 156, in train\n    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])\n  File \"/workspace/GNN_module/src/core/model_handler.py\", line 946, in _scalable_run_whole_epoch\n    first_agg_vec = network.encoder.graph_encoders[-1](node_vec, first_node_anchor_adj, anchor_mp=True, batch_norm=False)\n  File \"/root/miniconda3/envs/twig_env/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/workspace/GNN_module/src/core/layers/anchor.py\", line 84, in forward\n    node_norm = node_anchor_adj / torch.clamp(torch.sum(node_anchor_adj, dim=-2, keepdim=True), min=VERY_SMALL_NUMBER)\nRuntimeError: CUDA out of memory. Tried to allocate 58.00 MiB (GPU 0; 12.00 GiB total capacity; 9.50 GiB already allocated; 0 bytes free; 9.71 GiB reserved in total by PyTorch)\n"]
[[0, 0, 4], 11.11111111111111, {"submitted": 1636038364.4343626, "started": 1636038364.4346843, "finished": 1636038367.58061}, null, "Traceback (most recent call last):\n  File \"/root/miniconda3/envs/twig_env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/workspace/NAS_module/sample.py\", line 67, in compute\n    res = GNN_run(self.idgl_conf)\n  File \"/workspace/GNN_module/src/main.py\", line 29, in main\n    model.train()\n  File \"/workspace/GNN_module/src/core/model_handler.py\", line 156, in train\n    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])\n  File \"/workspace/GNN_module/src/core/model_handler.py\", line 973, in _scalable_run_whole_epoch\n    loss.backward()\n  File \"/root/miniconda3/envs/twig_env/lib/python3.7/site-packages/torch/_tensor.py\", line 255, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n  File \"/root/miniconda3/envs/twig_env/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 149, in backward\n    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\nRuntimeError: CUDA out of memory. Tried to allocate 504.00 MiB (GPU 0; 12.00 GiB total capacity; 8.68 GiB already allocated; 206.38 MiB free; 9.26 GiB reserved in total by PyTorch)\n"]
[[0, 0, 5], 11.11111111111111, {"submitted": 1636038367.5998192, "started": 1636038367.6000907, "finished": 1636038371.1148064}, null, "Traceback (most recent call last):\n  File \"/root/miniconda3/envs/twig_env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/workspace/NAS_module/sample.py\", line 67, in compute\n    res = GNN_run(self.idgl_conf)\n  File \"/workspace/GNN_module/src/main.py\", line 29, in main\n    model.train()\n  File \"/workspace/GNN_module/src/core/model_handler.py\", line 156, in train\n    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])\n  File \"/workspace/GNN_module/src/core/model_handler.py\", line 904, in _scalable_run_whole_epoch\n    cur_node_anchor_adj = network.learn_graph(network.graph_learner2, node_vec, anchor_features=anchor_vec)\n  File \"/workspace/GNN_module/src/core/models/graph_clf.py\", line 90, in learn_graph\n    node_anchor_adj = graph_learner(node_features, anchor_features)\n  File \"/root/miniconda3/envs/twig_env/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/workspace/GNN_module/src/core/layers/scalable_graphlearn.py\", line 90, in forward\n    attention = torch.matmul(context_norm, anchors_norm.transpose(-1, -2)).mean(0)\nRuntimeError: CUDA out of memory. Tried to allocate 560.00 MiB (GPU 0; 12.00 GiB total capacity; 9.32 GiB already allocated; 0 bytes free; 9.64 GiB reserved in total by PyTorch)\n"]
[[0, 0, 6], 11.11111111111111, {"submitted": 1636038371.1319902, "started": 1636038371.1322675, "finished": 1636038372.421559}, null, "Traceback (most recent call last):\n  File \"/root/miniconda3/envs/twig_env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/workspace/NAS_module/sample.py\", line 67, in compute\n    res = GNN_run(self.idgl_conf)\n  File \"/workspace/GNN_module/src/main.py\", line 29, in main\n    model.train()\n  File \"/workspace/GNN_module/src/core/model_handler.py\", line 156, in train\n    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])\n  File \"/workspace/GNN_module/src/core/model_handler.py\", line 904, in _scalable_run_whole_epoch\n    cur_node_anchor_adj = network.learn_graph(network.graph_learner2, node_vec, anchor_features=anchor_vec)\n  File \"/workspace/GNN_module/src/core/models/graph_clf.py\", line 90, in learn_graph\n    node_anchor_adj = graph_learner(node_features, anchor_features)\n  File \"/root/miniconda3/envs/twig_env/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/workspace/GNN_module/src/core/layers/scalable_graphlearn.py\", line 90, in forward\n    attention = torch.matmul(context_norm, anchors_norm.transpose(-1, -2)).mean(0)\nRuntimeError: CUDA out of memory. Tried to allocate 168.00 MiB (GPU 0; 12.00 GiB total capacity; 9.55 GiB already allocated; 0 bytes free; 9.64 GiB reserved in total by PyTorch)\n"]
[[0, 0, 7], 11.11111111111111, {"submitted": 1636038372.440527, "started": 1636038372.4408019, "finished": 1636038374.2955728}, null, "Traceback (most recent call last):\n  File \"/root/miniconda3/envs/twig_env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/workspace/NAS_module/sample.py\", line 67, in compute\n    res = GNN_run(self.idgl_conf)\n  File \"/workspace/GNN_module/src/main.py\", line 29, in main\n    model.train()\n  File \"/workspace/GNN_module/src/core/model_handler.py\", line 156, in train\n    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])\n  File \"/workspace/GNN_module/src/core/model_handler.py\", line 904, in _scalable_run_whole_epoch\n    cur_node_anchor_adj = network.learn_graph(network.graph_learner2, node_vec, anchor_features=anchor_vec)\n  File \"/workspace/GNN_module/src/core/models/graph_clf.py\", line 90, in learn_graph\n    node_anchor_adj = graph_learner(node_features, anchor_features)\n  File \"/root/miniconda3/envs/twig_env/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/workspace/GNN_module/src/core/layers/scalable_graphlearn.py\", line 90, in forward\n    attention = torch.matmul(context_norm, anchors_norm.transpose(-1, -2)).mean(0)\nRuntimeError: CUDA out of memory. Tried to allocate 308.00 MiB (GPU 0; 12.00 GiB total capacity; 9.24 GiB already allocated; 18.38 MiB free; 9.45 GiB reserved in total by PyTorch)\n"]
[[0, 0, 8], 11.11111111111111, {"submitted": 1636038374.3151426, "started": 1636038374.3154035, "finished": 1636038382.971606}, {"loss": 0.144, "info": 0.144}, null]
[[0, 0, 9], 11.11111111111111, {"submitted": 1636038382.9961045, "started": 1636038382.996678, "finished": 1636038390.4938498}, {"loss": 0.13, "info": 0.13}, null]
[[0, 0, 10], 11.11111111111111, {"submitted": 1636038390.5141504, "started": 1636038390.5144353, "finished": 1636038392.547371}, null, "Traceback (most recent call last):\n  File \"/root/miniconda3/envs/twig_env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/workspace/NAS_module/sample.py\", line 67, in compute\n    res = GNN_run(self.idgl_conf)\n  File \"/workspace/GNN_module/src/main.py\", line 29, in main\n    model.train()\n  File \"/workspace/GNN_module/src/core/model_handler.py\", line 156, in train\n    self.run_epoch(self.train_loader, training=True, verbose=self.config['verbose'])\n  File \"/workspace/GNN_module/src/core/model_handler.py\", line 930, in _scalable_run_whole_epoch\n    mid_first_agg_vecc = encoder(node_vec, first_node_anchor_adj, anchor_mp=True, batch_norm=False)\n  File \"/root/miniconda3/envs/twig_env/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/workspace/GNN_module/src/core/layers/anchor.py\", line 85, in forward\n    anchor_norm = node_anchor_adj / torch.clamp(torch.sum(node_anchor_adj, dim=-1, keepdim=True), min=VERY_SMALL_NUMBER)\nRuntimeError: CUDA out of memory. Tried to allocate 28.00 MiB (GPU 0; 12.00 GiB total capacity; 9.34 GiB already allocated; 0 bytes free; 9.69 GiB reserved in total by PyTorch)\n"]
