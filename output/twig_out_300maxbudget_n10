Hello, I am Twig. I do my job!
Loading job details...success
Doing my job!
=========================NAS Starting=========================
{'run_id': 'twig_run', 'n_iterations': 10, 'host_addr': '127.0.0.1', 'min_budget': 10, 'max_budget': 300, 'idgl_config_file': '/workspace/GNN_module/src/config/cora/idgl_anchor.yml', 'idgl_working_dir': '/workspace/GNN_module/src/', 'idgl_params': [None], 'hyperparameters': {'learning_rate': {'min': 0, 'max': 10, 'type': 'uniform_float'}, 'weight_decay': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'lr_reduce_factor': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'lr_patience': {'min': 1, 'max': 10, 'type': 'uniform_integer'}, 'grad_accumulated_steps': {'min': 1, 'max': 10, 'type': 'uniform_integer'}, 'dropout': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'feat_adj_dropout': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'gl_dropout': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'num_anchors': {'min': 1, 'max': 10000, 'type': 'uniform_integer'}, 'hidden_size': {'min': 1, 'max': 200, 'type': 'uniform_integer'}, 'graph_skip_conn': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'update_adj_ratio': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'smoothness_ratio': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'degree_ratio': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'sparsity_ratio': {'min': 0, 'max': 1, 'type': 'uniform_float'}, 'graph_learn_hidden_size': {'min': 1, 'max': 200, 'type': 'uniform_integer'}, 'graph_learn_num_pers': {'min': 1, 'max': 20, 'type': 'uniform_integer'}, 'graph_hops': {'min': 1, 'max': 10, 'type': 'uniform_integer'}}}
{'min': 0, 'max': 10, 'type': 'uniform_float'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 1, 'max': 10, 'type': 'uniform_integer'}
{'min': 1, 'max': 10, 'type': 'uniform_integer'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 1, 'max': 10000, 'type': 'uniform_integer'}
{'min': 1, 'max': 200, 'type': 'uniform_integer'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 0, 'max': 1, 'type': 'uniform_float'}
{'min': 1, 'max': 200, 'type': 'uniform_integer'}
{'min': 1, 'max': 20, 'type': 'uniform_integer'}
{'min': 1, 'max': 10, 'type': 'uniform_integer'}
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.7194342682638708
dropout                  -->   0.46902088518489893
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6801707009000239
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.2699003523838135
grad_accumulated_steps   -->   3
grad_clipping            -->   None
graph_hops               -->   6
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   175
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.8067858873870353
graph_type               -->   dynamic
hidden_size              -->   109
learning_rate            -->   1.5394976203250454
logging                  -->   True
lr_patience              -->   8
lr_reduce_factor         -->   0.321087968976034
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2186
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.1338516701426281
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7765573813686932
sparsity_ratio           -->   0.6688564193525814
task_type                -->   classification
update_adj_ratio         -->   0.5144021380754381
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.4006844651807121
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 109])
encoder.graph_encoders.1.weight: torch.Size([109, 109])
encoder.graph_encoders.2.weight: torch.Size([109, 109])
encoder.graph_encoders.3.weight: torch.Size([109, 109])
encoder.graph_encoders.4.weight: torch.Size([109, 109])
encoder.graph_encoders.5.weight: torch.Size([109, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 109])
#Parameters = 216820

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 08s <> <> <>
Finished Training: /tmp/iteration_id_0.1338516701426281
Training time: 8.8

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 5; 
NLOSS = 4.21788
ACC = 0.11400

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.1338516701426281/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.1338516701426281/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 4.21128 | ACC = 0.10300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.1338516701426281
Testing time: 0.13
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.276172120984297
device                   -->   cuda:0
dropout                  -->   0.28028121638861236
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.25578043008841844
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.3670775155517685
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   9
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   182
graph_learn_num_pers     -->   14
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.782124324082597
graph_type               -->   dynamic
hidden_size              -->   35
learning_rate            -->   3.4706106879494425
logging                  -->   True
lr_patience              -->   8
lr_reduce_factor         -->   0.9766180153705628
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5179
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.9114899293203529
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.6892134994912748
sparsity_ratio           -->   0.4907975143132851
task_type                -->   classification
update_adj_ratio         -->   0.3322198350418136
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8871511789817381
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 14 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 14 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 35])
encoder.graph_encoders.1.weight: torch.Size([35, 35])
encoder.graph_encoders.2.weight: torch.Size([35, 35])
encoder.graph_encoders.3.weight: torch.Size([35, 35])
encoder.graph_encoders.4.weight: torch.Size([35, 35])
encoder.graph_encoders.5.weight: torch.Size([35, 35])
encoder.graph_encoders.6.weight: torch.Size([35, 35])
encoder.graph_encoders.7.weight: torch.Size([35, 35])
encoder.graph_encoders.8.weight: torch.Size([35, 7])
graph_learner.weight_tensor: torch.Size([14, 1433])
graph_learner2.weight_tensor: torch.Size([14, 35])
#Parameters = 79527

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9609885452709579
device                   -->   cuda:0
dropout                  -->   0.6115918661454994
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.9899298420721658
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6129693923843333
grad_accumulated_steps   -->   10
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   158
graph_learn_num_pers     -->   16
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.201723689892656
graph_type               -->   dynamic
hidden_size              -->   74
learning_rate            -->   4.506286806873042
logging                  -->   True
lr_patience              -->   8
lr_reduce_factor         -->   0.8919695655658995
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   9369
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.28269606223477584
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7618990932539613
sparsity_ratio           -->   0.7317144190781176
task_type                -->   classification
update_adj_ratio         -->   0.6289378994128584
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6105817484781254
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 74])
encoder.graph_encoders.1.weight: torch.Size([74, 74])
encoder.graph_encoders.2.weight: torch.Size([74, 74])
encoder.graph_encoders.3.weight: torch.Size([74, 7])
graph_learner.weight_tensor: torch.Size([16, 1433])
graph_learner2.weight_tensor: torch.Size([16, 74])
#Parameters = 141624

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424350102628695
device                   -->   cuda:0
dropout                  -->   0.13239312390416857
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.8371179081315682
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.06225762571988569
grad_accumulated_steps   -->   3
grad_clipping            -->   None
graph_hops               -->   5
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   180
graph_learn_num_pers     -->   11
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5956418744032697
graph_type               -->   dynamic
hidden_size              -->   12
learning_rate            -->   4.588022825251107
logging                  -->   True
lr_patience              -->   7
lr_reduce_factor         -->   0.009908696920908455
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8526
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.3643942949800375
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.5623219350788345
sparsity_ratio           -->   0.4800740234678097
task_type                -->   classification
update_adj_ratio         -->   0.5354933488034386
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.78071400443107
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 12])
encoder.graph_encoders.1.weight: torch.Size([12, 12])
encoder.graph_encoders.2.weight: torch.Size([12, 12])
encoder.graph_encoders.3.weight: torch.Size([12, 12])
encoder.graph_encoders.4.weight: torch.Size([12, 7])
graph_learner.weight_tensor: torch.Size([11, 1433])
graph_learner2.weight_tensor: torch.Size([11, 12])
#Parameters = 33607

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.2179733733357745
device                   -->   cuda:0
dropout                  -->   0.21665051697374604
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.8969791591944228
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.17168922357655858
grad_accumulated_steps   -->   9
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   62
graph_learn_num_pers     -->   11
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.47923431913333536
graph_type               -->   dynamic
hidden_size              -->   156
learning_rate            -->   0.7300034524446364
logging                  -->   True
lr_patience              -->   7
lr_reduce_factor         -->   0.04367720902445227
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   6498
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6305080187912462
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.923632880907373
sparsity_ratio           -->   0.9710594146653994
task_type                -->   classification
update_adj_ratio         -->   0.5752842059481492
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.7821909696327815
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 156])
encoder.graph_encoders.1.weight: torch.Size([156, 156])
encoder.graph_encoders.2.weight: torch.Size([156, 156])
encoder.graph_encoders.3.weight: torch.Size([156, 7])
graph_learner.weight_tensor: torch.Size([11, 1433])
graph_learner2.weight_tensor: torch.Size([11, 156])
#Parameters = 290791

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 07s <> <> <>
Finished Training: /tmp/iteration_id_0.6305080187912462
Training time: 7.81

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = -2.16414
ACC = 0.16200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6305080187912462/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6305080187912462/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -2.17640 | ACC = 0.14900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6305080187912462
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.32379981304522865
device                   -->   cuda:0
dropout                  -->   0.9940740985217984
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.25040325616872083
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.3701965845614392
grad_accumulated_steps   -->   8
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   1
graph_learn_num_pers     -->   10
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.881304062349316
graph_type               -->   dynamic
hidden_size              -->   35
learning_rate            -->   0.12974014947487067
logging                  -->   True
lr_patience              -->   10
lr_reduce_factor         -->   0.6915252959593312
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   7211
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5036020487364874
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.03368199227401325
sparsity_ratio           -->   0.028580792817709866
task_type                -->   classification
update_adj_ratio         -->   0.050718395460652044
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8038552269020668
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 10 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 10 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 35])
encoder.graph_encoders.1.weight: torch.Size([35, 35])
encoder.graph_encoders.2.weight: torch.Size([35, 35])
encoder.graph_encoders.3.weight: torch.Size([35, 7])
graph_learner.weight_tensor: torch.Size([10, 1433])
graph_learner2.weight_tensor: torch.Size([10, 35])
#Parameters = 67530

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 08s <> <> <>
Finished Training: /tmp/iteration_id_0.5036020487364874
Training time: 8.11

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 0.52604
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5036020487364874/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 10 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 10 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5036020487364874/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.52604 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5036020487364874
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.8657091201156626
device                   -->   cuda:0
dropout                  -->   0.8380160656454126
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5663416772995763
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.853430346101773
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   7
graph_learn_num_pers     -->   3
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.2783827172470321
graph_type               -->   dynamic
hidden_size              -->   67
learning_rate            -->   1.687815046593294
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.45114561069464043
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   44
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.3528015923488721
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.2317615973687127
sparsity_ratio           -->   0.78035548796186
task_type                -->   classification
update_adj_ratio         -->   0.8337497363036568
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8949961009016693
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 67])
encoder.graph_encoders.1.weight: torch.Size([67, 67])
encoder.graph_encoders.2.weight: torch.Size([67, 67])
encoder.graph_encoders.3.weight: torch.Size([67, 7])
graph_learner.weight_tensor: torch.Size([3, 1433])
graph_learner2.weight_tensor: torch.Size([3, 67])
#Parameters = 109958

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 06s <> <> <>
Finished Training: /tmp/iteration_id_0.3528015923488721
Training time: 6.05

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 8; 
NLOSS = -3076.90723
ACC = 0.16200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.3528015923488721/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.3528015923488721/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -3088.43701 | ACC = 0.14900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.3528015923488721
Testing time: 0.05
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.7835124562687789
device                   -->   cuda:0
dropout                  -->   0.60480078520503
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.803740043019317
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.19167221146751268
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   135
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.4601558274027089
graph_type               -->   dynamic
hidden_size              -->   184
learning_rate            -->   3.966655970820768
logging                  -->   True
lr_patience              -->   9
lr_reduce_factor         -->   0.41793504715756224
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   3981
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8890026666879516
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7559572800452773
sparsity_ratio           -->   0.5639486759604717
task_type                -->   classification
update_adj_ratio         -->   0.41388287113042
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.48477876078217186
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 184])
encoder.graph_encoders.1.weight: torch.Size([184, 184])
encoder.graph_encoders.2.weight: torch.Size([184, 184])
encoder.graph_encoders.3.weight: torch.Size([184, 184])
encoder.graph_encoders.4.weight: torch.Size([184, 184])
encoder.graph_encoders.5.weight: torch.Size([184, 184])
encoder.graph_encoders.6.weight: torch.Size([184, 184])
encoder.graph_encoders.7.weight: torch.Size([184, 184])
encoder.graph_encoders.8.weight: torch.Size([184, 184])
encoder.graph_encoders.9.weight: torch.Size([184, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 184])
#Parameters = 548744

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.24408634324168166
device                   -->   cuda:0
dropout                  -->   0.10386543950852067
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6253821040774287
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5292701582838738
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   87
graph_learn_num_pers     -->   13
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.3444634267008265
graph_type               -->   dynamic
hidden_size              -->   163
learning_rate            -->   6.204937897234042
logging                  -->   True
lr_patience              -->   8
lr_reduce_factor         -->   0.4591204522024309
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1473
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.10214644651215143
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9400714270184949
sparsity_ratio           -->   0.4920211186118304
task_type                -->   classification
update_adj_ratio         -->   0.2583753929802449
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8375187286300986
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 13 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 13 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 163])
encoder.graph_encoders.1.weight: torch.Size([163, 163])
encoder.graph_encoders.2.weight: torch.Size([163, 163])
encoder.graph_encoders.3.weight: torch.Size([163, 163])
encoder.graph_encoders.4.weight: torch.Size([163, 163])
encoder.graph_encoders.5.weight: torch.Size([163, 163])
encoder.graph_encoders.6.weight: torch.Size([163, 163])
encoder.graph_encoders.7.weight: torch.Size([163, 163])
encoder.graph_encoders.8.weight: torch.Size([163, 163])
encoder.graph_encoders.9.weight: torch.Size([163, 7])
graph_learner.weight_tensor: torch.Size([13, 1433])
graph_learner2.weight_tensor: torch.Size([13, 163])
#Parameters = 468020

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.6227053300201973
device                   -->   cuda:0
dropout                  -->   0.13400587422650667
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.045725755466878404
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.4908268998654062
grad_accumulated_steps   -->   8
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   168
graph_learn_num_pers     -->   4
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.38230197698285784
graph_type               -->   dynamic
hidden_size              -->   103
learning_rate            -->   6.0548492526694755
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.05006412858257725
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8161
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.3313450100389169
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.01386883348174106
sparsity_ratio           -->   0.02445161546919361
task_type                -->   classification
update_adj_ratio         -->   0.5588799492458094
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.4008574680891883
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 4 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 4 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 103])
encoder.graph_encoders.1.weight: torch.Size([103, 103])
encoder.graph_encoders.2.weight: torch.Size([103, 103])
encoder.graph_encoders.3.weight: torch.Size([103, 103])
encoder.graph_encoders.4.weight: torch.Size([103, 103])
encoder.graph_encoders.5.weight: torch.Size([103, 103])
encoder.graph_encoders.6.weight: torch.Size([103, 103])
encoder.graph_encoders.7.weight: torch.Size([103, 103])
encoder.graph_encoders.8.weight: torch.Size([103, 103])
encoder.graph_encoders.9.weight: torch.Size([103, 7])
graph_learner.weight_tensor: torch.Size([4, 1433])
graph_learner2.weight_tensor: torch.Size([4, 103])
#Parameters = 239336

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.4728763479731668
device                   -->   cuda:0
dropout                  -->   0.6817627177706042
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.20483456165863745
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.10289425011879871
grad_accumulated_steps   -->   8
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   68
graph_learn_num_pers     -->   17
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.323632899040063
graph_type               -->   dynamic
hidden_size              -->   81
learning_rate            -->   2.4963224605410437
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.09064569285776436
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2183
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.3519313776370667
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.4370878998651033
sparsity_ratio           -->   0.009746874229749514
task_type                -->   classification
update_adj_ratio         -->   0.4054189308806093
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.11809799984962599
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 81])
encoder.graph_encoders.1.weight: torch.Size([81, 81])
encoder.graph_encoders.2.weight: torch.Size([81, 81])
encoder.graph_encoders.3.weight: torch.Size([81, 7])
graph_learner.weight_tensor: torch.Size([17, 1433])
graph_learner2.weight_tensor: torch.Size([17, 81])
#Parameters = 155500

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 09s <> <> <>
Finished Training: /tmp/iteration_id_0.3519313776370667
Training time: 9.11

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = -225.86543
ACC = 0.15600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.3519313776370667/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.3519313776370667/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -224.75711 | ACC = 0.14400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.3519313776370667
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5292356525874066
device                   -->   cuda:0
dropout                  -->   0.26032539690626855
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.40880063139326617
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6966723550025326
grad_accumulated_steps   -->   3
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   160
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.1800675179185408
graph_type               -->   dynamic
hidden_size              -->   144
learning_rate            -->   1.4324882681551498
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.8198758070907582
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   9932
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6025383563375296
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.16232620310896329
sparsity_ratio           -->   0.8359594946241952
task_type                -->   classification
update_adj_ratio         -->   0.24022466911594675
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5960601435963093
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 144])
encoder.graph_encoders.1.weight: torch.Size([144, 144])
encoder.graph_encoders.2.weight: torch.Size([144, 144])
encoder.graph_encoders.3.weight: torch.Size([144, 144])
encoder.graph_encoders.4.weight: torch.Size([144, 144])
encoder.graph_encoders.5.weight: torch.Size([144, 144])
encoder.graph_encoders.6.weight: torch.Size([144, 144])
encoder.graph_encoders.7.weight: torch.Size([144, 144])
encoder.graph_encoders.8.weight: torch.Size([144, 144])
encoder.graph_encoders.9.weight: torch.Size([144, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 144])
#Parameters = 396903

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.012839812217815383
device                   -->   cuda:0
dropout                  -->   0.2509742604546704
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.8611333388165169
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.16718375061419588
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   6
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   62
graph_learn_num_pers     -->   11
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.9897859345383001
graph_type               -->   dynamic
hidden_size              -->   92
learning_rate            -->   6.978499543757359
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.21718686613399762
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   6480
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.019369444291480575
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.6629874263325813
sparsity_ratio           -->   0.6245847994237747
task_type                -->   classification
update_adj_ratio         -->   0.32026073955798273
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.3462849039850886
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 92])
encoder.graph_encoders.1.weight: torch.Size([92, 92])
encoder.graph_encoders.2.weight: torch.Size([92, 92])
encoder.graph_encoders.3.weight: torch.Size([92, 92])
encoder.graph_encoders.4.weight: torch.Size([92, 92])
encoder.graph_encoders.5.weight: torch.Size([92, 7])
graph_learner.weight_tensor: torch.Size([11, 1433])
graph_learner2.weight_tensor: torch.Size([11, 92])
#Parameters = 183111

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.0757346682030352
device                   -->   cuda:0
dropout                  -->   0.17641253443679028
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.4140572708846998
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7180080824596486
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   200
graph_learn_num_pers     -->   18
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5234147229266272
graph_type               -->   dynamic
hidden_size              -->   69
learning_rate            -->   5.1247095058621825
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.8067940355867738
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1404
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.658904168738986
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.32876938789254406
sparsity_ratio           -->   0.4147978455924386
task_type                -->   classification
update_adj_ratio         -->   0.5383917110252154
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8424328283039144
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 69])
encoder.graph_encoders.1.weight: torch.Size([69, 69])
encoder.graph_encoders.2.weight: torch.Size([69, 69])
encoder.graph_encoders.3.weight: torch.Size([69, 7])
graph_learner.weight_tensor: torch.Size([18, 1433])
graph_learner2.weight_tensor: torch.Size([18, 69])
#Parameters = 135918

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 06s <> <> <>
Finished Training: /tmp/iteration_id_0.658904168738986
Training time: 6.88

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 8; 
NLOSS = -1630.05530
ACC = 0.11400

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.658904168738986/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.658904168738986/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -1671.40820 | ACC = 0.10300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.658904168738986
Testing time: 0.09
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.544500259721074
device                   -->   cuda:0
dropout                  -->   0.857274593363579
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.8632309590161971
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6946729588226077
grad_accumulated_steps   -->   1
grad_clipping            -->   None
graph_hops               -->   8
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   111
graph_learn_num_pers     -->   2
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.661109655035358
graph_type               -->   dynamic
hidden_size              -->   24
learning_rate            -->   2.0122193450235546
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.4073329393016456
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   9803
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.9659196908875377
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.1450285930477555
sparsity_ratio           -->   0.3191974992675103
task_type                -->   classification
update_adj_ratio         -->   0.3760512397039565
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.16744901024208148
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 24])
encoder.graph_encoders.1.weight: torch.Size([24, 24])
encoder.graph_encoders.2.weight: torch.Size([24, 24])
encoder.graph_encoders.3.weight: torch.Size([24, 24])
encoder.graph_encoders.4.weight: torch.Size([24, 24])
encoder.graph_encoders.5.weight: torch.Size([24, 24])
encoder.graph_encoders.6.weight: torch.Size([24, 24])
encoder.graph_encoders.7.weight: torch.Size([24, 7])
graph_learner.weight_tensor: torch.Size([2, 1433])
graph_learner2.weight_tensor: torch.Size([2, 24])
#Parameters = 40930

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.8612339505069138
device                   -->   cuda:0
dropout                  -->   0.705792480002691
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6440642896208029
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5178574065329066
grad_accumulated_steps   -->   7
grad_clipping            -->   None
graph_hops               -->   6
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   193
graph_learn_num_pers     -->   9
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.8797032321694648
graph_type               -->   dynamic
hidden_size              -->   7
learning_rate            -->   2.83121097245714
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.21759260714353046
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2010
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.7247168473737354
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9782118215122672
sparsity_ratio           -->   0.6757794043585512
task_type                -->   classification
update_adj_ratio         -->   0.03982348508577982
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.7455277961038922
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 7])
encoder.graph_encoders.1.weight: torch.Size([7, 7])
encoder.graph_encoders.2.weight: torch.Size([7, 7])
encoder.graph_encoders.3.weight: torch.Size([7, 7])
encoder.graph_encoders.4.weight: torch.Size([7, 7])
encoder.graph_encoders.5.weight: torch.Size([7, 7])
graph_learner.weight_tensor: torch.Size([9, 1433])
graph_learner2.weight_tensor: torch.Size([9, 7])
#Parameters = 23236

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 07s <> <> <>
Finished Training: /tmp/iteration_id_0.7247168473737354
Training time: 7.83

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = -22.72299
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.7247168473737354/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.7247168473737354/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -22.71614 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.7247168473737354
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.7734873911219987
device                   -->   cuda:0
dropout                  -->   0.04929527760524144
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.071127991687575
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.9566092668298958
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   7
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   146
graph_learn_num_pers     -->   10
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.35336424511528297
graph_type               -->   dynamic
hidden_size              -->   136
learning_rate            -->   4.724656896415157
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.6614759937439011
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   7177
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.37470491260107475
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9083264694870046
sparsity_ratio           -->   0.17326715117430003
task_type                -->   classification
update_adj_ratio         -->   0.2944483077624135
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5965990054000266
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 10 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 10 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 136])
encoder.graph_encoders.1.weight: torch.Size([136, 136])
encoder.graph_encoders.2.weight: torch.Size([136, 136])
encoder.graph_encoders.3.weight: torch.Size([136, 136])
encoder.graph_encoders.4.weight: torch.Size([136, 136])
encoder.graph_encoders.5.weight: torch.Size([136, 136])
encoder.graph_encoders.6.weight: torch.Size([136, 7])
graph_learner.weight_tensor: torch.Size([10, 1433])
graph_learner2.weight_tensor: torch.Size([10, 136])
#Parameters = 304010

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5638838682693406
device                   -->   cuda:0
dropout                  -->   0.31613150277905844
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.09764858990864511
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.18646627702816088
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   7
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   50
graph_learn_num_pers     -->   19
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.06459040647219372
graph_type               -->   dynamic
hidden_size              -->   81
learning_rate            -->   4.365256130901964
logging                  -->   True
lr_patience              -->   10
lr_reduce_factor         -->   0.7122782421321117
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   6399
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.25122680304992095
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.4317104342757452
sparsity_ratio           -->   0.009596295652939735
task_type                -->   classification
update_adj_ratio         -->   0.10818395160686456
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6073655820562345
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 19 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 19 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 81])
encoder.graph_encoders.1.weight: torch.Size([81, 81])
encoder.graph_encoders.2.weight: torch.Size([81, 81])
encoder.graph_encoders.3.weight: torch.Size([81, 81])
encoder.graph_encoders.4.weight: torch.Size([81, 81])
encoder.graph_encoders.5.weight: torch.Size([81, 81])
encoder.graph_encoders.6.weight: torch.Size([81, 7])
graph_learner.weight_tensor: torch.Size([19, 1433])
graph_learner2.weight_tensor: torch.Size([19, 81])
#Parameters = 178211

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.450530277353991
device                   -->   cuda:0
dropout                  -->   0.4960306520711555
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5990189690005909
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.35924638416465526
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   137
graph_learn_num_pers     -->   3
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.34213042480146894
graph_type               -->   dynamic
hidden_size              -->   108
learning_rate            -->   9.855970472649108
logging                  -->   True
lr_patience              -->   9
lr_reduce_factor         -->   0.8531620124697299
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   6056
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.0022663335530953566
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.5198993967974108
sparsity_ratio           -->   0.009623000451603803
task_type                -->   classification
update_adj_ratio         -->   0.7541984991815673
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.936030347243207
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 108])
encoder.graph_encoders.1.weight: torch.Size([108, 7])
graph_learner.weight_tensor: torch.Size([3, 1433])
graph_learner2.weight_tensor: torch.Size([3, 108])
#Parameters = 160143

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 06s <> <> <>
Finished Training: /tmp/iteration_id_0.0022663335530953566
Training time: 6.29

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 0.58717
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.0022663335530953566/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.0022663335530953566/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.56984 | ACC = 0.06600
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.0022663335530953566
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.8014337531676324
device                   -->   cuda:0
dropout                  -->   0.7000745067018942
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.002026705703706333
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7267898583329877
grad_accumulated_steps   -->   9
grad_clipping            -->   None
graph_hops               -->   6
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   181
graph_learn_num_pers     -->   17
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.4719789083530549
graph_type               -->   dynamic
hidden_size              -->   199
learning_rate            -->   5.746526114016529
logging                  -->   True
lr_patience              -->   7
lr_reduce_factor         -->   0.3052512568285888
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   6826
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.35999634261247737
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.05843734569795611
sparsity_ratio           -->   0.6635429670801971
task_type                -->   classification
update_adj_ratio         -->   0.2517462008556306
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.07587829029189042
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 199])
encoder.graph_encoders.1.weight: torch.Size([199, 199])
encoder.graph_encoders.2.weight: torch.Size([199, 199])
encoder.graph_encoders.3.weight: torch.Size([199, 199])
encoder.graph_encoders.4.weight: torch.Size([199, 199])
encoder.graph_encoders.5.weight: torch.Size([199, 7])
graph_learner.weight_tensor: torch.Size([17, 1433])
graph_learner2.weight_tensor: torch.Size([17, 199])
#Parameters = 472708

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5841554678405277
device                   -->   cuda:0
dropout                  -->   0.5552467832053878
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.8762865986855153
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.41175608357060534
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   4
graph_learn_num_pers     -->   20
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.8289387127274559
graph_type               -->   dynamic
hidden_size              -->   123
learning_rate            -->   9.837212720312976
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.44675026282883445
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   7582
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.7543235567862798
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.5388939781187309
sparsity_ratio           -->   0.5422970144243259
task_type                -->   classification
update_adj_ratio         -->   0.8055581000227928
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.13629799774805695
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 123])
encoder.graph_encoders.1.weight: torch.Size([123, 123])
encoder.graph_encoders.2.weight: torch.Size([123, 123])
encoder.graph_encoders.3.weight: torch.Size([123, 123])
encoder.graph_encoders.4.weight: torch.Size([123, 123])
encoder.graph_encoders.5.weight: torch.Size([123, 123])
encoder.graph_encoders.6.weight: torch.Size([123, 123])
encoder.graph_encoders.7.weight: torch.Size([123, 123])
encoder.graph_encoders.8.weight: torch.Size([123, 123])
encoder.graph_encoders.9.weight: torch.Size([123, 7])
graph_learner.weight_tensor: torch.Size([20, 1433])
graph_learner2.weight_tensor: torch.Size([20, 123])
#Parameters = 329272

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.46854195284369826
device                   -->   cuda:0
dropout                  -->   0.47726977263891346
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5309079990479713
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5167106154665941
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   4
graph_learn_num_pers     -->   11
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.610305092667424
graph_type               -->   dynamic
hidden_size              -->   178
learning_rate            -->   8.129224926296516
logging                  -->   True
lr_patience              -->   9
lr_reduce_factor         -->   0.7560291756049335
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2215
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.12187698660479707
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.4750819243063472
sparsity_ratio           -->   0.48151291129447193
task_type                -->   classification
update_adj_ratio         -->   0.11688299097157873
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.17324828571558892
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 178])
encoder.graph_encoders.1.weight: torch.Size([178, 178])
encoder.graph_encoders.2.weight: torch.Size([178, 178])
encoder.graph_encoders.3.weight: torch.Size([178, 7])
graph_learner.weight_tensor: torch.Size([11, 1433])
graph_learner2.weight_tensor: torch.Size([11, 178])
#Parameters = 337409

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 07s <> <> <>
Finished Training: /tmp/iteration_id_0.12187698660479707
Training time: 7.58

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = -14.44872
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.12187698660479707/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.12187698660479707/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -14.44576 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.12187698660479707
Testing time: 0.13
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9604045830507689
device                   -->   cuda:0
dropout                  -->   0.22418030748180762
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.2599527611464557
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6416001526327524
grad_accumulated_steps   -->   3
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   9
graph_learn_num_pers     -->   13
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5267795905012186
graph_type               -->   dynamic
hidden_size              -->   3
learning_rate            -->   5.582672677946353
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.6512173550071804
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   4507
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.7496016806167161
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.8081964015450269
sparsity_ratio           -->   0.28071762696650426
task_type                -->   classification
update_adj_ratio         -->   0.13272742092216572
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6197645027913314
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 13 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 13 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 3])
encoder.graph_encoders.1.weight: torch.Size([3, 3])
encoder.graph_encoders.2.weight: torch.Size([3, 3])
encoder.graph_encoders.3.weight: torch.Size([3, 7])
graph_learner.weight_tensor: torch.Size([13, 1433])
graph_learner2.weight_tensor: torch.Size([13, 3])
#Parameters = 23006

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 07s <> <> <>
Finished Training: /tmp/iteration_id_0.7496016806167161
Training time: 7.07

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 4; 
NLOSS = 3.01985
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.7496016806167161/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 13 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 13 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.7496016806167161/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 3.53458 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.7496016806167161
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.6171922783801871
device                   -->   cuda:0
dropout                  -->   0.1734073166327762
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5568380858168325
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.19372256799260035
grad_accumulated_steps   -->   1
grad_clipping            -->   None
graph_hops               -->   6
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   88
graph_learn_num_pers     -->   18
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.47028991945241905
graph_type               -->   dynamic
hidden_size              -->   79
learning_rate            -->   7.743978676870151
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.4210061064096705
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   4662
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6083860693928761
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.3672111114482387
sparsity_ratio           -->   0.26712428174767044
task_type                -->   classification
update_adj_ratio         -->   0.22788544470740468
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9157856163392769
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 79])
encoder.graph_encoders.1.weight: torch.Size([79, 79])
encoder.graph_encoders.2.weight: torch.Size([79, 79])
encoder.graph_encoders.3.weight: torch.Size([79, 79])
encoder.graph_encoders.4.weight: torch.Size([79, 79])
encoder.graph_encoders.5.weight: torch.Size([79, 7])
graph_learner.weight_tensor: torch.Size([18, 1433])
graph_learner2.weight_tensor: torch.Size([18, 79])
#Parameters = 165940

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.23938332452032085
device                   -->   cuda:0
dropout                  -->   0.22317926761604012
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.07244700035858176
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.8517640990371124
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   36
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.3921708189922365
graph_type               -->   dynamic
hidden_size              -->   25
learning_rate            -->   1.4842429102018129
logging                  -->   True
lr_patience              -->   3
lr_reduce_factor         -->   0.06629917008793051
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1815
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.959787036125501
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9142002506552742
sparsity_ratio           -->   0.05096791899920006
task_type                -->   classification
update_adj_ratio         -->   0.8824919331316713
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9146613540281
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 25])
encoder.graph_encoders.1.weight: torch.Size([25, 25])
encoder.graph_encoders.2.weight: torch.Size([25, 25])
encoder.graph_encoders.3.weight: torch.Size([25, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 25])
#Parameters = 38708

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 05s <> <> <>
Finished Training: /tmp/iteration_id_0.959787036125501
Training time: 5.4

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = -1.03312
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.959787036125501/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.959787036125501/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -1.06602 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.959787036125501
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.11712074596418232
device                   -->   cuda:0
dropout                  -->   0.8867796086983547
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.4039040383238407
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.9244693653376905
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   66
graph_learn_num_pers     -->   20
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.3609222495571358
graph_type               -->   dynamic
hidden_size              -->   26
learning_rate            -->   4.412643704448131
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.2832992966986764
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   351
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.23966538080362
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.49426781890582283
sparsity_ratio           -->   0.7886451554731403
task_type                -->   classification
update_adj_ratio         -->   0.5764989808736828
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6451177924303916
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 26])
encoder.graph_encoders.1.weight: torch.Size([26, 26])
encoder.graph_encoders.2.weight: torch.Size([26, 26])
encoder.graph_encoders.3.weight: torch.Size([26, 7])
graph_learner.weight_tensor: torch.Size([20, 1433])
graph_learner2.weight_tensor: torch.Size([20, 26])
#Parameters = 67972

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 05s <> <> <>
Finished Training: /tmp/iteration_id_0.23966538080362
Training time: 5.98

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 8; 
NLOSS = -9.89831
ACC = 0.15600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.23966538080362/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.23966538080362/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -9.78440 | ACC = 0.14900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.23966538080362
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.3857074872627094
device                   -->   cuda:0
dropout                  -->   0.031360022238044905
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.19667109121858628
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.23711846348619914
grad_accumulated_steps   -->   9
grad_clipping            -->   None
graph_hops               -->   7
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   57
graph_learn_num_pers     -->   6
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6857524509966877
graph_type               -->   dynamic
hidden_size              -->   93
learning_rate            -->   3.05906155947235
logging                  -->   True
lr_patience              -->   3
lr_reduce_factor         -->   0.22364770214784957
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5720
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.30559596607598605
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.20226806878618875
sparsity_ratio           -->   0.7315498270595767
task_type                -->   classification
update_adj_ratio         -->   0.8163977228059728
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9793201858131884
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 6 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 6 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 93])
encoder.graph_encoders.1.weight: torch.Size([93, 93])
encoder.graph_encoders.2.weight: torch.Size([93, 93])
encoder.graph_encoders.3.weight: torch.Size([93, 93])
encoder.graph_encoders.4.weight: torch.Size([93, 93])
encoder.graph_encoders.5.weight: torch.Size([93, 93])
encoder.graph_encoders.6.weight: torch.Size([93, 7])
graph_learner.weight_tensor: torch.Size([6, 1433])
graph_learner2.weight_tensor: torch.Size([6, 93])
#Parameters = 186321

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.7194342682638708
device                   -->   cuda:0
dropout                  -->   0.46902088518489893
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6801707009000239
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.2699003523838135
grad_accumulated_steps   -->   3
grad_clipping            -->   None
graph_hops               -->   6
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   175
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.8067858873870353
graph_type               -->   dynamic
hidden_size              -->   109
learning_rate            -->   1.5394976203250454
logging                  -->   True
lr_patience              -->   8
lr_reduce_factor         -->   0.321087968976034
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2186
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.14092215819968368
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7765573813686932
sparsity_ratio           -->   0.6688564193525814
task_type                -->   classification
update_adj_ratio         -->   0.5144021380754381
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.4006844651807121
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 109])
encoder.graph_encoders.1.weight: torch.Size([109, 109])
encoder.graph_encoders.2.weight: torch.Size([109, 109])
encoder.graph_encoders.3.weight: torch.Size([109, 109])
encoder.graph_encoders.4.weight: torch.Size([109, 109])
encoder.graph_encoders.5.weight: torch.Size([109, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 109])
#Parameters = 216820

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.32379981304522865
device                   -->   cuda:0
dropout                  -->   0.9940740985217984
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.25040325616872083
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.3701965845614392
grad_accumulated_steps   -->   8
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   1
graph_learn_num_pers     -->   10
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.881304062349316
graph_type               -->   dynamic
hidden_size              -->   35
learning_rate            -->   0.12974014947487067
logging                  -->   True
lr_patience              -->   10
lr_reduce_factor         -->   0.6915252959593312
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   7211
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5076521815371166
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.03368199227401325
sparsity_ratio           -->   0.028580792817709866
task_type                -->   classification
update_adj_ratio         -->   0.050718395460652044
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8038552269020668
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 10 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 10 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 35])
encoder.graph_encoders.1.weight: torch.Size([35, 35])
encoder.graph_encoders.2.weight: torch.Size([35, 35])
encoder.graph_encoders.3.weight: torch.Size([35, 7])
graph_learner.weight_tensor: torch.Size([10, 1433])
graph_learner2.weight_tensor: torch.Size([10, 35])
#Parameters = 67530

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 20s <> <> <>
Finished Training: /tmp/iteration_id_0.5076521815371166
Training time: 20.29

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 34; 
NLOSS = 0.56182
ACC = 0.30800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5076521815371166/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 10 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 10 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5076521815371166/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.56182 | ACC = 0.31100
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5076521815371166
Testing time: 0.13
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.4728763479731668
device                   -->   cuda:0
dropout                  -->   0.6817627177706042
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.20483456165863745
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.10289425011879871
grad_accumulated_steps   -->   8
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   68
graph_learn_num_pers     -->   17
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.323632899040063
graph_type               -->   dynamic
hidden_size              -->   81
learning_rate            -->   2.4963224605410437
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.09064569285776436
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2183
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5071917937662493
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.4370878998651033
sparsity_ratio           -->   0.009746874229749514
task_type                -->   classification
update_adj_ratio         -->   0.4054189308806093
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.11809799984962599
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 81])
encoder.graph_encoders.1.weight: torch.Size([81, 81])
encoder.graph_encoders.2.weight: torch.Size([81, 81])
encoder.graph_encoders.3.weight: torch.Size([81, 7])
graph_learner.weight_tensor: torch.Size([17, 1433])
graph_learner2.weight_tensor: torch.Size([17, 81])
#Parameters = 155500

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 15s <> <> <>
Finished Training: /tmp/iteration_id_0.5071917937662493
Training time: 15.68

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 16; 
NLOSS = -14.10746
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5071917937662493/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5071917937662493/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -14.10044 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5071917937662493
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.0757346682030352
device                   -->   cuda:0
dropout                  -->   0.17641253443679028
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.4140572708846998
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7180080824596486
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   200
graph_learn_num_pers     -->   18
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5234147229266272
graph_type               -->   dynamic
hidden_size              -->   69
learning_rate            -->   5.1247095058621825
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.8067940355867738
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1404
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.3871776402074235
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.32876938789254406
sparsity_ratio           -->   0.4147978455924386
task_type                -->   classification
update_adj_ratio         -->   0.5383917110252154
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8424328283039144
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 69])
encoder.graph_encoders.1.weight: torch.Size([69, 69])
encoder.graph_encoders.2.weight: torch.Size([69, 69])
encoder.graph_encoders.3.weight: torch.Size([69, 7])
graph_learner.weight_tensor: torch.Size([18, 1433])
graph_learner2.weight_tensor: torch.Size([18, 69])
#Parameters = 135918

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 17s <> <> <>
Finished Training: /tmp/iteration_id_0.3871776402074235
Training time: 17.64

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 15; 
NLOSS = -5.67392
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.3871776402074235/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.3871776402074235/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -5.67469 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.3871776402074235
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.8612339505069138
device                   -->   cuda:0
dropout                  -->   0.705792480002691
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6440642896208029
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5178574065329066
grad_accumulated_steps   -->   7
grad_clipping            -->   None
graph_hops               -->   6
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   193
graph_learn_num_pers     -->   9
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.8797032321694648
graph_type               -->   dynamic
hidden_size              -->   7
learning_rate            -->   2.83121097245714
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.21759260714353046
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2010
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.29871106967627836
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9782118215122672
sparsity_ratio           -->   0.6757794043585512
task_type                -->   classification
update_adj_ratio         -->   0.03982348508577982
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.7455277961038922
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 7])
encoder.graph_encoders.1.weight: torch.Size([7, 7])
encoder.graph_encoders.2.weight: torch.Size([7, 7])
encoder.graph_encoders.3.weight: torch.Size([7, 7])
encoder.graph_encoders.4.weight: torch.Size([7, 7])
encoder.graph_encoders.5.weight: torch.Size([7, 7])
graph_learner.weight_tensor: torch.Size([9, 1433])
graph_learner2.weight_tensor: torch.Size([9, 7])
#Parameters = 23236

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 19s <> <> <>
Finished Training: /tmp/iteration_id_0.29871106967627836
Training time: 19.45

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 30; 
NLOSS = 6.75385
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.29871106967627836/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.29871106967627836/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 6.76812 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.29871106967627836
Testing time: 0.08
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.450530277353991
device                   -->   cuda:0
dropout                  -->   0.4960306520711555
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5990189690005909
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.35924638416465526
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   137
graph_learn_num_pers     -->   3
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.34213042480146894
graph_type               -->   dynamic
hidden_size              -->   108
learning_rate            -->   9.855970472649108
logging                  -->   True
lr_patience              -->   9
lr_reduce_factor         -->   0.8531620124697299
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   6056
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6490443940195882
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.5198993967974108
sparsity_ratio           -->   0.009623000451603803
task_type                -->   classification
update_adj_ratio         -->   0.7541984991815673
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.936030347243207
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 108])
encoder.graph_encoders.1.weight: torch.Size([108, 7])
graph_learner.weight_tensor: torch.Size([3, 1433])
graph_learner2.weight_tensor: torch.Size([3, 108])
#Parameters = 160143

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 12s <> <> <>
Finished Training: /tmp/iteration_id_0.6490443940195882
Training time: 12.79

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 32; 
NLOSS = 1.69516
ACC = 0.25600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6490443940195882/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6490443940195882/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.61064 | ACC = 0.22500
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6490443940195882
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.46854195284369826
device                   -->   cuda:0
dropout                  -->   0.47726977263891346
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5309079990479713
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5167106154665941
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   4
graph_learn_num_pers     -->   11
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.610305092667424
graph_type               -->   dynamic
hidden_size              -->   178
learning_rate            -->   8.129224926296516
logging                  -->   True
lr_patience              -->   9
lr_reduce_factor         -->   0.7560291756049335
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2215
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.49263698335395867
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.4750819243063472
sparsity_ratio           -->   0.48151291129447193
task_type                -->   classification
update_adj_ratio         -->   0.11688299097157873
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.17324828571558892
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 178])
encoder.graph_encoders.1.weight: torch.Size([178, 178])
encoder.graph_encoders.2.weight: torch.Size([178, 178])
encoder.graph_encoders.3.weight: torch.Size([178, 7])
graph_learner.weight_tensor: torch.Size([11, 1433])
graph_learner2.weight_tensor: torch.Size([11, 178])
#Parameters = 337409

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 19s <> <> <>
Finished Training: /tmp/iteration_id_0.49263698335395867
Training time: 19.94

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 20; 
NLOSS = -14.37713
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.49263698335395867/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.49263698335395867/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -14.37289 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.49263698335395867
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9604045830507689
device                   -->   cuda:0
dropout                  -->   0.22418030748180762
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.2599527611464557
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6416001526327524
grad_accumulated_steps   -->   3
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   9
graph_learn_num_pers     -->   13
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5267795905012186
graph_type               -->   dynamic
hidden_size              -->   3
learning_rate            -->   5.582672677946353
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.6512173550071804
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   4507
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.9502266589209113
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.8081964015450269
sparsity_ratio           -->   0.28071762696650426
task_type                -->   classification
update_adj_ratio         -->   0.13272742092216572
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6197645027913314
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 13 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 13 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 3])
encoder.graph_encoders.1.weight: torch.Size([3, 3])
encoder.graph_encoders.2.weight: torch.Size([3, 3])
encoder.graph_encoders.3.weight: torch.Size([3, 7])
graph_learner.weight_tensor: torch.Size([13, 1433])
graph_learner2.weight_tensor: torch.Size([13, 3])
#Parameters = 23006

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.23938332452032085
device                   -->   cuda:0
dropout                  -->   0.22317926761604012
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.07244700035858176
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.8517640990371124
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   36
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.3921708189922365
graph_type               -->   dynamic
hidden_size              -->   25
learning_rate            -->   1.4842429102018129
logging                  -->   True
lr_patience              -->   3
lr_reduce_factor         -->   0.06629917008793051
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1815
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6379342035017843
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9142002506552742
sparsity_ratio           -->   0.05096791899920006
task_type                -->   classification
update_adj_ratio         -->   0.8824919331316713
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9146613540281
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 25])
encoder.graph_encoders.1.weight: torch.Size([25, 25])
encoder.graph_encoders.2.weight: torch.Size([25, 25])
encoder.graph_encoders.3.weight: torch.Size([25, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 25])
#Parameters = 38708

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 14s <> <> <>
Finished Training: /tmp/iteration_id_0.6379342035017843
Training time: 14.24

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 24; 
NLOSS = -0.70622
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6379342035017843/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6379342035017843/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -0.70780 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6379342035017843
Testing time: 0.07
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.4728763479731668
device                   -->   cuda:0
dropout                  -->   0.6817627177706042
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.20483456165863745
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.10289425011879871
grad_accumulated_steps   -->   8
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   68
graph_learn_num_pers     -->   17
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.323632899040063
graph_type               -->   dynamic
hidden_size              -->   81
learning_rate            -->   2.4963224605410437
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.09064569285776436
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2183
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.7753028544082455
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.4370878998651033
sparsity_ratio           -->   0.009746874229749514
task_type                -->   classification
update_adj_ratio         -->   0.4054189308806093
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.11809799984962599
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 81])
encoder.graph_encoders.1.weight: torch.Size([81, 81])
encoder.graph_encoders.2.weight: torch.Size([81, 81])
encoder.graph_encoders.3.weight: torch.Size([81, 7])
graph_learner.weight_tensor: torch.Size([17, 1433])
graph_learner2.weight_tensor: torch.Size([17, 81])
#Parameters = 155500

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 39s <> <> <>
Finished Training: /tmp/iteration_id_0.7753028544082455
Training time: 39.76

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 95; 
NLOSS = 2.28239
ACC = 0.07200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.7753028544082455/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.7753028544082455/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 2.33951 | ACC = 0.09100
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.7753028544082455
Testing time: 0.14
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.0757346682030352
device                   -->   cuda:0
dropout                  -->   0.17641253443679028
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.4140572708846998
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7180080824596486
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   200
graph_learn_num_pers     -->   18
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5234147229266272
graph_type               -->   dynamic
hidden_size              -->   69
learning_rate            -->   5.1247095058621825
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.8067940355867738
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1404
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.7550067074945238
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.32876938789254406
sparsity_ratio           -->   0.4147978455924386
task_type                -->   classification
update_adj_ratio         -->   0.5383917110252154
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8424328283039144
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 69])
encoder.graph_encoders.1.weight: torch.Size([69, 69])
encoder.graph_encoders.2.weight: torch.Size([69, 69])
encoder.graph_encoders.3.weight: torch.Size([69, 7])
graph_learner.weight_tensor: torch.Size([18, 1433])
graph_learner2.weight_tensor: torch.Size([18, 69])
#Parameters = 135918

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 49s <> <> <>
Finished Training: /tmp/iteration_id_0.7550067074945238
Training time: 49.92

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 87; 
NLOSS = -4.28250
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.7550067074945238/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.7550067074945238/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -4.28625 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.7550067074945238
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.46854195284369826
device                   -->   cuda:0
dropout                  -->   0.47726977263891346
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5309079990479713
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5167106154665941
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   4
graph_learn_num_pers     -->   11
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.610305092667424
graph_type               -->   dynamic
hidden_size              -->   178
learning_rate            -->   8.129224926296516
logging                  -->   True
lr_patience              -->   9
lr_reduce_factor         -->   0.7560291756049335
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2215
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.872632016446079
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.4750819243063472
sparsity_ratio           -->   0.48151291129447193
task_type                -->   classification
update_adj_ratio         -->   0.11688299097157873
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.17324828571558892
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 178])
encoder.graph_encoders.1.weight: torch.Size([178, 178])
encoder.graph_encoders.2.weight: torch.Size([178, 178])
encoder.graph_encoders.3.weight: torch.Size([178, 7])
graph_learner.weight_tensor: torch.Size([11, 1433])
graph_learner2.weight_tensor: torch.Size([11, 178])
#Parameters = 337409

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.4728763479731668
device                   -->   cuda:0
dropout                  -->   0.6817627177706042
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.20483456165863745
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.10289425011879871
grad_accumulated_steps   -->   8
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   68
graph_learn_num_pers     -->   17
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.323632899040063
graph_type               -->   dynamic
hidden_size              -->   81
learning_rate            -->   2.4963224605410437
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.09064569285776436
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2183
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.15488872124715625
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.4370878998651033
sparsity_ratio           -->   0.009746874229749514
task_type                -->   classification
update_adj_ratio         -->   0.4054189308806093
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.11809799984962599
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 81])
encoder.graph_encoders.1.weight: torch.Size([81, 81])
encoder.graph_encoders.2.weight: torch.Size([81, 81])
encoder.graph_encoders.3.weight: torch.Size([81, 7])
graph_learner.weight_tensor: torch.Size([17, 1433])
graph_learner2.weight_tensor: torch.Size([17, 81])
#Parameters = 155500

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 02m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.15488872124715625
Training time: 123.43

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 175; 
NLOSS = 2.68781
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.15488872124715625/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 17 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.15488872124715625/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 2.68879 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.15488872124715625
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.7177355189245742
device                   -->   cuda:0
dropout                  -->   0.3907611165914855
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.0009991392174196756
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.1007848987075387
grad_accumulated_steps   -->   10
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   198
graph_learn_num_pers     -->   5
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.04651927579176096
graph_type               -->   dynamic
hidden_size              -->   4
learning_rate            -->   0.7008382201695285
logging                  -->   True
lr_patience              -->   3
lr_reduce_factor         -->   0.4722904737191099
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   3978
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.05753192240517202
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7706507476528152
sparsity_ratio           -->   0.49377345313290133
task_type                -->   classification
update_adj_ratio         -->   0.7465865683530853
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.07422606855127811
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 5 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 5 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 4])
encoder.graph_encoders.1.weight: torch.Size([4, 4])
encoder.graph_encoders.2.weight: torch.Size([4, 7])
graph_learner.weight_tensor: torch.Size([5, 1433])
graph_learner2.weight_tensor: torch.Size([5, 4])
#Parameters = 12961

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 14s <> <> <>
Finished Training: /tmp/iteration_id_0.05753192240517202
Training time: 14.76

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 18; 
NLOSS = 5.53430
ACC = 0.07200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.05753192240517202/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 5 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 5 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.05753192240517202/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 5.53439 | ACC = 0.09100
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.05753192240517202
Testing time: 0.09
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.0635293477100416
device                   -->   cuda:0
dropout                  -->   0.11689415404261727
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.8763231465197452
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.952170037686227
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   162
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.06483977762472193
graph_type               -->   dynamic
hidden_size              -->   144
learning_rate            -->   5.855381174801728
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.19205985265587122
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5183
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5467763234617278
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.5007724517995159
sparsity_ratio           -->   0.6183464952988524
task_type                -->   classification
update_adj_ratio         -->   0.26111644103264653
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.2440715410243669
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 144])
encoder.graph_encoders.1.weight: torch.Size([144, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 144])
#Parameters = 231015

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 16s <> <> <>
Finished Training: /tmp/iteration_id_0.5467763234617278
Training time: 16.86

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 30; 
NLOSS = -3.75072
ACC = 0.11400

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5467763234617278/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5467763234617278/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -3.77338 | ACC = 0.10300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5467763234617278
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5386476822377596
device                   -->   cuda:0
dropout                  -->   0.1394106289536169
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5567133755218616
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.38670554606587904
grad_accumulated_steps   -->   7
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   20
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5474727965786576
graph_type               -->   dynamic
hidden_size              -->   93
learning_rate            -->   9.238223188046087
logging                  -->   True
lr_patience              -->   10
lr_reduce_factor         -->   0.7394918096953689
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8111
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.9165463867840226
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.37767251852420936
sparsity_ratio           -->   0.8669246116651876
task_type                -->   classification
update_adj_ratio         -->   0.6013970163345302
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5734659706255677
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 93])
encoder.graph_encoders.1.weight: torch.Size([93, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 93])
#Parameters = 146128

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 14s <> <> <>
Finished Training: /tmp/iteration_id_0.9165463867840226
Training time: 14.07

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 18; 
NLOSS = 2.45934
ACC = 0.09400

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.9165463867840226/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.9165463867840226/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 2.45840 | ACC = 0.10900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.9165463867840226
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9016998022449557
device                   -->   cuda:0
dropout                  -->   0.6800220262511967
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.9436576737361148
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.23525858289027857
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   5
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   37
graph_learn_num_pers     -->   16
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02630859296040622
graph_type               -->   dynamic
hidden_size              -->   23
learning_rate            -->   6.390731488392662
logging                  -->   True
lr_patience              -->   7
lr_reduce_factor         -->   0.2962119822668635
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2543
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.04936193646445486
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.09252991134451616
sparsity_ratio           -->   0.6905121848505882
task_type                -->   classification
update_adj_ratio         -->   0.56386901371454
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.3335391371846109
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 23])
encoder.graph_encoders.1.weight: torch.Size([23, 23])
encoder.graph_encoders.2.weight: torch.Size([23, 23])
encoder.graph_encoders.3.weight: torch.Size([23, 23])
encoder.graph_encoders.4.weight: torch.Size([23, 7])
graph_learner.weight_tensor: torch.Size([16, 1433])
graph_learner2.weight_tensor: torch.Size([16, 23])
#Parameters = 58003

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9355724707483077
device                   -->   cuda:0
dropout                  -->   0.9432899910327579
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.08724619808727407
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.8926774819342238
grad_accumulated_steps   -->   7
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   110
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.9725603913322926
graph_type               -->   dynamic
hidden_size              -->   63
learning_rate            -->   0.24045280581432182
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.5713984953546215
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1070
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5192873963444091
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9935440837499956
sparsity_ratio           -->   0.23722807582060523
task_type                -->   classification
update_adj_ratio         -->   0.30412349958304763
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.3528282930692235
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 63])
encoder.graph_encoders.1.weight: torch.Size([63, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 63])
#Parameters = 113160

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 10s <> <> <>
Finished Training: /tmp/iteration_id_0.5192873963444091
Training time: 10.76

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 6; 
NLOSS = 7.61657
ACC = 0.13400

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5192873963444091/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5192873963444091/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 7.60495 | ACC = 0.13400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5192873963444091
Testing time: 0.07
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.896991888016023
device                   -->   cuda:0
dropout                  -->   0.26093921984950996
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6952992909529649
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6461002364284164
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   5
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   108
graph_learn_num_pers     -->   10
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.42181200745406155
graph_type               -->   dynamic
hidden_size              -->   53
learning_rate            -->   5.808773343119393
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.8126763155813533
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8108
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.7181048394714192
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.5032867099429099
sparsity_ratio           -->   0.4273170793014709
task_type                -->   classification
update_adj_ratio         -->   0.13897338072148568
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.027538806809113026
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 10 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 10 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 53])
encoder.graph_encoders.1.weight: torch.Size([53, 53])
encoder.graph_encoders.2.weight: torch.Size([53, 53])
encoder.graph_encoders.3.weight: torch.Size([53, 53])
encoder.graph_encoders.4.weight: torch.Size([53, 7])
graph_learner.weight_tensor: torch.Size([10, 1433])
graph_learner2.weight_tensor: torch.Size([10, 53])
#Parameters = 99607

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.18379167576628186
device                   -->   cuda:0
dropout                  -->   0.8496646370215933
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.845204264398709
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.9115367943940174
grad_accumulated_steps   -->   7
grad_clipping            -->   None
graph_hops               -->   8
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   34
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6532246784905422
graph_type               -->   dynamic
hidden_size              -->   85
learning_rate            -->   9.32550603047174
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.3387905627957022
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5778
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.3168801903305132
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.07994221866902662
sparsity_ratio           -->   0.07640925347490679
task_type                -->   classification
update_adj_ratio         -->   0.16525712220331645
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.3876426673868191
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 85])
encoder.graph_encoders.1.weight: torch.Size([85, 85])
encoder.graph_encoders.2.weight: torch.Size([85, 85])
encoder.graph_encoders.3.weight: torch.Size([85, 85])
encoder.graph_encoders.4.weight: torch.Size([85, 85])
encoder.graph_encoders.5.weight: torch.Size([85, 85])
encoder.graph_encoders.6.weight: torch.Size([85, 85])
encoder.graph_encoders.7.weight: torch.Size([85, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 85])
#Parameters = 188520

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.7374490215299017
device                   -->   cuda:0
dropout                  -->   0.4386505943796194
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7404706207332766
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7935413351507584
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   7
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   16
graph_learn_num_pers     -->   2
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5435083179903141
graph_type               -->   dynamic
hidden_size              -->   125
learning_rate            -->   0.3987971032097759
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.13721643755688762
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2956
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.7515941275629532
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9350840508498361
sparsity_ratio           -->   0.16761426491615394
task_type                -->   classification
update_adj_ratio         -->   0.8740141285463484
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.06561174291526983
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 125])
encoder.graph_encoders.1.weight: torch.Size([125, 125])
encoder.graph_encoders.2.weight: torch.Size([125, 125])
encoder.graph_encoders.3.weight: torch.Size([125, 125])
encoder.graph_encoders.4.weight: torch.Size([125, 125])
encoder.graph_encoders.5.weight: torch.Size([125, 125])
encoder.graph_encoders.6.weight: torch.Size([125, 7])
graph_learner.weight_tensor: torch.Size([2, 1433])
graph_learner2.weight_tensor: torch.Size([2, 125])
#Parameters = 261241

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.7355174841950297
device                   -->   cuda:0
dropout                  -->   0.9854006665750543
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.09059779982578975
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.449458028924276
grad_accumulated_steps   -->   10
grad_clipping            -->   None
graph_hops               -->   6
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   76
graph_learn_num_pers     -->   11
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.7081483082604109
graph_type               -->   dynamic
hidden_size              -->   162
learning_rate            -->   2.076701003631485
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.7688394222467452
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   6499
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.22263424554284084
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9539997388205864
sparsity_ratio           -->   0.7328936328915557
task_type                -->   classification
update_adj_ratio         -->   0.2350237415427493
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.4697828635687147
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 162])
encoder.graph_encoders.1.weight: torch.Size([162, 162])
encoder.graph_encoders.2.weight: torch.Size([162, 162])
encoder.graph_encoders.3.weight: torch.Size([162, 162])
encoder.graph_encoders.4.weight: torch.Size([162, 162])
encoder.graph_encoders.5.weight: torch.Size([162, 7])
graph_learner.weight_tensor: torch.Size([11, 1433])
graph_learner2.weight_tensor: torch.Size([11, 162])
#Parameters = 355801

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.7177355189245742
device                   -->   cuda:0
dropout                  -->   0.3907611165914855
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.0009991392174196756
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.1007848987075387
grad_accumulated_steps   -->   10
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   198
graph_learn_num_pers     -->   5
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.04651927579176096
graph_type               -->   dynamic
hidden_size              -->   4
learning_rate            -->   0.7008382201695285
logging                  -->   True
lr_patience              -->   3
lr_reduce_factor         -->   0.4722904737191099
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   3978
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.9030717958945195
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7706507476528152
sparsity_ratio           -->   0.49377345313290133
task_type                -->   classification
update_adj_ratio         -->   0.7465865683530853
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.07422606855127811
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 5 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 5 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 4])
encoder.graph_encoders.1.weight: torch.Size([4, 4])
encoder.graph_encoders.2.weight: torch.Size([4, 7])
graph_learner.weight_tensor: torch.Size([5, 1433])
graph_learner2.weight_tensor: torch.Size([5, 4])
#Parameters = 12961

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 42s <> <> <>
Finished Training: /tmp/iteration_id_0.9030717958945195
Training time: 42.14

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 97; 
NLOSS = 5.58708
ACC = 0.16200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.9030717958945195/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 5 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 5 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.9030717958945195/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 5.58708 | ACC = 0.14900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.9030717958945195
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.0635293477100416
device                   -->   cuda:0
dropout                  -->   0.11689415404261727
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.8763231465197452
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.952170037686227
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   162
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.06483977762472193
graph_type               -->   dynamic
hidden_size              -->   144
learning_rate            -->   5.855381174801728
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.19205985265587122
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5183
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.47104170197856376
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.5007724517995159
sparsity_ratio           -->   0.6183464952988524
task_type                -->   classification
update_adj_ratio         -->   0.26111644103264653
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.2440715410243669
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 144])
encoder.graph_encoders.1.weight: torch.Size([144, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 144])
#Parameters = 231015

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 49s <> <> <>
Finished Training: /tmp/iteration_id_0.47104170197856376
Training time: 49.28

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 82; 
NLOSS = -3.68023
ACC = 0.16200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.47104170197856376/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.47104170197856376/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -3.68076 | ACC = 0.14900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.47104170197856376
Testing time: 0.13
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5386476822377596
device                   -->   cuda:0
dropout                  -->   0.1394106289536169
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5567133755218616
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.38670554606587904
grad_accumulated_steps   -->   7
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   20
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5474727965786576
graph_type               -->   dynamic
hidden_size              -->   93
learning_rate            -->   9.238223188046087
logging                  -->   True
lr_patience              -->   10
lr_reduce_factor         -->   0.7394918096953689
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8111
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6128972861785313
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.37767251852420936
sparsity_ratio           -->   0.8669246116651876
task_type                -->   classification
update_adj_ratio         -->   0.6013970163345302
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5734659706255677
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 93])
encoder.graph_encoders.1.weight: torch.Size([93, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 93])
#Parameters = 146128

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 40s <> <> <>
Finished Training: /tmp/iteration_id_0.6128972861785313
Training time: 40.46

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 89; 
NLOSS = 2.67365
ACC = 0.15600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6128972861785313/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6128972861785313/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 2.67341 | ACC = 0.14400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6128972861785313
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5386476822377596
device                   -->   cuda:0
dropout                  -->   0.1394106289536169
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5567133755218616
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.38670554606587904
grad_accumulated_steps   -->   7
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   20
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5474727965786576
graph_type               -->   dynamic
hidden_size              -->   93
learning_rate            -->   9.238223188046087
logging                  -->   True
lr_patience              -->   10
lr_reduce_factor         -->   0.7394918096953689
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8111
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8127882226988332
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.37767251852420936
sparsity_ratio           -->   0.8669246116651876
task_type                -->   classification
update_adj_ratio         -->   0.6013970163345302
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5734659706255677
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 93])
encoder.graph_encoders.1.weight: torch.Size([93, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 93])
#Parameters = 146128

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 01m 25s <> <> <>
Finished Training: /tmp/iteration_id_0.8127882226988332
Training time: 85.04

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 112; 
NLOSS = 2.76364
ACC = 0.15600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.8127882226988332/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.8127882226988332/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 2.76362 | ACC = 0.14300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.8127882226988332
Testing time: 0.14
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5672347604233462
device                   -->   cuda:0
dropout                  -->   0.3983865679232914
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.3621627814219298
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5912034572380548
grad_accumulated_steps   -->   1
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   114
graph_learn_num_pers     -->   20
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5318719993359028
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   1.8720350063517222
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.44317369917510985
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2642
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.7695715710907561
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.2640676164559079
sparsity_ratio           -->   0.6616078744795302
task_type                -->   classification
update_adj_ratio         -->   0.08234708692438086
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.2143447209984215
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 30])
encoder.graph_encoders.2.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([20, 1433])
graph_learner2.weight_tensor: torch.Size([20, 30])
#Parameters = 73360

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 56s <> <> <>
Finished Training: /tmp/iteration_id_0.7695715710907561
Training time: 56.61

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 70; 
NLOSS = 3.25685
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.7695715710907561/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.7695715710907561/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 3.25951 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.7695715710907561
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.3211514945772802
device                   -->   cuda:0
dropout                  -->   0.17306214774508033
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.21591654694895124
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5535051651802104
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   7
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   176
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.13976853520455312
graph_type               -->   dynamic
hidden_size              -->   104
learning_rate            -->   2.8128583189250578
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.8635194326196955
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   183
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.07843795469972215
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9347470457546505
sparsity_ratio           -->   0.7249511386831209
task_type                -->   classification
update_adj_ratio         -->   0.7700458906652918
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.7152282770166923
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 104])
encoder.graph_encoders.1.weight: torch.Size([104, 104])
encoder.graph_encoders.2.weight: torch.Size([104, 104])
encoder.graph_encoders.3.weight: torch.Size([104, 104])
encoder.graph_encoders.4.weight: torch.Size([104, 104])
encoder.graph_encoders.5.weight: torch.Size([104, 104])
encoder.graph_encoders.6.weight: torch.Size([104, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 104])
#Parameters = 205377

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 32s <> <> <>
Finished Training: /tmp/iteration_id_0.07843795469972215
Training time: 32.63

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 19; 
NLOSS = -11.77757
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.07843795469972215/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.07843795469972215/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -11.80507 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.07843795469972215
Testing time: 0.09
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.0662169809674612
device                   -->   cuda:0
dropout                  -->   0.8678663381470475
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.2407126692936341
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.3761236412015919
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   9
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   115
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.14572331208860378
graph_type               -->   dynamic
hidden_size              -->   138
learning_rate            -->   6.581957837353288
logging                  -->   True
lr_patience              -->   9
lr_reduce_factor         -->   0.6451617872070387
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5206
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.3468913092970918
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7699280691395528
sparsity_ratio           -->   0.01818989922522518
task_type                -->   classification
update_adj_ratio         -->   0.09127763769499075
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5998595048056345
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 138])
encoder.graph_encoders.1.weight: torch.Size([138, 138])
encoder.graph_encoders.2.weight: torch.Size([138, 138])
encoder.graph_encoders.3.weight: torch.Size([138, 138])
encoder.graph_encoders.4.weight: torch.Size([138, 138])
encoder.graph_encoders.5.weight: torch.Size([138, 138])
encoder.graph_encoders.6.weight: torch.Size([138, 138])
encoder.graph_encoders.7.weight: torch.Size([138, 138])
encoder.graph_encoders.8.weight: torch.Size([138, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 138])
#Parameters = 355593

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.2914012154397513
device                   -->   cuda:0
dropout                  -->   0.08569089559521159
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.22720587423524308
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.9913312230326886
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   8
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   1
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.3151348252419992
graph_type               -->   dynamic
hidden_size              -->   163
learning_rate            -->   4.085414790885487
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.6321623391457267
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   837
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8017766316252234
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.793162197507831
sparsity_ratio           -->   0.540147279765088
task_type                -->   classification
update_adj_ratio         -->   0.7988802640687869
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.21012023134407565
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 163])
encoder.graph_encoders.1.weight: torch.Size([163, 163])
encoder.graph_encoders.2.weight: torch.Size([163, 163])
encoder.graph_encoders.3.weight: torch.Size([163, 163])
encoder.graph_encoders.4.weight: torch.Size([163, 163])
encoder.graph_encoders.5.weight: torch.Size([163, 163])
encoder.graph_encoders.6.weight: torch.Size([163, 163])
encoder.graph_encoders.7.weight: torch.Size([163, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 163])
#Parameters = 418074

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 01m 14s <> <> <>
Finished Training: /tmp/iteration_id_0.8017766316252234
Training time: 74.17

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 63; 
NLOSS = -61542536.00000
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.8017766316252234/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.8017766316252234/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -85535168.00000 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.8017766316252234
Testing time: 0.26
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.8210336615446311
device                   -->   cuda:0
dropout                  -->   0.8399860545653289
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.8758522694557322
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7102384431090367
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   5
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   162
graph_learn_num_pers     -->   4
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.19946985424385333
graph_type               -->   dynamic
hidden_size              -->   166
learning_rate            -->   8.789489494919277
logging                  -->   True
lr_patience              -->   7
lr_reduce_factor         -->   0.9063931554438278
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2742
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.0065618561735036884
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.1601197794616518
sparsity_ratio           -->   0.1921338981104186
task_type                -->   classification
update_adj_ratio         -->   0.5867469186769597
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6332286993331503
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 4 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 4 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 166])
encoder.graph_encoders.1.weight: torch.Size([166, 166])
encoder.graph_encoders.2.weight: torch.Size([166, 166])
encoder.graph_encoders.3.weight: torch.Size([166, 166])
encoder.graph_encoders.4.weight: torch.Size([166, 7])
graph_learner.weight_tensor: torch.Size([4, 1433])
graph_learner2.weight_tensor: torch.Size([4, 166])
#Parameters = 328104

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.07375447530132384
device                   -->   cuda:0
dropout                  -->   0.973372308790313
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5050433868526739
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.462188153486931
grad_accumulated_steps   -->   7
grad_clipping            -->   None
graph_hops               -->   8
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   26
graph_learn_num_pers     -->   11
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6157906279882074
graph_type               -->   dynamic
hidden_size              -->   119
learning_rate            -->   4.732534295168463
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.27915887677890383
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   189
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.1429986977519615
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.4512315340687647
sparsity_ratio           -->   0.43444701947314446
task_type                -->   classification
update_adj_ratio         -->   0.3524156702428324
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.33394276397555855
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 119])
encoder.graph_encoders.1.weight: torch.Size([119, 119])
encoder.graph_encoders.2.weight: torch.Size([119, 119])
encoder.graph_encoders.3.weight: torch.Size([119, 119])
encoder.graph_encoders.4.weight: torch.Size([119, 119])
encoder.graph_encoders.5.weight: torch.Size([119, 119])
encoder.graph_encoders.6.weight: torch.Size([119, 119])
encoder.graph_encoders.7.weight: torch.Size([119, 7])
graph_learner.weight_tensor: torch.Size([11, 1433])
graph_learner2.weight_tensor: torch.Size([11, 119])
#Parameters = 273398

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 36s <> <> <>
Finished Training: /tmp/iteration_id_0.1429986977519615
Training time: 36.28

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 18; 
NLOSS = -6.01397
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.1429986977519615/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 11 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.1429986977519615/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -6.02777 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.1429986977519615
Testing time: 0.07
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5672347604233462
device                   -->   cuda:0
dropout                  -->   0.3983865679232914
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.3621627814219298
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5912034572380548
grad_accumulated_steps   -->   1
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   114
graph_learn_num_pers     -->   20
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5318719993359028
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   1.8720350063517222
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.44317369917510985
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2642
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.20072285444622406
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.2640676164559079
sparsity_ratio           -->   0.6616078744795302
task_type                -->   classification
update_adj_ratio         -->   0.08234708692438086
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.2143447209984215
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 30])
encoder.graph_encoders.2.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([20, 1433])
graph_learner2.weight_tensor: torch.Size([20, 30])
#Parameters = 73360

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 02m 46s <> <> <>
Finished Training: /tmp/iteration_id_0.20072285444622406
Training time: 166.31

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 238; 
NLOSS = 3.31864
ACC = 0.08200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.20072285444622406/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.20072285444622406/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 3.32384 | ACC = 0.10300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.20072285444622406
Testing time: 0.13
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.3211514945772802
device                   -->   cuda:0
dropout                  -->   0.17306214774508033
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.21591654694895124
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5535051651802104
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   7
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   176
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.13976853520455312
graph_type               -->   dynamic
hidden_size              -->   104
learning_rate            -->   2.8128583189250578
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.8635194326196955
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   183
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8465084363084837
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9347470457546505
sparsity_ratio           -->   0.7249511386831209
task_type                -->   classification
update_adj_ratio         -->   0.7700458906652918
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.7152282770166923
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 104])
encoder.graph_encoders.1.weight: torch.Size([104, 104])
encoder.graph_encoders.2.weight: torch.Size([104, 104])
encoder.graph_encoders.3.weight: torch.Size([104, 104])
encoder.graph_encoders.4.weight: torch.Size([104, 104])
encoder.graph_encoders.5.weight: torch.Size([104, 104])
encoder.graph_encoders.6.weight: torch.Size([104, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 104])
#Parameters = 205377

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 50s <> <> <>
Finished Training: /tmp/iteration_id_0.8465084363084837
Training time: 50.33

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 19; 
NLOSS = -11.77757
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.8465084363084837/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.8465084363084837/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -11.80417 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.8465084363084837
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.19734984831420066
device                   -->   cuda:0
dropout                  -->   0.9353874957021797
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5037846593895546
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.10313146763989778
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   8
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   46
graph_learn_num_pers     -->   19
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.8310187065017791
graph_type               -->   dynamic
hidden_size              -->   70
learning_rate            -->   1.3613312236220132
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.958138382201023
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5765
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.18805576852353156
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.3032187517318763
sparsity_ratio           -->   0.9904593342674104
task_type                -->   classification
update_adj_ratio         -->   0.2766125300181149
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6179600643296613
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 19 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 19 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 70])
encoder.graph_encoders.1.weight: torch.Size([70, 70])
encoder.graph_encoders.2.weight: torch.Size([70, 70])
encoder.graph_encoders.3.weight: torch.Size([70, 70])
encoder.graph_encoders.4.weight: torch.Size([70, 70])
encoder.graph_encoders.5.weight: torch.Size([70, 70])
encoder.graph_encoders.6.weight: torch.Size([70, 70])
encoder.graph_encoders.7.weight: torch.Size([70, 7])
graph_learner.weight_tensor: torch.Size([19, 1433])
graph_learner2.weight_tensor: torch.Size([19, 70])
#Parameters = 158757

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.8265350160323921
device                   -->   cuda:0
dropout                  -->   0.6706196043996628
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5141968845437479
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.20052386515665588
grad_accumulated_steps   -->   9
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   134
graph_learn_num_pers     -->   3
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.44767516798282836
graph_type               -->   dynamic
hidden_size              -->   101
learning_rate            -->   6.790706333247668
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.4494329337855858
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2002
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.28418661970439496
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.2188654204147158
sparsity_ratio           -->   0.9627264416448678
task_type                -->   classification
update_adj_ratio         -->   0.6697800174978513
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.396579576441878
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 101])
encoder.graph_encoders.1.weight: torch.Size([101, 101])
encoder.graph_encoders.2.weight: torch.Size([101, 101])
encoder.graph_encoders.3.weight: torch.Size([101, 7])
graph_learner.weight_tensor: torch.Size([3, 1433])
graph_learner2.weight_tensor: torch.Size([3, 101])
#Parameters = 170444

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 43s <> <> <>
Finished Training: /tmp/iteration_id_0.28418661970439496
Training time: 43.66

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 40; 
NLOSS = -21.86447
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.28418661970439496/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.28418661970439496/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -21.87956 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.28418661970439496
Testing time: 0.09
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9134041507783164
device                   -->   cuda:0
dropout                  -->   0.473193973745208
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.8129605118802397
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.13287134238478204
grad_accumulated_steps   -->   3
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   182
graph_learn_num_pers     -->   12
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.21598732447831848
graph_type               -->   dynamic
hidden_size              -->   106
learning_rate            -->   7.737829925902617
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.231588924175249
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   7678
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.11150530343556664
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.2092208117059592
sparsity_ratio           -->   0.032690317721711715
task_type                -->   classification
update_adj_ratio         -->   0.7282286790590028
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9263069918473633
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 12 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 12 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 106])
encoder.graph_encoders.1.weight: torch.Size([106, 106])
encoder.graph_encoders.2.weight: torch.Size([106, 106])
encoder.graph_encoders.3.weight: torch.Size([106, 106])
encoder.graph_encoders.4.weight: torch.Size([106, 106])
encoder.graph_encoders.5.weight: torch.Size([106, 106])
encoder.graph_encoders.6.weight: torch.Size([106, 106])
encoder.graph_encoders.7.weight: torch.Size([106, 106])
encoder.graph_encoders.8.weight: torch.Size([106, 106])
encoder.graph_encoders.9.weight: torch.Size([106, 7])
graph_learner.weight_tensor: torch.Size([12, 1433])
graph_learner2.weight_tensor: torch.Size([12, 106])
#Parameters = 260996

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.667646781258026
device                   -->   cuda:0
dropout                  -->   0.5492709986331462
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.10957079544458126
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.9410980516184365
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   177
graph_learn_num_pers     -->   2
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.7916167820087138
graph_type               -->   dynamic
hidden_size              -->   53
learning_rate            -->   8.43369814318982
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.7946735601975123
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   782
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6556534336394114
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.32902986237777687
sparsity_ratio           -->   0.0018199781715153573
task_type                -->   classification
update_adj_ratio         -->   0.71252913587658
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.09968457304121225
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 53])
encoder.graph_encoders.1.weight: torch.Size([53, 53])
encoder.graph_encoders.2.weight: torch.Size([53, 53])
encoder.graph_encoders.3.weight: torch.Size([53, 53])
encoder.graph_encoders.4.weight: torch.Size([53, 53])
encoder.graph_encoders.5.weight: torch.Size([53, 53])
encoder.graph_encoders.6.weight: torch.Size([53, 53])
encoder.graph_encoders.7.weight: torch.Size([53, 53])
encoder.graph_encoders.8.weight: torch.Size([53, 53])
encoder.graph_encoders.9.weight: torch.Size([53, 7])
graph_learner.weight_tensor: torch.Size([2, 1433])
graph_learner2.weight_tensor: torch.Size([2, 53])
#Parameters = 101764

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 59s <> <> <>
Finished Training: /tmp/iteration_id_0.6556534336394114
Training time: 59.94

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 80; 
NLOSS = -18.73780
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6556534336394114/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 2 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6556534336394114/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -18.76496 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6556534336394114
Testing time: 0.09
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.8726407914912268
device                   -->   cuda:0
dropout                  -->   0.018720973662931573
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.3691892799480825
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7334638148988569
grad_accumulated_steps   -->   2
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   13
graph_learn_num_pers     -->   9
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5556026082576575
graph_type               -->   dynamic
hidden_size              -->   167
learning_rate            -->   5.454520556546162
logging                  -->   True
lr_patience              -->   8
lr_reduce_factor         -->   0.8877784877728194
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   457
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.10621462839421547
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7258664905012485
sparsity_ratio           -->   0.4399932658607627
task_type                -->   classification
update_adj_ratio         -->   0.690104347601642
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.34029174166255105
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 167])
encoder.graph_encoders.1.weight: torch.Size([167, 167])
encoder.graph_encoders.2.weight: torch.Size([167, 167])
encoder.graph_encoders.3.weight: torch.Size([167, 167])
encoder.graph_encoders.4.weight: torch.Size([167, 167])
encoder.graph_encoders.5.weight: torch.Size([167, 167])
encoder.graph_encoders.6.weight: torch.Size([167, 167])
encoder.graph_encoders.7.weight: torch.Size([167, 167])
encoder.graph_encoders.8.weight: torch.Size([167, 167])
encoder.graph_encoders.9.weight: torch.Size([167, 7])
graph_learner.weight_tensor: torch.Size([9, 1433])
graph_learner2.weight_tensor: torch.Size([9, 167])
#Parameters = 477992

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 07s <> <> <>
Finished Training: /tmp/iteration_id_0.10621462839421547
Training time: 7.37

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 11; 
NLOSS = -23.76500
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.10621462839421547/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.10621462839421547/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -23.76582 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.10621462839421547
Testing time: 0.09
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5485217403380984
device                   -->   cuda:0
dropout                  -->   0.8828655779646547
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.4590830399307442
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5690979924471609
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   6
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   34
graph_learn_num_pers     -->   10
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.650189076156208
graph_type               -->   dynamic
hidden_size              -->   98
learning_rate            -->   6.032982087787447
logging                  -->   True
lr_patience              -->   10
lr_reduce_factor         -->   0.6566462696125139
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   3441
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.4687034589593363
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.29794683984432213
sparsity_ratio           -->   0.6224891591503114
task_type                -->   classification
update_adj_ratio         -->   0.9626336101151587
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.08971777842438045
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 10 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 10 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 98])
encoder.graph_encoders.1.weight: torch.Size([98, 98])
encoder.graph_encoders.2.weight: torch.Size([98, 98])
encoder.graph_encoders.3.weight: torch.Size([98, 98])
encoder.graph_encoders.4.weight: torch.Size([98, 98])
encoder.graph_encoders.5.weight: torch.Size([98, 7])
graph_learner.weight_tensor: torch.Size([10, 1433])
graph_learner2.weight_tensor: torch.Size([10, 98])
#Parameters = 194846

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.22697867217415135
device                   -->   cuda:0
dropout                  -->   0.7164706918901458
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.47614677481972323
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7205992248037817
grad_accumulated_steps   -->   9
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   177
graph_learn_num_pers     -->   18
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.8920893882168243
graph_type               -->   dynamic
hidden_size              -->   96
learning_rate            -->   5.480218358591048
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.7519226629978286
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2957
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.20906389248501323
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.27065657188027004
sparsity_ratio           -->   0.49084824993006815
task_type                -->   classification
update_adj_ratio         -->   0.8930272262308943
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6730698571097273
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 18 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 96])
encoder.graph_encoders.1.weight: torch.Size([96, 96])
encoder.graph_encoders.2.weight: torch.Size([96, 96])
encoder.graph_encoders.3.weight: torch.Size([96, 96])
encoder.graph_encoders.4.weight: torch.Size([96, 96])
encoder.graph_encoders.5.weight: torch.Size([96, 96])
encoder.graph_encoders.6.weight: torch.Size([96, 96])
encoder.graph_encoders.7.weight: torch.Size([96, 96])
encoder.graph_encoders.8.weight: torch.Size([96, 96])
encoder.graph_encoders.9.weight: torch.Size([96, 7])
graph_learner.weight_tensor: torch.Size([18, 1433])
graph_learner2.weight_tensor: torch.Size([18, 96])
#Parameters = 239490

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.06038870937510299
device                   -->   cuda:0
dropout                  -->   0.9353485930562593
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.20807352875438867
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.4758417432562638
grad_accumulated_steps   -->   3
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   176
graph_learn_num_pers     -->   9
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.7041824674257496
graph_type               -->   dynamic
hidden_size              -->   131
learning_rate            -->   2.4448718065766717
logging                  -->   True
lr_patience              -->   10
lr_reduce_factor         -->   0.21916898554831665
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   9394
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.15508046465952852
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9487513641229371
sparsity_ratio           -->   0.5305603853265933
task_type                -->   classification
update_adj_ratio         -->   0.7531430047369362
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.720560126675187
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 131])
encoder.graph_encoders.1.weight: torch.Size([131, 131])
encoder.graph_encoders.2.weight: torch.Size([131, 131])
encoder.graph_encoders.3.weight: torch.Size([131, 7])
graph_learner.weight_tensor: torch.Size([9, 1433])
graph_learner2.weight_tensor: torch.Size([9, 131])
#Parameters = 237038

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.04961727010423489
device                   -->   cuda:0
dropout                  -->   0.03724368827656044
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.34829220784181714
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.8836634586388572
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   4
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   63
graph_learn_num_pers     -->   16
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.8473295445598333
graph_type               -->   dynamic
hidden_size              -->   116
learning_rate            -->   4.9111554334976475
logging                  -->   True
lr_patience              -->   9
lr_reduce_factor         -->   0.5537316226516266
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   6924
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6271550816853765
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9341557465639742
sparsity_ratio           -->   0.6111128785337502
task_type                -->   classification
update_adj_ratio         -->   0.3364966086825728
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.1532077506657753
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 116])
encoder.graph_encoders.1.weight: torch.Size([116, 116])
encoder.graph_encoders.2.weight: torch.Size([116, 116])
encoder.graph_encoders.3.weight: torch.Size([116, 7])
graph_learner.weight_tensor: torch.Size([16, 1433])
graph_learner2.weight_tensor: torch.Size([16, 116])
#Parameters = 218736

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.2598712859291866
device                   -->   cuda:0
dropout                  -->   0.040933283323188685
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.91054583368209
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.666621579276667
grad_accumulated_steps   -->   10
grad_clipping            -->   None
graph_hops               -->   5
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   92
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.704921073948744
graph_type               -->   dynamic
hidden_size              -->   7
learning_rate            -->   3.647104266688358
logging                  -->   True
lr_patience              -->   7
lr_reduce_factor         -->   0.7326895120649656
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   9472
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8259507325847065
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.054139521985320016
sparsity_ratio           -->   0.4080329606159734
task_type                -->   classification
update_adj_ratio         -->   0.7149640537153258
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9359930363445156
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 7])
encoder.graph_encoders.1.weight: torch.Size([7, 7])
encoder.graph_encoders.2.weight: torch.Size([7, 7])
encoder.graph_encoders.3.weight: torch.Size([7, 7])
encoder.graph_encoders.4.weight: torch.Size([7, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 7])
#Parameters = 21747

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.4440877740225987
device                   -->   cuda:0
dropout                  -->   0.4827474751600985
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.023604569308076084
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.26902384467134943
grad_accumulated_steps   -->   10
grad_clipping            -->   None
graph_hops               -->   10
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   144
graph_learn_num_pers     -->   20
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.4486216223464772
graph_type               -->   dynamic
hidden_size              -->   198
learning_rate            -->   2.860788100973336
logging                  -->   True
lr_patience              -->   7
lr_reduce_factor         -->   0.058717180923229306
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   196
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.07486730595022062
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.10162277800132014
sparsity_ratio           -->   0.5886578733195372
task_type                -->   classification
update_adj_ratio         -->   0.2764534402178035
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.7968844871441115
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 198])
encoder.graph_encoders.1.weight: torch.Size([198, 198])
encoder.graph_encoders.2.weight: torch.Size([198, 198])
encoder.graph_encoders.3.weight: torch.Size([198, 198])
encoder.graph_encoders.4.weight: torch.Size([198, 198])
encoder.graph_encoders.5.weight: torch.Size([198, 198])
encoder.graph_encoders.6.weight: torch.Size([198, 198])
encoder.graph_encoders.7.weight: torch.Size([198, 198])
encoder.graph_encoders.8.weight: torch.Size([198, 198])
encoder.graph_encoders.9.weight: torch.Size([198, 7])
graph_learner.weight_tensor: torch.Size([20, 1433])
graph_learner2.weight_tensor: torch.Size([20, 198])
#Parameters = 631372

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 08s <> <> <>
Finished Training: /tmp/iteration_id_0.07486730595022062
Training time: 8.24

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 11; 
NLOSS = -14.54490
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.07486730595022062/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 20 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.07486730595022062/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -14.59823 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.07486730595022062
Testing time: 0.09
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.4799875042827523
device                   -->   cuda:0
dropout                  -->   0.012012731623819883
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.9707378727128833
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.20067961297246129
grad_accumulated_steps   -->   1
grad_clipping            -->   None
graph_hops               -->   5
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   76
graph_learn_num_pers     -->   3
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.820491656797512
graph_type               -->   dynamic
hidden_size              -->   133
learning_rate            -->   4.08998405886222
logging                  -->   True
lr_patience              -->   3
lr_reduce_factor         -->   0.3114828726907162
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   3745
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.06756387504390582
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.23139724565848585
sparsity_ratio           -->   0.9928074876858829
task_type                -->   classification
update_adj_ratio         -->   0.2801705037028921
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9466723595462762
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 133])
encoder.graph_encoders.1.weight: torch.Size([133, 133])
encoder.graph_encoders.2.weight: torch.Size([133, 133])
encoder.graph_encoders.3.weight: torch.Size([133, 133])
encoder.graph_encoders.4.weight: torch.Size([133, 7])
graph_learner.weight_tensor: torch.Size([3, 1433])
graph_learner2.weight_tensor: torch.Size([3, 133])
#Parameters = 249285

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.2056965520132319
device                   -->   cuda:0
dropout                  -->   0.08890495062295767
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.9270315958842625
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.24274655823457802
grad_accumulated_steps   -->   7
grad_clipping            -->   None
graph_hops               -->   6
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   46
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.7112031826594293
graph_type               -->   dynamic
hidden_size              -->   75
learning_rate            -->   8.746034344778558
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.5678970522807314
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8138
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.27963424179019547
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.061918839571673656
sparsity_ratio           -->   0.9612856105524519
task_type                -->   classification
update_adj_ratio         -->   0.31668950754110514
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.151970900297823
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 75])
encoder.graph_encoders.1.weight: torch.Size([75, 75])
encoder.graph_encoders.2.weight: torch.Size([75, 75])
encoder.graph_encoders.3.weight: torch.Size([75, 75])
encoder.graph_encoders.4.weight: torch.Size([75, 75])
encoder.graph_encoders.5.weight: torch.Size([75, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 75])
#Parameters = 142564

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.3712736210472939
device                   -->   cuda:0
dropout                  -->   0.16429909663332198
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.028603803338515976
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6652904307611729
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   5
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   146
graph_learn_num_pers     -->   5
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.13762199967376343
graph_type               -->   dynamic
hidden_size              -->   62
learning_rate            -->   9.156836030625655
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.23708809759524863
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   487
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6087229076415399
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.9123221182386246
sparsity_ratio           -->   0.6261182005366216
task_type                -->   classification
update_adj_ratio         -->   0.9764359095500287
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9396662696936503
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 5 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 5 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 62])
encoder.graph_encoders.1.weight: torch.Size([62, 62])
encoder.graph_encoders.2.weight: torch.Size([62, 62])
encoder.graph_encoders.3.weight: torch.Size([62, 62])
encoder.graph_encoders.4.weight: torch.Size([62, 7])
graph_learner.weight_tensor: torch.Size([5, 1433])
graph_learner2.weight_tensor: torch.Size([5, 62])
#Parameters = 108287

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 06s <> <> <>
Finished Training: /tmp/iteration_id_0.6087229076415399
Training time: 6.19

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 9; 
NLOSS = -12.41874
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6087229076415399/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 5 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 5 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6087229076415399/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -12.41008 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6087229076415399
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9881360821746776
device                   -->   cuda:0
dropout                  -->   0.09312645881615356
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5842242901175959
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.707559636461572
grad_accumulated_steps   -->   9
grad_clipping            -->   None
graph_hops               -->   9
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   153
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.909648849015019
graph_type               -->   dynamic
hidden_size              -->   109
learning_rate            -->   4.751322925893654
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.5212200347331167
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2463
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.4891501565708024
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.5912295814804884
sparsity_ratio           -->   0.8649013308854157
task_type                -->   classification
update_adj_ratio         -->   0.006556625691121698
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.35067648388190187
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 109])
encoder.graph_encoders.1.weight: torch.Size([109, 109])
encoder.graph_encoders.2.weight: torch.Size([109, 109])
encoder.graph_encoders.3.weight: torch.Size([109, 109])
encoder.graph_encoders.4.weight: torch.Size([109, 109])
encoder.graph_encoders.5.weight: torch.Size([109, 109])
encoder.graph_encoders.6.weight: torch.Size([109, 109])
encoder.graph_encoders.7.weight: torch.Size([109, 109])
encoder.graph_encoders.8.weight: torch.Size([109, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 109])
#Parameters = 263257

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5232332169404652
device                   -->   cuda:0
dropout                  -->   0.8847419577496412
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7882770817542746
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.14966102100635395
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   151
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5188113146118172
graph_type               -->   dynamic
hidden_size              -->   152
learning_rate            -->   9.04441181559876
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.8431746608865426
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1325
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6968624506937654
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.8375415103851143
sparsity_ratio           -->   0.1005616298589147
task_type                -->   classification
update_adj_ratio         -->   0.44612974207484457
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.835140463774466
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 152])
encoder.graph_encoders.1.weight: torch.Size([152, 152])
encoder.graph_encoders.2.weight: torch.Size([152, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 152])
#Parameters = 243569

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 04s <> <> <>
Finished Training: /tmp/iteration_id_0.6968624506937654
Training time: 4.93

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = -56.17018
ACC = 0.16200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6968624506937654/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6968624506937654/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -57.05328 | ACC = 0.14700
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6968624506937654
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5207516145122854
device                   -->   cuda:0
dropout                  -->   0.8849357402264613
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7885162738356897
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.149486822486794
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   151
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5152084510334161
graph_type               -->   dynamic
hidden_size              -->   152
learning_rate            -->   8.994359138418623
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.841953757547187
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1359
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.22718955524378515
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.8380177002285719
sparsity_ratio           -->   0.10671782550822458
task_type                -->   classification
update_adj_ratio         -->   0.4520473377414428
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8341874143868436
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 152])
encoder.graph_encoders.1.weight: torch.Size([152, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 152])
#Parameters = 220465

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.22718955524378515
Training time: 3.89

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 2.55823
ACC = 0.07200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.22718955524378515/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.22718955524378515/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 2.58947 | ACC = 0.09100
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.22718955524378515
Testing time: 0.07
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5220163088703526
device                   -->   cuda:0
dropout                  -->   0.8855054575456711
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.78840927716715
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.1496968327670441
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   151
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5150518168611351
graph_type               -->   dynamic
hidden_size              -->   152
learning_rate            -->   8.993818527813698
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.8431591080170799
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1394
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6889114093343485
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.8366848744536816
sparsity_ratio           -->   0.10515984286389954
task_type                -->   classification
update_adj_ratio         -->   0.4469063321577583
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8402545378361725
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 152])
encoder.graph_encoders.1.weight: torch.Size([152, 152])
encoder.graph_encoders.2.weight: torch.Size([152, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 152])
#Parameters = 243569

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 04s <> <> <>
Finished Training: /tmp/iteration_id_0.6889114093343485
Training time: 4.47

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = -507.27591
ACC = 0.07200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6889114093343485/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6889114093343485/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -483.18134 | ACC = 0.09100
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6889114093343485
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5212852685458754
device                   -->   cuda:0
dropout                  -->   0.885151636785618
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7884542515890705
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.14971276686661095
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   151
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5035851055828588
graph_type               -->   dynamic
hidden_size              -->   152
learning_rate            -->   8.976453063046575
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.8401964394056327
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1355
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.866570343740665
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.8364703900341206
sparsity_ratio           -->   0.10342195465611126
task_type                -->   classification
update_adj_ratio         -->   0.45486082859193916
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8425058799417899
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 152])
encoder.graph_encoders.1.weight: torch.Size([152, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 152])
#Parameters = 220465

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.866570343740665
Training time: 3.73

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 2.62360
ACC = 0.07200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.866570343740665/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.866570343740665/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 2.64912 | ACC = 0.09100
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.866570343740665
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5196198635217072
device                   -->   cuda:0
dropout                  -->   0.8849345309435767
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7884394412071065
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.14965671378596296
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   151
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5029727144103088
graph_type               -->   dynamic
hidden_size              -->   152
learning_rate            -->   8.963273163256396
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.8411529446898663
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1466
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6274890406068646
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.8367298521291947
sparsity_ratio           -->   0.10424714782622783
task_type                -->   classification
update_adj_ratio         -->   0.45492785494392435
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8420895919743221
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 152])
encoder.graph_encoders.1.weight: torch.Size([152, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 152])
#Parameters = 220465

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.6274890406068646
Training time: 3.78

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 2.66513
ACC = 0.09800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6274890406068646/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6274890406068646/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 2.68442 | ACC = 0.10300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6274890406068646
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5177948880603932
device                   -->   cuda:0
dropout                  -->   0.884928367462412
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7884750476397498
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.14948761622351808
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   151
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5011774371164263
graph_type               -->   dynamic
hidden_size              -->   152
learning_rate            -->   8.953376285087625
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.8408351441747448
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1480
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.36316546788559445
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.8368320990417613
sparsity_ratio           -->   0.1029490743363906
task_type                -->   classification
update_adj_ratio         -->   0.4552740999168136
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8416499530736956
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 152])
encoder.graph_encoders.1.weight: torch.Size([152, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 152])
#Parameters = 220465

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.36316546788559445
Training time: 3.95

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 2.62561
ACC = 0.07200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.36316546788559445/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.36316546788559445/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 2.64892 | ACC = 0.09200
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.36316546788559445
Testing time: 0.08
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5159857151231981
device                   -->   cuda:0
dropout                  -->   0.8850706783027723
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7885025911242463
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.1493097087856909
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   151
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.4959942454122745
graph_type               -->   dynamic
hidden_size              -->   152
learning_rate            -->   8.955925743710829
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.840240601783868
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1504
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.44741046122124495
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.8357589029441028
sparsity_ratio           -->   0.10094094936274224
task_type                -->   classification
update_adj_ratio         -->   0.461083401775576
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8421473196620535
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 152])
encoder.graph_encoders.1.weight: torch.Size([152, 152])
encoder.graph_encoders.2.weight: torch.Size([152, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 152])
#Parameters = 243569

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 05s <> <> <>
Finished Training: /tmp/iteration_id_0.44741046122124495
Training time: 5.24

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 8; 
NLOSS = -379.58832
ACC = 0.15600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.44741046122124495/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.44741046122124495/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -392.52197 | ACC = 0.14300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.44741046122124495
Testing time: 0.07
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5144349404353892
device                   -->   cuda:0
dropout                  -->   0.8848907505223469
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7884766015322777
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.14932111140160412
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   151
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.4958730621393813
graph_type               -->   dynamic
hidden_size              -->   152
learning_rate            -->   8.970667600677535
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.8422953179935785
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1625
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8405071302155618
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.835489296041284
sparsity_ratio           -->   0.09311691329600551
task_type                -->   classification
update_adj_ratio         -->   0.461794339325243
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.841785188163519
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 152])
encoder.graph_encoders.1.weight: torch.Size([152, 152])
encoder.graph_encoders.2.weight: torch.Size([152, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 152])
#Parameters = 243569

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 05s <> <> <>
Finished Training: /tmp/iteration_id_0.8405071302155618
Training time: 5.36

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 8; 
NLOSS = -227.51529
ACC = 0.12000

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.8405071302155618/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.8405071302155618/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -224.80215 | ACC = 0.10800
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.8405071302155618
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.48805249719807026
device                   -->   cuda:0
dropout                  -->   0.7457818528279212
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.4866626161439457
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6206106634225451
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   154
graph_learn_num_pers     -->   7
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.03516787346371414
graph_type               -->   dynamic
hidden_size              -->   123
learning_rate            -->   1.8789579183118428
logging                  -->   True
lr_patience              -->   10
lr_reduce_factor         -->   0.957949376103594
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8044
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.7962715778317466
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.3473278003749787
sparsity_ratio           -->   0.016900818925685457
task_type                -->   classification
update_adj_ratio         -->   0.9208535197984647
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.511862309469949
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 123])
encoder.graph_encoders.1.weight: torch.Size([123, 7])
graph_learner.weight_tensor: torch.Size([7, 1433])
graph_learner2.weight_tensor: torch.Size([7, 123])
#Parameters = 188012

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 05s <> <> <>
Finished Training: /tmp/iteration_id_0.7962715778317466
Training time: 5.39

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 2.69058
ACC = 0.16200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.7962715778317466/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.7962715778317466/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 2.68961 | ACC = 0.14900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.7962715778317466
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.37118728659334843
device                   -->   cuda:0
dropout                  -->   0.08181963502477328
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.2728712009156701
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5598323184240673
grad_accumulated_steps   -->   8
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   100
graph_learn_num_pers     -->   6
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.7057885806407889
graph_type               -->   dynamic
hidden_size              -->   136
learning_rate            -->   6.408148006832926
logging                  -->   True
lr_patience              -->   3
lr_reduce_factor         -->   0.8861122007201129
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   287
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.1475387297855476
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.1640850358902295
sparsity_ratio           -->   0.43107482001993713
task_type                -->   classification
update_adj_ratio         -->   0.20554683616114944
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9660775926112168
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 6 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 6 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 136])
encoder.graph_encoders.1.weight: torch.Size([136, 7])
graph_learner.weight_tensor: torch.Size([6, 1433])
graph_learner2.weight_tensor: torch.Size([6, 136])
#Parameters = 205254

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.1475387297855476
Training time: 3.77

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 8; 
NLOSS = -21.39699
ACC = 0.08600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.1475387297855476/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 6 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 6 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.1475387297855476/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -20.88511 | ACC = 0.12400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.1475387297855476
Testing time: 0.04
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.517654251348435
device                   -->   cuda:0
dropout                  -->   0.11024753065517934
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.37129639124619607
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5249803088609889
grad_accumulated_steps   -->   8
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   107
graph_learn_num_pers     -->   6
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.8980869068026637
graph_type               -->   dynamic
hidden_size              -->   127
learning_rate            -->   5.517888206912625
logging                  -->   True
lr_patience              -->   3
lr_reduce_factor         -->   0.8808479567231886
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   366
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5288366075958033
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.16324243536705452
sparsity_ratio           -->   0.44517567788870505
task_type                -->   classification
update_adj_ratio         -->   0.09652771118285985
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.960666667731523
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 6 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 6 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 127])
encoder.graph_encoders.1.weight: torch.Size([127, 7])
graph_learner.weight_tensor: torch.Size([6, 1433])
graph_learner2.weight_tensor: torch.Size([6, 127])
#Parameters = 192240

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.5288366075958033
Training time: 3.68

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = -4.01115
ACC = 0.12400

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5288366075958033/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 6 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 6 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5288366075958033/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -3.93175 | ACC = 0.13100
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5288366075958033
Testing time: 0.04
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.3997259618550769
device                   -->   cuda:0
dropout                  -->   0.09735094174057557
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.35207751774509255
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5247842096346838
grad_accumulated_steps   -->   7
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   81
graph_learn_num_pers     -->   7
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.8494937360294492
graph_type               -->   dynamic
hidden_size              -->   152
learning_rate            -->   6.313741289957111
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9167211961626816
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   379
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.4877658134309606
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.11661375433887583
sparsity_ratio           -->   0.3965447555296522
task_type                -->   classification
update_adj_ratio         -->   0.1037704086236868
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9184414529867116
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 152])
encoder.graph_encoders.1.weight: torch.Size([152, 7])
graph_learner.weight_tensor: torch.Size([7, 1433])
graph_learner2.weight_tensor: torch.Size([7, 152])
#Parameters = 229975

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.4877658134309606
Training time: 3.56

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = -6.82643
ACC = 0.06200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.4877658134309606/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.4877658134309606/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -7.05699 | ACC = 0.05900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.4877658134309606
Testing time: 0.04
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.6993729076970189
device                   -->   cuda:0
dropout                  -->   0.9112449718840571
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6677209769281633
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.44614149692073113
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   5
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   80
graph_learn_num_pers     -->   7
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5286569284254485
graph_type               -->   dynamic
hidden_size              -->   18
learning_rate            -->   2.906319416503802
logging                  -->   True
lr_patience              -->   6
lr_reduce_factor         -->   0.49348604173614374
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   2452
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8338405162119605
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7604036483649999
sparsity_ratio           -->   0.5799701592070343
task_type                -->   classification
update_adj_ratio         -->   0.17510518316824897
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9029510266568412
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 18])
encoder.graph_encoders.1.weight: torch.Size([18, 18])
encoder.graph_encoders.2.weight: torch.Size([18, 18])
encoder.graph_encoders.3.weight: torch.Size([18, 18])
encoder.graph_encoders.4.weight: torch.Size([18, 7])
graph_learner.weight_tensor: torch.Size([7, 1433])
graph_learner2.weight_tensor: torch.Size([7, 18])
#Parameters = 37049

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 07s <> <> <>
Finished Training: /tmp/iteration_id_0.8338405162119605
Training time: 7.71

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 8; 
NLOSS = 3.94829
ACC = 0.15600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.8338405162119605/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.8338405162119605/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 3.73508 | ACC = 0.14400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.8338405162119605
Testing time: 0.09
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9367511555926453
device                   -->   cuda:0
dropout                  -->   0.6827371211298744
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.521858798863958
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6080778117041861
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.03797437419648353
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5536604320211791
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.8785843069901762
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5136
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8787526666824202
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41775965091071193
sparsity_ratio           -->   0.10162685957971807
task_type                -->   classification
update_adj_ratio         -->   0.4136951908712868
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5971449891543184
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 05s <> <> <>
Finished Training: /tmp/iteration_id_0.8787526666824202
Training time: 5.77

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 8.92999
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.8787526666824202/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.8787526666824202/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 8.92997 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.8787526666824202
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9380662520620665
device                   -->   cuda:0
dropout                  -->   0.6825275889277246
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5213390290287226
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.608170200750138
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.03208002824519951
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5432338311378571
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.8806409893995297
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5335
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5934496287392698
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41492596480671773
sparsity_ratio           -->   0.10220270569236434
task_type                -->   classification
update_adj_ratio         -->   0.4053605657222341
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5943985870938734
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 05s <> <> <>
Finished Training: /tmp/iteration_id_0.5934496287392698
Training time: 5.68

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 8.95278
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5934496287392698/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5934496287392698/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 8.95278 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5934496287392698
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9406104344693624
device                   -->   cuda:0
dropout                  -->   0.6793098206091812
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159972470373695
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.608082426557282
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.029522689305987893
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5357645894486907
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883536432231425
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5445
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.029181368993392742
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41237873540878583
sparsity_ratio           -->   0.10293398861259362
task_type                -->   classification
update_adj_ratio         -->   0.38247554305996323
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5961891791928413
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 05s <> <> <>
Finished Training: /tmp/iteration_id_0.029181368993392742
Training time: 5.98

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 8.98925
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.029181368993392742/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.029181368993392742/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 8.98928 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.029181368993392742
Testing time: 0.13
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5207516145122854
device                   -->   cuda:0
dropout                  -->   0.8849357402264613
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7885162738356897
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.149486822486794
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   151
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5152084510334161
graph_type               -->   dynamic
hidden_size              -->   152
learning_rate            -->   8.994359138418623
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.841953757547187
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1359
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6434931722723785
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.8380177002285719
sparsity_ratio           -->   0.10671782550822458
task_type                -->   classification
update_adj_ratio         -->   0.4520473377414428
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8341874143868436
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 152])
encoder.graph_encoders.1.weight: torch.Size([152, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 152])
#Parameters = 220465

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 09s <> <> <>
Finished Training: /tmp/iteration_id_0.6434931722723785
Training time: 9.58

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 30; 
NLOSS = 2.64641
ACC = 0.07200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6434931722723785/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6434931722723785/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 2.65870 | ACC = 0.09100
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6434931722723785
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5220163088703526
device                   -->   cuda:0
dropout                  -->   0.8855054575456711
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.78840927716715
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.1496968327670441
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   151
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5150518168611351
graph_type               -->   dynamic
hidden_size              -->   152
learning_rate            -->   8.993818527813698
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.8431591080170799
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1394
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5810924336418131
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.8366848744536816
sparsity_ratio           -->   0.10515984286389954
task_type                -->   classification
update_adj_ratio         -->   0.4469063321577583
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8402545378361725
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 152])
encoder.graph_encoders.1.weight: torch.Size([152, 152])
encoder.graph_encoders.2.weight: torch.Size([152, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 152])
#Parameters = 243569

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 12s <> <> <>
Finished Training: /tmp/iteration_id_0.5810924336418131
Training time: 12.1

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 29; 
NLOSS = -15.75600
ACC = 0.20000

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5810924336418131/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5810924336418131/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -16.88080 | ACC = 0.19100
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5810924336418131
Testing time: 0.08
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5212852685458754
device                   -->   cuda:0
dropout                  -->   0.885151636785618
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7884542515890705
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.14971276686661095
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   151
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5035851055828588
graph_type               -->   dynamic
hidden_size              -->   152
learning_rate            -->   8.976453063046575
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.8401964394056327
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1355
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.32615177685453367
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.8364703900341206
sparsity_ratio           -->   0.10342195465611126
task_type                -->   classification
update_adj_ratio         -->   0.45486082859193916
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8425058799417899
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 152])
encoder.graph_encoders.1.weight: torch.Size([152, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 152])
#Parameters = 220465

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 09s <> <> <>
Finished Training: /tmp/iteration_id_0.32615177685453367
Training time: 9.35

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 30; 
NLOSS = 2.67021
ACC = 0.07200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.32615177685453367/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.32615177685453367/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 2.67999 | ACC = 0.09100
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.32615177685453367
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5196198635217072
device                   -->   cuda:0
dropout                  -->   0.8849345309435767
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7884394412071065
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.14965671378596296
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   151
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5029727144103088
graph_type               -->   dynamic
hidden_size              -->   152
learning_rate            -->   8.963273163256396
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.8411529446898663
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1466
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.44414702695745345
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.8367298521291947
sparsity_ratio           -->   0.10424714782622783
task_type                -->   classification
update_adj_ratio         -->   0.45492785494392435
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8420895919743221
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 152])
encoder.graph_encoders.1.weight: torch.Size([152, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 152])
#Parameters = 220465

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 08s <> <> <>
Finished Training: /tmp/iteration_id_0.44414702695745345
Training time: 8.21

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 2.66513
ACC = 0.09800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.44414702695745345/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.44414702695745345/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 2.67104 | ACC = 0.10200
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.44414702695745345
Testing time: 0.02
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5177948880603932
device                   -->   cuda:0
dropout                  -->   0.884928367462412
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7884750476397498
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.14948761622351808
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   151
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.5011774371164263
graph_type               -->   dynamic
hidden_size              -->   152
learning_rate            -->   8.953376285087625
logging                  -->   True
lr_patience              -->   5
lr_reduce_factor         -->   0.8408351441747448
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1480
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6666699315631562
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.8368320990417613
sparsity_ratio           -->   0.1029490743363906
task_type                -->   classification
update_adj_ratio         -->   0.4552740999168136
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8416499530736956
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 152])
encoder.graph_encoders.1.weight: torch.Size([152, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 152])
#Parameters = 220465

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 06s <> <> <>
Finished Training: /tmp/iteration_id_0.6666699315631562
Training time: 6.67

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 30; 
NLOSS = 2.62848
ACC = 0.07200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6666699315631562/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6666699315631562/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 2.63811 | ACC = 0.09100
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6666699315631562
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.3997259618550769
device                   -->   cuda:0
dropout                  -->   0.09735094174057557
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.35207751774509255
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5247842096346838
grad_accumulated_steps   -->   7
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   81
graph_learn_num_pers     -->   7
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.8494937360294492
graph_type               -->   dynamic
hidden_size              -->   152
learning_rate            -->   6.313741289957111
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9167211961626816
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   379
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.12598583159702892
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.11661375433887583
sparsity_ratio           -->   0.3965447555296522
task_type                -->   classification
update_adj_ratio         -->   0.1037704086236868
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9184414529867116
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 152])
encoder.graph_encoders.1.weight: torch.Size([152, 7])
graph_learner.weight_tensor: torch.Size([7, 1433])
graph_learner2.weight_tensor: torch.Size([7, 152])
#Parameters = 229975

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 09s <> <> <>
Finished Training: /tmp/iteration_id_0.12598583159702892
Training time: 9.41

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 31; 
NLOSS = -4.14521
ACC = 0.11400

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.12598583159702892/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 7 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.12598583159702892/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = -4.18519 | ACC = 0.12800
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.12598583159702892
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9367511555926453
device                   -->   cuda:0
dropout                  -->   0.6827371211298744
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.521858798863958
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6080778117041861
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.03797437419648353
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5536604320211791
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.8785843069901762
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5136
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6286614503105195
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41775965091071193
sparsity_ratio           -->   0.10162685957971807
task_type                -->   classification
update_adj_ratio         -->   0.4136951908712868
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5971449891543184
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 15s <> <> <>
Finished Training: /tmp/iteration_id_0.6286614503105195
Training time: 15.44

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 8.92999
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6286614503105195/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6286614503105195/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 8.92997 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6286614503105195
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9380662520620665
device                   -->   cuda:0
dropout                  -->   0.6825275889277246
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5213390290287226
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.608170200750138
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.03208002824519951
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5432338311378571
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.8806409893995297
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5335
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6701773563818207
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41492596480671773
sparsity_ratio           -->   0.10220270569236434
task_type                -->   classification
update_adj_ratio         -->   0.4053605657222341
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5943985870938734
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 15s <> <> <>
Finished Training: /tmp/iteration_id_0.6701773563818207
Training time: 15.66

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 8.95278
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6701773563818207/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6701773563818207/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 8.95278 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6701773563818207
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9406104344693624
device                   -->   cuda:0
dropout                  -->   0.6793098206091812
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159972470373695
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.608082426557282
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.029522689305987893
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5357645894486907
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883536432231425
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5445
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.27691123900773773
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41237873540878583
sparsity_ratio           -->   0.10293398861259362
task_type                -->   classification
update_adj_ratio         -->   0.38247554305996323
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5961891791928413
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 15s <> <> <>
Finished Training: /tmp/iteration_id_0.27691123900773773
Training time: 15.47

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 8.98925
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.27691123900773773/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.27691123900773773/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 8.98928 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.27691123900773773
Testing time: 0.16
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9367511555926453
device                   -->   cuda:0
dropout                  -->   0.6827371211298744
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.521858798863958
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6080778117041861
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.03797437419648353
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5536604320211791
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.8785843069901762
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5136
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5551064493781594
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41775965091071193
sparsity_ratio           -->   0.10162685957971807
task_type                -->   classification
update_adj_ratio         -->   0.4136951908712868
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5971449891543184
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 44s <> <> <>
Finished Training: /tmp/iteration_id_0.5551064493781594
Training time: 44.75

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 95; 
NLOSS = 9.04028
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5551064493781594/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5551064493781594/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.04028 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5551064493781594
Testing time: 0.14
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9380662520620665
device                   -->   cuda:0
dropout                  -->   0.6825275889277246
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5213390290287226
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.608170200750138
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.03208002824519951
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5432338311378571
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.8806409893995297
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5335
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8595245553065542
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41492596480671773
sparsity_ratio           -->   0.10220270569236434
task_type                -->   classification
update_adj_ratio         -->   0.4053605657222341
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5943985870938734
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 45s <> <> <>
Finished Training: /tmp/iteration_id_0.8595245553065542
Training time: 45.95

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 77; 
NLOSS = 9.04919
ACC = 0.11400

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.8595245553065542/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.8595245553065542/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.04919 | ACC = 0.10300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.8595245553065542
Testing time: 0.14
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9406104344693624
device                   -->   cuda:0
dropout                  -->   0.6793098206091812
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159972470373695
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.608082426557282
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.029522689305987893
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5357645894486907
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883536432231425
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5445
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.27724541410099146
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41237873540878583
sparsity_ratio           -->   0.10293398861259362
task_type                -->   classification
update_adj_ratio         -->   0.38247554305996323
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5961891791928413
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 45s <> <> <>
Finished Training: /tmp/iteration_id_0.27724541410099146
Training time: 45.09

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 82; 
NLOSS = 9.10278
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.27724541410099146/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.27724541410099146/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.10278 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.27724541410099146
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9406104344693624
device                   -->   cuda:0
dropout                  -->   0.6793098206091812
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159972470373695
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.608082426557282
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.029522689305987893
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5357645894486907
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883536432231425
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5445
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5184310898920146
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41237873540878583
sparsity_ratio           -->   0.10293398861259362
task_type                -->   classification
update_adj_ratio         -->   0.38247554305996323
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5961891791928413
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 01m 20s <> <> <>
Finished Training: /tmp/iteration_id_0.5184310898920146
Training time: 80.51

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 82; 
NLOSS = 9.10278
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5184310898920146/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5184310898920146/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.10278 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5184310898920146
Testing time: 0.15
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.11297904751733057
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 16s <> <> <>
Finished Training: /tmp/iteration_id_0.11297904751733057
Training time: 16.0

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 9.01420
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.11297904751733057/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.11297904751733057/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.01419 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.11297904751733057
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5183614401545623
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 15s <> <> <>
Finished Training: /tmp/iteration_id_0.5183614401545623
Training time: 15.25

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 9.01420
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5183614401545623/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5183614401545623/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.01419 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5183614401545623
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.9205056878830329
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 15s <> <> <>
Finished Training: /tmp/iteration_id_0.9205056878830329
Training time: 15.59

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 9.01420
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.9205056878830329/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.9205056878830329/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.01419 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.9205056878830329
Testing time: 0.13
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5934454986913954
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 15s <> <> <>
Finished Training: /tmp/iteration_id_0.5934454986913954
Training time: 15.15

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 9.01420
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5934454986913954/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5934454986913954/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.01419 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5934454986913954
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6403554563840456
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 15s <> <> <>
Finished Training: /tmp/iteration_id_0.6403554563840456
Training time: 15.14

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 9.01420
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6403554563840456/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6403554563840456/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.01419 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6403554563840456
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5431687508597428
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 15s <> <> <>
Finished Training: /tmp/iteration_id_0.5431687508597428
Training time: 15.47

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 9.01420
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5431687508597428/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5431687508597428/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.01419 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5431687508597428
Testing time: 0.13
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6357391548263227
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 15s <> <> <>
Finished Training: /tmp/iteration_id_0.6357391548263227
Training time: 15.29

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 9.01420
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6357391548263227/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6357391548263227/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.01419 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6357391548263227
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.7471748459493176
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 15s <> <> <>
Finished Training: /tmp/iteration_id_0.7471748459493176
Training time: 15.45

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 9.01420
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.7471748459493176/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.7471748459493176/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.01419 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.7471748459493176
Testing time: 0.13
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.41098548459226436
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 15s <> <> <>
Finished Training: /tmp/iteration_id_0.41098548459226436
Training time: 15.44

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 9.01420
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.41098548459226436/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.41098548459226436/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.01419 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.41098548459226436
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.0630736690287308
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 44s <> <> <>
Finished Training: /tmp/iteration_id_0.0630736690287308
Training time: 44.54

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.0630736690287308/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.0630736690287308/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.0630736690287308
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.7232925249121409
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 44s <> <> <>
Finished Training: /tmp/iteration_id_0.7232925249121409
Training time: 44.77

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.7232925249121409/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.7232925249121409/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.7232925249121409
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.36492953720557253
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 44s <> <> <>
Finished Training: /tmp/iteration_id_0.36492953720557253
Training time: 44.53

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.36492953720557253/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.36492953720557253/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.36492953720557253
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.3207656604506255
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 01m 36s <> <> <>
Finished Training: /tmp/iteration_id_0.3207656604506255
Training time: 96.2

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.3207656604506255/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.3207656604506255/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.3207656604506255
Testing time: 0.05
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.30689977647477973
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 33s <> <> <>
Finished Training: /tmp/iteration_id_0.30689977647477973
Training time: 33.25

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.30689977647477973/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.30689977647477973/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.30689977647477973
Testing time: 0.05
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8166004979468278
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 41s <> <> <>
Finished Training: /tmp/iteration_id_0.8166004979468278
Training time: 41.48

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.8166004979468278/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.8166004979468278/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.8166004979468278
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.533356845235399
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 45s <> <> <>
Finished Training: /tmp/iteration_id_0.533356845235399
Training time: 45.01

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.533356845235399/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.533356845235399/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.533356845235399
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.646871422974113
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 44s <> <> <>
Finished Training: /tmp/iteration_id_0.646871422974113
Training time: 44.78

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.646871422974113/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.646871422974113/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.646871422974113
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6239099538268555
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 44s <> <> <>
Finished Training: /tmp/iteration_id_0.6239099538268555
Training time: 44.24

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6239099538268555/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6239099538268555/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6239099538268555
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.13568520635954084
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 45s <> <> <>
Finished Training: /tmp/iteration_id_0.13568520635954084
Training time: 45.4

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.13568520635954084/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.13568520635954084/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.13568520635954084
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5819033983354631
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 01m 27s <> <> <>
Finished Training: /tmp/iteration_id_0.5819033983354631
Training time: 87.26

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5819033983354631/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5819033983354631/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5819033983354631
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.022052860077367842
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 01m 26s <> <> <>
Finished Training: /tmp/iteration_id_0.022052860077367842
Training time: 86.83

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.022052860077367842/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.022052860077367842/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.022052860077367842
Testing time: 0.15
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.4023970821853433
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 01m 27s <> <> <>
Finished Training: /tmp/iteration_id_0.4023970821853433
Training time: 87.28

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.4023970821853433/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.4023970821853433/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.4023970821853433
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.1093453393783348
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 01m 27s <> <> <>
Finished Training: /tmp/iteration_id_0.1093453393783348
Training time: 87.29

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.1093453393783348/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.1093453393783348/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.1093453393783348
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.2837163655179612
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 01m 24s <> <> <>
Finished Training: /tmp/iteration_id_0.2837163655179612
Training time: 84.43

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.2837163655179612/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.2837163655179612/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.2837163655179612
Testing time: 0.13
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.31322367297952636
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 01m 25s <> <> <>
Finished Training: /tmp/iteration_id_0.31322367297952636
Training time: 85.53

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.31322367297952636/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.31322367297952636/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.31322367297952636
Testing time: 0.15
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8908660309174774
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 05s <> <> <>
Finished Training: /tmp/iteration_id_0.8908660309174774
Training time: 5.68

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 9.01420
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.8908660309174774/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.8908660309174774/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.01419 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.8908660309174774
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.941442349371581
device                   -->   cuda:0
dropout                  -->   0.6711725452080415
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.519843911073804
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6079867092773644
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.022852623485608015
graph_type               -->   dynamic
hidden_size              -->   31
learning_rate            -->   0.5196001268944328
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.8798159854677384
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5651
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6779775713972814
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41467268995901013
sparsity_ratio           -->   0.10238535654013348
task_type                -->   classification
update_adj_ratio         -->   0.38676417431183896
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6805836393993107
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 31])
encoder.graph_encoders.1.weight: torch.Size([31, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 31])
#Parameters = 66600

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 05s <> <> <>
Finished Training: /tmp/iteration_id_0.6779775713972814
Training time: 5.87

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 9.01290
ACC = 0.15600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6779775713972814/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6779775713972814/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.01032 | ACC = 0.14400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6779775713972814
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.8634506043840231
device                   -->   cuda:0
dropout                  -->   0.8091238802829289
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6250908880963508
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.25611146516465805
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   5
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   98
graph_learn_num_pers     -->   6
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.4086993897269674
graph_type               -->   dynamic
hidden_size              -->   87
learning_rate            -->   9.949788351292046
logging                  -->   True
lr_patience              -->   9
lr_reduce_factor         -->   0.5340712775307025
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   6196
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6121238676768408
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7226501803846839
sparsity_ratio           -->   0.026109984570696743
task_type                -->   classification
update_adj_ratio         -->   0.8633834850387803
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8486333647610671
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 6 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 6 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 87])
encoder.graph_encoders.1.weight: torch.Size([87, 87])
encoder.graph_encoders.2.weight: torch.Size([87, 87])
encoder.graph_encoders.3.weight: torch.Size([87, 87])
encoder.graph_encoders.4.weight: torch.Size([87, 7])
graph_learner.weight_tensor: torch.Size([6, 1433])
graph_learner2.weight_tensor: torch.Size([6, 87])
#Parameters = 157107

<> <> <> Starting Timer [Train] <> <> <>
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9430549944085872
device                   -->   cuda:0
dropout                  -->   0.6625985363500744
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5135637521048351
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6079715762240938
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.023608016392042352
graph_type               -->   dynamic
hidden_size              -->   29
learning_rate            -->   0.5292194785070958
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.8795427285159141
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5296
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5140697145226605
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.4081288837451789
sparsity_ratio           -->   0.10236660277679616
task_type                -->   classification
update_adj_ratio         -->   0.36565197640447933
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.680570327559591
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 29])
encoder.graph_encoders.1.weight: torch.Size([29, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 29])
#Parameters = 63690

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 07s <> <> <>
Finished Training: /tmp/iteration_id_0.5140697145226605
Training time: 7.78

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 9.01155
ACC = 0.11400

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5140697145226605/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5140697145226605/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.01035 | ACC = 0.10300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5140697145226605
Testing time: 0.13
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9426475602731179
device                   -->   cuda:0
dropout                  -->   0.6648784864775089
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.504787943176289
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6072379759595815
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02070615705261558
graph_type               -->   dynamic
hidden_size              -->   31
learning_rate            -->   0.5177732457479023
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.8914692386993267
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5641
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.43049798360387515
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.4100347838447059
sparsity_ratio           -->   0.10207447113072143
task_type                -->   classification
update_adj_ratio         -->   0.38048938351181116
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6824700344832615
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 31])
encoder.graph_encoders.1.weight: torch.Size([31, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 31])
#Parameters = 66600

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 07s <> <> <>
Finished Training: /tmp/iteration_id_0.43049798360387515
Training time: 7.07

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 9.03172
ACC = 0.15600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.43049798360387515/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.43049798360387515/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.02909 | ACC = 0.14400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.43049798360387515
Testing time: 0.12
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.7972392779278105
device                   -->   cuda:0
dropout                  -->   0.277661555621
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.4008835312723592
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5650528355722599
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   58
graph_learn_num_pers     -->   3
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.04345363450763548
graph_type               -->   dynamic
hidden_size              -->   188
learning_rate            -->   8.117231163181128
logging                  -->   True
lr_patience              -->   3
lr_reduce_factor         -->   0.9688372808522003
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   6681
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.9597237509894874
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.4665047255716136
sparsity_ratio           -->   0.37501249227056693
task_type                -->   classification
update_adj_ratio         -->   0.08560643226578862
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.14549920932091254
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 188])
encoder.graph_encoders.1.weight: torch.Size([188, 188])
encoder.graph_encoders.2.weight: torch.Size([188, 7])
graph_learner.weight_tensor: torch.Size([3, 1433])
graph_learner2.weight_tensor: torch.Size([3, 188])
#Parameters = 310927

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 06s <> <> <>
Finished Training: /tmp/iteration_id_0.9597237509894874
Training time: 6.66

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 6.21063
ACC = 0.15600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.9597237509894874/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 3 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.9597237509894874/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 6.21048 | ACC = 0.14400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.9597237509894874
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5085616782221998
device                   -->   cuda:0
dropout                  -->   0.8486337426143193
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7317326689544593
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.17862149482258327
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   143
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6203088578997108
graph_type               -->   dynamic
hidden_size              -->   157
learning_rate            -->   8.76911605109746
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.8657976098872249
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   798
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6043620274142869
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7915502023768504
sparsity_ratio           -->   0.13134063457889905
task_type                -->   classification
update_adj_ratio         -->   0.3035318312695333
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8822336560045811
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 157])
encoder.graph_encoders.1.weight: torch.Size([157, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 157])
#Parameters = 227670

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.6043620274142869
Training time: 3.81

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 1.39126
ACC = 0.05600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6043620274142869/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6043620274142869/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.37415 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6043620274142869
Testing time: 0.04
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5067722440200518
device                   -->   cuda:0
dropout                  -->   0.8428595843386332
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7334551566329612
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.17933648599762936
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   142
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6277185790470716
graph_type               -->   dynamic
hidden_size              -->   157
learning_rate            -->   8.769118289603757
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.8685117841442838
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   810
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.26128515220593074
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7892967551823054
sparsity_ratio           -->   0.1329747370641814
task_type                -->   classification
update_adj_ratio         -->   0.24971542207974018
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8839584059329604
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 157])
encoder.graph_encoders.1.weight: torch.Size([157, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 157])
#Parameters = 227670

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.26128515220593074
Training time: 3.54

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 1.37460
ACC = 0.05600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.26128515220593074/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.26128515220593074/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.35384 | ACC = 0.06700
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.26128515220593074
Testing time: 0.05
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5062581862032987
device                   -->   cuda:0
dropout                  -->   0.8381667920173602
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6907888720459188
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.17782813387610347
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   140
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6266580175257691
graph_type               -->   dynamic
hidden_size              -->   157
learning_rate            -->   8.769125146369035
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.8784366062990892
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   752
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.2361018801058553
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.775721355080289
sparsity_ratio           -->   0.13253706197351128
task_type                -->   classification
update_adj_ratio         -->   0.25234829499052736
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8827177075089888
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 157])
encoder.graph_encoders.1.weight: torch.Size([157, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 157])
#Parameters = 227670

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.2361018801058553
Training time: 3.29

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 1.10178
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.2361018801058553/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.2361018801058553/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.08309 | ACC = 0.06700
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.2361018801058553
Testing time: 0.04
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5050300872960667
device                   -->   cuda:0
dropout                  -->   0.8395953272816282
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.691585172988253
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.17732964070437163
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   139
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6322540264638359
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769125024571014
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9081279674016114
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   761
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.02353066863630182
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7683288076031098
sparsity_ratio           -->   0.13544504621155884
task_type                -->   classification
update_adj_ratio         -->   0.2306264733829386
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8816919035781472
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.02353066863630182
Training time: 3.28

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 1.50323
ACC = 0.05600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.02353066863630182/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.02353066863630182/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.48682 | ACC = 0.06500
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.02353066863630182
Testing time: 0.05
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5039645127261336
device                   -->   cuda:0
dropout                  -->   0.8187856678111514
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6636268941650103
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.17767496916487685
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   139
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6336334113923852
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.7691224615415
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.907795751227836
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   755
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.4323628259976995
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7528743685216521
sparsity_ratio           -->   0.1369404826239825
task_type                -->   classification
update_adj_ratio         -->   0.22847181452748683
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8842981049671835
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.4323628259976995
Training time: 3.3

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 1.42844
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.4323628259976995/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.4323628259976995/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.40851 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.4323628259976995
Testing time: 0.04
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5040149066096181
device                   -->   cuda:0
dropout                  -->   0.8170212421045051
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.657266253334158
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.17798665972068706
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   139
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6322157733922728
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769122975109967
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9072000577787903
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   762
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.9035961762456503
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7499369304213421
sparsity_ratio           -->   0.13706502072647375
task_type                -->   classification
update_adj_ratio         -->   0.23382539868409433
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8835157772436921
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.9035961762456503
Training time: 3.23

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 1.44784
ACC = 0.06600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.9035961762456503/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.9035961762456503/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.42473 | ACC = 0.06800
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.9035961762456503
Testing time: 0.05
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.49480888773408144
device                   -->   cuda:0
dropout                  -->   0.781814829573357
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.63934999083604
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.18256474463041944
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   137
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6310854451109799
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769119770953273
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.906831068389751
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   767
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.35658887919334603
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7402017008461064
sparsity_ratio           -->   0.13919660957497942
task_type                -->   classification
update_adj_ratio         -->   0.23303795446995523
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8827916778540279
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.35658887919334603
Training time: 3.2

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 1.31361
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.35658887919334603/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.35658887919334603/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.29211 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.35658887919334603
Testing time: 0.05
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.49507144653428514
device                   -->   cuda:0
dropout                  -->   0.767720032113968
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6389767152881067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.1819287757273123
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   135
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6350004564917201
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769125485732944
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9586051662949321
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   775
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.7381819495960567
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7391205594735943
sparsity_ratio           -->   0.191446799257833
task_type                -->   classification
update_adj_ratio         -->   0.23191259567351694
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9016830352973939
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.7381819495960567
Training time: 3.31

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 1.00325
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.7381819495960567/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.7381819495960567/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.98019 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.7381819495960567
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.49529353563542466
device                   -->   cuda:0
dropout                  -->   0.7633207852343893
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.630389278022564
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.1823184881414065
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   135
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6335760888810634
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769125446900501
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9581593411195649
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   780
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.45903918151710443
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7351996693310081
sparsity_ratio           -->   0.1890483344683295
task_type                -->   classification
update_adj_ratio         -->   0.2327604311305352
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9005579681540389
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.45903918151710443
Training time: 3.09

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 1.04902
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.45903918151710443/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.45903918151710443/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.02500 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.45903918151710443
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.4903016670547311
device                   -->   cuda:0
dropout                  -->   0.7618656105548558
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6231552376615153
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.1860005949818334
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   133
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.640770393043473
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769086066675573
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9569557770734632
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   760
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6174270968473219
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7275741267025055
sparsity_ratio           -->   0.1875406499847048
task_type                -->   classification
update_adj_ratio         -->   0.23534113258527165
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9022931410307405
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.6174270968473219
Training time: 3.55

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 0.92165
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6174270968473219/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6174270968473219/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.89760 | ACC = 0.06500
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6174270968473219
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.49055110318375034
device                   -->   cuda:0
dropout                  -->   0.756971526611569
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6127799558046685
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.1864798658209751
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   133
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6394974528457364
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769084334290275
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9563395726857419
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   764
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.3039294686730635
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7229005159002464
sparsity_ratio           -->   0.18664953297847062
task_type                -->   classification
update_adj_ratio         -->   0.23413753598101245
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9014054929833742
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.3039294686730635
Training time: 3.96

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 0.93378
ACC = 0.06200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.3039294686730635/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.3039294686730635/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.91173 | ACC = 0.06600
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.3039294686730635
Testing time: 0.07
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.4908206908247247
device                   -->   cuda:0
dropout                  -->   0.7512001867016986
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5998023951990914
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.18698260003110312
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   132
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6384075029208123
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769082119426452
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9560246762372815
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   768
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.28559479326793524
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7175169765144107
sparsity_ratio           -->   0.1861850495362263
task_type                -->   classification
update_adj_ratio         -->   0.23231610344143463
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9006028118239098
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 04s <> <> <>
Finished Training: /tmp/iteration_id_0.28559479326793524
Training time: 4.31

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 1.00408
ACC = 0.06200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.28559479326793524/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.28559479326793524/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.98340 | ACC = 0.06600
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.28559479326793524
Testing time: 0.05
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.4910706247828206
device                   -->   cuda:0
dropout                  -->   0.7444412520259992
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5833373198347271
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.1875176816561272
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   132
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6374396281399322
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769079808316674
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9561096806762522
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   771
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.9886140611051842
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7111301578223992
sparsity_ratio           -->   0.18610023339988357
task_type                -->   classification
update_adj_ratio         -->   0.22904661780782382
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8998760648881902
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 04s <> <> <>
Finished Training: /tmp/iteration_id_0.9886140611051842
Training time: 4.24

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 0.95780
ACC = 0.09400

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.9886140611051842/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.9886140611051842/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.93542 | ACC = 0.09100
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.9886140611051842
Testing time: 0.07
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.49106581176194875
device                   -->   cuda:0
dropout                  -->   0.7444746858605155
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5833273721844783
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.18751741561108914
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   132
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6374252971862253
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.76907999959691
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9562055331600561
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   771
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.7122152555377474
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7111474582727773
sparsity_ratio           -->   0.1861942201346368
task_type                -->   classification
update_adj_ratio         -->   0.2284915709175703
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8998821399078794
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 04s <> <> <>
Finished Training: /tmp/iteration_id_0.7122152555377474
Training time: 4.22

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 0.95663
ACC = 0.09400

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.7122152555377474/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.7122152555377474/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.93412 | ACC = 0.09000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.7122152555377474
Testing time: 0.05
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.4913139922630762
device                   -->   cuda:0
dropout                  -->   0.7363614945558256
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5622539247817351
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.18808063476423448
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   131
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6365737726542561
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769077608608649
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9566049539359119
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   774
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.22683217547494816
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7037167081791278
sparsity_ratio           -->   0.18662409928083235
task_type                -->   classification
update_adj_ratio         -->   0.22429940729471054
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8992462408372133
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.22683217547494816
Training time: 3.34

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 0.91080
ACC = 0.08000

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.22683217547494816/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.22683217547494816/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.88556 | ACC = 0.08000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.22683217547494816
Testing time: 0.08
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.491311644471679
device                   -->   cuda:0
dropout                  -->   0.7362446974433386
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5632885328003362
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.18808795547298113
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   131
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6365839968897531
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769077608584226
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9565954415263308
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   774
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.921891231287833
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7034652238953814
sparsity_ratio           -->   0.18660548780676292
task_type                -->   classification
update_adj_ratio         -->   0.22443733535911597
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8992581768801604
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.921891231287833
Training time: 3.26

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 0.90802
ACC = 0.07600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.921891231287833/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.921891231287833/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.88258 | ACC = 0.07600
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.921891231287833
Testing time: 0.05
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.4913116666550675
device                   -->   cuda:0
dropout                  -->   0.7362433102793541
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.563223368404026
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.1880880504149413
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   131
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6365838744727401
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769077608584226
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9565956690493223
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   774
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.01871738894696684
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7034571113819477
sparsity_ratio           -->   0.1866062979668737
task_type                -->   classification
update_adj_ratio         -->   0.22443266857878974
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8992579538448319
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.01871738894696684
Training time: 3.17

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 0.90804
ACC = 0.07600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.01871738894696684/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.01871738894696684/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.88253 | ACC = 0.07600
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.01871738894696684
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.49131166644546265
device                   -->   cuda:0
dropout                  -->   0.7362432938546684
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5632274292781799
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.18808805164620385
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   131
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6365838759385156
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769077608584226
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.956595663607862
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   774
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.429972425940776
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7034568501201488
sparsity_ratio           -->   0.18660626270874242
task_type                -->   classification
update_adj_ratio         -->   0.22443282633577444
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8992579580127944
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.429972425940776
Training time: 3.38

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 0.90799
ACC = 0.07600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.429972425940776/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.429972425940776/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.88248 | ACC = 0.07600
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.429972425940776
Testing time: 0.05
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.4913116664474431
device                   -->   cuda:0
dropout                  -->   0.7362432936601992
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5632271760443099
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.1880880516621714
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   131
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6365838759209649
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769077608584226
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9565956637380008
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   774
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.23002979562698034
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7034568417067202
sparsity_ratio           -->   0.18660626424319032
task_type                -->   classification
update_adj_ratio         -->   0.22443282100275516
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8992579579349059
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.23002979562698034
Training time: 3.24

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 0.90799
ACC = 0.07600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.23002979562698034/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.23002979562698034/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.88248 | ACC = 0.07600
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.23002979562698034
Testing time: 0.04
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.49131166644742447
device                   -->   cuda:0
dropout                  -->   0.7362432936578972
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5632271918351703
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.18808805166237846
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   131
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.636583875921175
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769077608584226
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9565956637348884
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   774
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.877424944520517
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7034568414357822
sparsity_ratio           -->   0.18660626417641055
task_type                -->   classification
update_adj_ratio         -->   0.22443282118303914
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8992579579363614
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.877424944520517
Training time: 3.35

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 0.90799
ACC = 0.07600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.877424944520517/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.877424944520517/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.88248 | ACC = 0.07600
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.877424944520517
Testing time: 0.07
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.4913116664474246
device                   -->   cuda:0
dropout                  -->   0.7362432936578699
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5632271908504998
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.18808805166238118
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   131
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6365838759211725
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769077608584226
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9565956637349627
max_epochs               -->   11.11111111111111
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   774
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.447247376838378
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7034568414270574
sparsity_ratio           -->   0.18660626417931678
task_type                -->   classification
update_adj_ratio         -->   0.22443282117694463
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8992579579363342
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 03s <> <> <>
Finished Training: /tmp/iteration_id_0.447247376838378
Training time: 3.23

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 0.90799
ACC = 0.07600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.447247376838378/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.447247376838378/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.88248 | ACC = 0.07600
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.447247376838378
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.0343974255389925
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 15s <> <> <>
Finished Training: /tmp/iteration_id_0.0343974255389925
Training time: 15.43

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 12; 
NLOSS = 9.01420
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.0343974255389925/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.0343974255389925/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.01419 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.0343974255389925
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5085616782221998
device                   -->   cuda:0
dropout                  -->   0.8486337426143193
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7317326689544593
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.17862149482258327
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   143
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6203088578997108
graph_type               -->   dynamic
hidden_size              -->   157
learning_rate            -->   8.76911605109746
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.8657976098872249
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   798
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.06967089916044489
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7915502023768504
sparsity_ratio           -->   0.13134063457889905
task_type                -->   classification
update_adj_ratio         -->   0.3035318312695333
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8822336560045811
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 157])
encoder.graph_encoders.1.weight: torch.Size([157, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 157])
#Parameters = 227670

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 08s <> <> <>
Finished Training: /tmp/iteration_id_0.06967089916044489
Training time: 8.54

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 30; 
NLOSS = 1.72633
ACC = 0.05600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.06967089916044489/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.06967089916044489/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.74183 | ACC = 0.06300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.06967089916044489
Testing time: 0.04
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5050300872960667
device                   -->   cuda:0
dropout                  -->   0.8395953272816282
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.691585172988253
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.17732964070437163
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   139
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6322540264638359
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769125024571014
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9081279674016114
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   761
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8118600244573422
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7683288076031098
sparsity_ratio           -->   0.13544504621155884
task_type                -->   classification
update_adj_ratio         -->   0.2306264733829386
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8816919035781472
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 09s <> <> <>
Finished Training: /tmp/iteration_id_0.8118600244573422
Training time: 9.51

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 1.50323
ACC = 0.05600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.8118600244573422/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.8118600244573422/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.47643 | ACC = 0.06500
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.8118600244573422
Testing time: 0.05
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5039645127261336
device                   -->   cuda:0
dropout                  -->   0.8187856678111514
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6636268941650103
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.17767496916487685
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   139
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6336334113923852
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.7691224615415
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.907795751227836
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   755
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.4678788971611575
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7528743685216521
sparsity_ratio           -->   0.1369404826239825
task_type                -->   classification
update_adj_ratio         -->   0.22847181452748683
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8842981049671835
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 08s <> <> <>
Finished Training: /tmp/iteration_id_0.4678788971611575
Training time: 8.59

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 1.42844
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.4678788971611575/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.4678788971611575/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.39848 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.4678788971611575
Testing time: 0.05
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.49480888773408144
device                   -->   cuda:0
dropout                  -->   0.781814829573357
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.63934999083604
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.18256474463041944
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   137
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6310854451109799
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769119770953273
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.906831068389751
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   767
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.1698508239573051
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7402017008461064
sparsity_ratio           -->   0.13919660957497942
task_type                -->   classification
update_adj_ratio         -->   0.23303795446995523
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8827916778540279
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 09s <> <> <>
Finished Training: /tmp/iteration_id_0.1698508239573051
Training time: 9.65

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 1.31361
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.1698508239573051/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.1698508239573051/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.26611 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.1698508239573051
Testing time: 0.07
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.49507144653428514
device                   -->   cuda:0
dropout                  -->   0.767720032113968
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6389767152881067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.1819287757273123
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   135
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6350004564917201
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769125485732944
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9586051662949321
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   775
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6557509382883518
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7391205594735943
sparsity_ratio           -->   0.191446799257833
task_type                -->   classification
update_adj_ratio         -->   0.23191259567351694
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9016830352973939
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 09s <> <> <>
Finished Training: /tmp/iteration_id_0.6557509382883518
Training time: 9.11

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 1.00325
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6557509382883518/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6557509382883518/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.96441 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6557509382883518
Testing time: 0.05
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.49529353563542466
device                   -->   cuda:0
dropout                  -->   0.7633207852343893
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.630389278022564
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.1823184881414065
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   135
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6335760888810634
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769125446900501
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9581593411195649
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   780
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5807384578682473
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7351996693310081
sparsity_ratio           -->   0.1890483344683295
task_type                -->   classification
update_adj_ratio         -->   0.2327604311305352
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9005579681540389
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 08s <> <> <>
Finished Training: /tmp/iteration_id_0.5807384578682473
Training time: 8.62

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 7; 
NLOSS = 1.04902
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5807384578682473/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5807384578682473/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.01024 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5807384578682473
Testing time: 0.05
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.4903016670547311
device                   -->   cuda:0
dropout                  -->   0.7618656105548558
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6231552376615153
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.1860005949818334
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   133
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.640770393043473
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769086066675573
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9569557770734632
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   760
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5004930817002154
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7275741267025055
sparsity_ratio           -->   0.1875406499847048
task_type                -->   classification
update_adj_ratio         -->   0.23534113258527165
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9022931410307405
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 09s <> <> <>
Finished Training: /tmp/iteration_id_0.5004930817002154
Training time: 9.01

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 31; 
NLOSS = 0.95879
ACC = 0.15000

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5004930817002154/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5004930817002154/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.87073 | ACC = 0.13500
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5004930817002154
Testing time: 0.04
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.49055110318375034
device                   -->   cuda:0
dropout                  -->   0.756971526611569
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6127799558046685
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.1864798658209751
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   133
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6394974528457364
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.769084334290275
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.9563395726857419
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   764
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5624605256400204
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7229005159002464
sparsity_ratio           -->   0.18664953297847062
task_type                -->   classification
update_adj_ratio         -->   0.23413753598101245
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.9014054929833742
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 10s <> <> <>
Finished Training: /tmp/iteration_id_0.5624605256400204
Training time: 10.06

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 31; 
NLOSS = 0.95626
ACC = 0.15400

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5624605256400204/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5624605256400204/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 0.87262 | ACC = 0.13100
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5624605256400204
Testing time: 0.08
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9424600614404053
device                   -->   cuda:0
dropout                  -->   0.6796034967999066
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159811381288067
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6081742629823185
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.02573136084725447
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5297647644128811
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883124652624831
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5580
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.12460637655206264
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41288566197242343
sparsity_ratio           -->   0.10329691142599934
task_type                -->   classification
update_adj_ratio         -->   0.3732952239038237
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6412123271254011
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 30])
encoder.graph_encoders.1.weight: torch.Size([30, 7])
graph_learner.weight_tensor: torch.Size([15, 1433])
graph_learner2.weight_tensor: torch.Size([15, 30])
#Parameters = 65145

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 45s <> <> <>
Finished Training: /tmp/iteration_id_0.12460637655206264
Training time: 45.17

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 96; 
NLOSS = 9.14045
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.12460637655206264/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 15 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.12460637655206264/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.14046 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.12460637655206264
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5085616782221998
device                   -->   cuda:0
dropout                  -->   0.8486337426143193
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.7317326689544593
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.17862149482258327
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   143
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6203088578997108
graph_type               -->   dynamic
hidden_size              -->   157
learning_rate            -->   8.76911605109746
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.8657976098872249
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   798
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8975172934416893
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7915502023768504
sparsity_ratio           -->   0.13134063457889905
task_type                -->   classification
update_adj_ratio         -->   0.3035318312695333
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8822336560045811
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 157])
encoder.graph_encoders.1.weight: torch.Size([157, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 157])
#Parameters = 227670

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 28s <> <> <>
Finished Training: /tmp/iteration_id_0.8975172934416893
Training time: 28.98

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 70; 
NLOSS = 2.11027
ACC = 0.12800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.8975172934416893/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.8975172934416893/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 2.09218 | ACC = 0.13200
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.8975172934416893
Testing time: 0.05
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5039645127261336
device                   -->   cuda:0
dropout                  -->   0.8187856678111514
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6636268941650103
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.17767496916487685
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   139
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6336334113923852
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.7691224615415
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.907795751227836
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   755
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.11516930759038735
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7528743685216521
sparsity_ratio           -->   0.1369404826239825
task_type                -->   classification
update_adj_ratio         -->   0.22847181452748683
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8842981049671835
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 24s <> <> <>
Finished Training: /tmp/iteration_id_0.11516930759038735
Training time: 24.85

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 78; 
NLOSS = 1.86727
ACC = 0.14000

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.11516930759038735/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.11516930759038735/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.83200 | ACC = 0.12900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.11516930759038735
Testing time: 0.04
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5039645127261336
device                   -->   cuda:0
dropout                  -->   0.8187856678111514
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.6636268941650103
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.17767496916487685
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   139
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.6336334113923852
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   8.7691224615415
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.907795751227836
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   755
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.08171372456808346
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.7528743685216521
sparsity_ratio           -->   0.1369404826239825
task_type                -->   classification
update_adj_ratio         -->   0.22847181452748683
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8842981049671835
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 41s <> <> <>
Finished Training: /tmp/iteration_id_0.08171372456808346
Training time: 41.53

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 78; 
NLOSS = 1.86727
ACC = 0.14000

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.08171372456808346/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.08171372456808346/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.86700 | ACC = 0.12800
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.08171372456808346
Testing time: 0.04
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.3839065597885686
device                   -->   cuda:0
dropout                  -->   0.6071889438752374
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5023167230253764
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.40638405864410687
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   100
graph_learn_num_pers     -->   16
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.46667632389218766
graph_type               -->   dynamic
hidden_size              -->   105
learning_rate            -->   5.158043584951459
logging                  -->   True
lr_patience              -->   3
lr_reduce_factor         -->   0.8519044906153679
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8902
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.0019618084237708056
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.5483762509067007
sparsity_ratio           -->   0.06560701280449971
task_type                -->   classification
update_adj_ratio         -->   0.3772604624919025
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.4665243988034743
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 105])
encoder.graph_encoders.1.weight: torch.Size([105, 7])
graph_learner.weight_tensor: torch.Size([16, 1433])
graph_learner2.weight_tensor: torch.Size([16, 105])
#Parameters = 175808

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 16s <> <> <>
Finished Training: /tmp/iteration_id_0.0019618084237708056
Training time: 16.92

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 30; 
NLOSS = 1.23213
ACC = 0.16200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.0019618084237708056/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.0019618084237708056/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.22498 | ACC = 0.14900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.0019618084237708056
Testing time: 0.14
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5987036989556576
device                   -->   cuda:0
dropout                  -->   0.5454282945032471
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.473468923930976
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.8788670773602514
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   63
graph_learn_num_pers     -->   19
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.21873255114784504
graph_type               -->   dynamic
hidden_size              -->   117
learning_rate            -->   0.004630093338903324
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.8458543515865983
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1958
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.08287912175175205
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.48696951644300684
sparsity_ratio           -->   0.10936555869631769
task_type                -->   classification
update_adj_ratio         -->   0.468844335289795
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.41566064847404627
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 19 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 19 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 117])
encoder.graph_encoders.1.weight: torch.Size([117, 7])
graph_learner.weight_tensor: torch.Size([19, 1433])
graph_learner2.weight_tensor: torch.Size([19, 117])
#Parameters = 197930

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 14s <> <> <>
Finished Training: /tmp/iteration_id_0.08287912175175205
Training time: 14.41

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 32; 
NLOSS = 4.20704
ACC = 0.07200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.08287912175175205/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 19 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 19 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.08287912175175205/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 4.19457 | ACC = 0.09100
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.08287912175175205
Testing time: 0.09
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.7974498089072458
device                   -->   cuda:0
dropout                  -->   0.8722715671585447
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5778702159757828
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.5707681146025085
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   63
graph_learn_num_pers     -->   9
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.4426939003159565
graph_type               -->   dynamic
hidden_size              -->   12
learning_rate            -->   2.0405435859900485
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.8681937383146302
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   3633
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.547599814923197
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.6581887674537278
sparsity_ratio           -->   0.14857811486385736
task_type                -->   classification
update_adj_ratio         -->   0.20817652357474192
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8749074012775563
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 12])
encoder.graph_encoders.1.weight: torch.Size([12, 7])
graph_learner.weight_tensor: torch.Size([9, 1433])
graph_learner2.weight_tensor: torch.Size([9, 12])
#Parameters = 30285

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 14s <> <> <>
Finished Training: /tmp/iteration_id_0.547599814923197
Training time: 14.86

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 24; 
NLOSS = 6.81112
ACC = 0.31600

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.547599814923197/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 9 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.547599814923197/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 6.81225 | ACC = 0.31900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.547599814923197
Testing time: 0.1
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9829863888906659
device                   -->   cuda:0
dropout                  -->   0.6803258004714172
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.4242155967067617
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7956392661752878
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   16
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.9382287739375065
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   6.480876359661405
logging                  -->   True
lr_patience              -->   3
lr_reduce_factor         -->   0.8171503468865565
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1870
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5443497961642241
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.2526760887552686
sparsity_ratio           -->   0.12083810041731169
task_type                -->   classification
update_adj_ratio         -->   0.48046739372037944
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.7050816560612774
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 09s <> <> <>
Finished Training: /tmp/iteration_id_0.5443497961642241
Training time: 9.98

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 30; 
NLOSS = 9.26258
ACC = 0.05800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5443497961642241/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5443497961642241/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.23506 | ACC = 0.06400
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5443497961642241
Testing time: 0.08
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9683976877624141
device                   -->   cuda:0
dropout                  -->   0.7584385210302566
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5328127288636719
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6793760388324406
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   29
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.9620603175204212
graph_type               -->   dynamic
hidden_size              -->   171
learning_rate            -->   7.244849643676094
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.8618573647048386
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1148
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5957592053254204
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.3909395984871619
sparsity_ratio           -->   0.19908398290686002
task_type                -->   classification
update_adj_ratio         -->   0.35881806453491083
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8297463242220109
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 171])
encoder.graph_encoders.1.weight: torch.Size([171, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 171])
#Parameters = 247844

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 09s <> <> <>
Finished Training: /tmp/iteration_id_0.5957592053254204
Training time: 9.13

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 30; 
NLOSS = 8.46332
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5957592053254204/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5957592053254204/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 8.46500 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5957592053254204
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9683733489014776
device                   -->   cuda:0
dropout                  -->   0.7739218110131646
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5411097743806172
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.6794525646136094
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   30
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.9620018342373302
graph_type               -->   dynamic
hidden_size              -->   171
learning_rate            -->   7.244849142796561
logging                  -->   True
lr_patience              -->   4
lr_reduce_factor         -->   0.8221127624536431
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1147
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.7815125364647472
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.39325842526453797
sparsity_ratio           -->   0.1516400941701857
task_type                -->   classification
update_adj_ratio         -->   0.3590488756247734
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.8234032021393138
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 171])
encoder.graph_encoders.1.weight: torch.Size([171, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 171])
#Parameters = 247844

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 09s <> <> <>
Finished Training: /tmp/iteration_id_0.7815125364647472
Training time: 9.06

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 30; 
NLOSS = 8.60859
ACC = 0.11400

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.7815125364647472/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.7815125364647472/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 8.61112 | ACC = 0.11300
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.7815125364647472
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.3967815642538649
device                   -->   cuda:0
dropout                  -->   0.6168490704924976
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.502360882939989
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.40658525457829875
grad_accumulated_steps   -->   6
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   102
graph_learn_num_pers     -->   16
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.4821166085052357
graph_type               -->   dynamic
hidden_size              -->   105
learning_rate            -->   5.12080922437789
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.8427307616976826
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   8895
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.33577122315407437
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.5480877509771842
sparsity_ratio           -->   0.06562657506226632
task_type                -->   classification
update_adj_ratio         -->   0.3783020374154007
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.47641500324484576
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 105])
encoder.graph_encoders.1.weight: torch.Size([105, 7])
graph_learner.weight_tensor: torch.Size([16, 1433])
graph_learner2.weight_tensor: torch.Size([16, 105])
#Parameters = 175808

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 16s <> <> <>
Finished Training: /tmp/iteration_id_0.33577122315407437
Training time: 16.85

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 30; 
NLOSS = 1.41037
ACC = 0.16200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.33577122315407437/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 16 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.33577122315407437/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 1.40429 | ACC = 0.14900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.33577122315407437
Testing time: 0.11
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9833250975732438
device                   -->   cuda:0
dropout                  -->   0.6853684179276828
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.429562764194406
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7956320141873062
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   16
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.9439995349908032
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   6.443914470138463
logging                  -->   True
lr_patience              -->   3
lr_reduce_factor         -->   0.7992090736438869
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1844
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.5652746071694568
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.2534753404458565
sparsity_ratio           -->   0.11960036552766337
task_type                -->   classification
update_adj_ratio         -->   0.5155342286057831
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6782068965064735
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 10s <> <> <>
Finished Training: /tmp/iteration_id_0.5652746071694568
Training time: 10.12

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 30; 
NLOSS = 9.25203
ACC = 0.06200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.5652746071694568/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.5652746071694568/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.22009 | ACC = 0.06800
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.5652746071694568
Testing time: 0.07
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.7705043838639881
device                   -->   cuda:0
dropout                  -->   0.8842947951991931
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5434826282743574
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.598474433028187
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   3
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   36
graph_learn_num_pers     -->   8
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.36042119222603386
graph_type               -->   dynamic
hidden_size              -->   90
learning_rate            -->   2.1418523165831838
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.896232732265782
max_epochs               -->   33.33333333333333
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   3233
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.6316555203689391
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.5258760822940934
sparsity_ratio           -->   0.04657670397801479
task_type                -->   classification
update_adj_ratio         -->   0.3703482486340056
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6202890923518543
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 90])
encoder.graph_encoders.1.weight: torch.Size([90, 90])
encoder.graph_encoders.2.weight: torch.Size([90, 7])
graph_learner.weight_tensor: torch.Size([8, 1433])
graph_learner2.weight_tensor: torch.Size([8, 90])
#Parameters = 149884

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 17s <> <> <>
Finished Training: /tmp/iteration_id_0.6316555203689391
Training time: 17.36

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 30; 
NLOSS = 6.33653
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.6316555203689391/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 8 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.6316555203689391/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 6.32779 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.6316555203689391
Testing time: 0.25
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5987036989556576
device                   -->   cuda:0
dropout                  -->   0.5454282945032471
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.473468923930976
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.8788670773602514
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   63
graph_learn_num_pers     -->   19
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.21873255114784504
graph_type               -->   dynamic
hidden_size              -->   117
learning_rate            -->   0.004630093338903324
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.8458543515865983
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1958
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.2764241308755201
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.48696951644300684
sparsity_ratio           -->   0.10936555869631769
task_type                -->   classification
update_adj_ratio         -->   0.468844335289795
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.41566064847404627
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 19 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 19 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 117])
encoder.graph_encoders.1.weight: torch.Size([117, 7])
graph_learner.weight_tensor: torch.Size([19, 1433])
graph_learner2.weight_tensor: torch.Size([19, 117])
#Parameters = 197930

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 42s <> <> <>
Finished Training: /tmp/iteration_id_0.2764241308755201
Training time: 42.89

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 61; 
NLOSS = 4.21230
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.2764241308755201/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 19 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 19 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.2764241308755201/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 4.21101 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.2764241308755201
Testing time: 0.14
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9829863888906659
device                   -->   cuda:0
dropout                  -->   0.6803258004714172
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.4242155967067617
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7956392661752878
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   16
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.9382287739375065
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   6.480876359661405
logging                  -->   True
lr_patience              -->   3
lr_reduce_factor         -->   0.8171503468865565
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1870
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8242157956626749
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.2526760887552686
sparsity_ratio           -->   0.12083810041731169
task_type                -->   classification
update_adj_ratio         -->   0.48046739372037944
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.7050816560612774
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 27s <> <> <>
Finished Training: /tmp/iteration_id_0.8242157956626749
Training time: 27.77

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 88; 
NLOSS = 9.53349
ACC = 0.16800

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.8242157956626749/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.8242157956626749/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.49266 | ACC = 0.16800
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.8242157956626749
Testing time: 0.06
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9833250975732438
device                   -->   cuda:0
dropout                  -->   0.6853684179276828
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.429562764194406
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.7956320141873062
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   16
graph_learn_num_pers     -->   1
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.9439995349908032
graph_type               -->   dynamic
hidden_size              -->   158
learning_rate            -->   6.443914470138463
logging                  -->   True
lr_patience              -->   3
lr_reduce_factor         -->   0.7992090736438869
max_epochs               -->   100.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1844
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.8500342860463899
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.2534753404458565
sparsity_ratio           -->   0.11960036552766337
task_type                -->   classification
update_adj_ratio         -->   0.5155342286057831
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.6782068965064735
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 158])
encoder.graph_encoders.1.weight: torch.Size([158, 7])
graph_learner.weight_tensor: torch.Size([1, 1433])
graph_learner2.weight_tensor: torch.Size([1, 158])
#Parameters = 229111

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 00m 30s <> <> <>
Finished Training: /tmp/iteration_id_0.8500342860463899
Training time: 30.66

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 80; 
NLOSS = 9.54976
ACC = 0.16200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.8500342860463899/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 1 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.8500342860463899/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 9.50493 | ACC = 0.14900
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.8500342860463899
Testing time: 0.09
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.5987036989556576
device                   -->   cuda:0
dropout                  -->   0.5454282945032471
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.473468923930976
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.8788670773602514
grad_accumulated_steps   -->   4
grad_clipping            -->   None
graph_hops               -->   1
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   63
graph_learn_num_pers     -->   19
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.21873255114784504
graph_type               -->   dynamic
hidden_size              -->   117
learning_rate            -->   0.004630093338903324
logging                  -->   True
lr_patience              -->   2
lr_reduce_factor         -->   0.8458543515865983
max_epochs               -->   300.0
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   1958
num_class                -->   7
num_feat                 -->   1433
optimizer                -->   adam
out_dir                  -->   /tmp/iteration_id_0.9558666609882543
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.48696951644300684
sparsity_ratio           -->   0.10936555869631769
task_type                -->   classification
update_adj_ratio         -->   0.468844335289795
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.41566064847404627
**************** MODEL CONFIGURATION ****************
[ Using CUDA ]
[ Using ground-truth input graph ]
[ Running GraphClf model ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 19 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 19 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
encoder.graph_encoders.0.weight: torch.Size([1433, 117])
encoder.graph_encoders.1.weight: torch.Size([117, 7])
graph_learner.weight_tensor: torch.Size([19, 1433])
graph_learner2.weight_tensor: torch.Size([19, 117])
#Parameters = 197930

<> <> <> Starting Timer [Train] <> <> <>
<> <> <> Finished Timer [Train] <> <> <> Total time elapsed: 0h 01m 09s <> <> <>
Finished Training: /tmp/iteration_id_0.9558666609882543
Training time: 69.67

<<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Best epoch = 61; 
NLOSS = 4.21230
ACC = 0.12200

 <<<<<<<<<<<<<<<< MODEL SUMMARY >>>>>>>>>>>>>>>> 
Restoring best model
[ Loading saved model /tmp/iteration_id_0.9558666609882543/params.saved ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 19 ]
[ Graph Learner metric type: weighted_cosine ]
[ Multi-perspective weighted_cosine AnchorGraphLearner: 19 ]
[ Graph Learner metric type: weighted_cosine ]
[ Graph Learner ]
[ Graph Regularization]
<> <> <> Starting Timer [Test] <> <> <>
Saved raw_learned_adj to /tmp/iteration_id_0.9558666609882543/cora_idgl_node_anchor_adj.npy
[test] | test_exs = 1000 | step: [1 / 1] | NLOSS = 4.21268 | ACC = 0.13000
<> <> <> Finished Timer [Test] <> <> <> Total time elapsed: 0h 00m 00s <> <> <>
Finished Testing: /tmp/iteration_id_0.9558666609882543
Testing time: 0.11
=========================
Best found configuration: {'degree_ratio': 0.9406104344693624, 'dropout': 0.6793098206091812, 'feat_adj_dropout': 0.5159972470373695, 'gl_dropout': 0.608082426557282, 'grad_accumulated_steps': 5, 'graph_hops': 2, 'graph_learn_hidden_size': 70, 'graph_learn_num_pers': 15, 'graph_skip_conn': 0.029522689305987893, 'hidden_size': 30, 'learning_rate': 0.5357645894486907, 'lr_patience': 1, 'lr_reduce_factor': 0.883536432231425, 'num_anchors': 5445, 'smoothness_ratio': 0.41237873540878583, 'sparsity_ratio': 0.10293398861259362, 'update_adj_ratio': 0.38247554305996323, 'weight_decay': 0.5961891791928413}
A total of 128 unique configurations where sampled.
A total of 183 runs where executed.
Total budget corresponds to 37.0 full function evaluations.
=========================NAS Done=========================
NA: {'data_type': 'network', 'dataset_name': 'cora', 'data_dir': '../data/cora/', 'pretrained': None, 'task_type': 'classification', 'out_dir': '../out/cora/idgl_anchor', 'seed': 42, 'model_name': 'GraphClf', 'scalable_run': True, 'num_anchors': 5445, 'hidden_size': 30, 'use_bert': False, 'dropout': 0.6793098206091812, 'feat_adj_dropout': 0.5159972470373695, 'gl_dropout': 0.608082426557282, 'bignn': False, 'graph_module': 'gcn', 'graph_type': 'dynamic', 'graph_learn': True, 'graph_metric_type': 'weighted_cosine', 'graph_skip_conn': 0.029522689305987893, 'update_adj_ratio': 0.38247554305996323, 'graph_include_self': False, 'graph_learn_regularization': True, 'smoothness_ratio': 0.41237873540878583, 'degree_ratio': 0.9406104344693624, 'sparsity_ratio': 0.10293398861259362, 'graph_learn_ratio': 0, 'graph_learn_hidden_size': 70, 'graph_learn_epsilon': 0, 'graph_learn_topk': None, 'graph_learn_num_pers': 15, 'graph_hops': 2, 'gat_nhead': 8, 'gat_alpha': 0.2, 'optimizer': 'adam', 'learning_rate': 0.5357645894486907, 'weight_decay': 0.5961891791928413, 'lr_patience': 1, 'lr_reduce_factor': 0.883536432231425, 'grad_clipping': None, 'grad_accumulated_steps': 5, 'eary_stop_metric': 'nloss', 'pretrain_epoch': 0, 'max_iter': 10, 'eps_adj': 8.5e-05, 'rl_ratio': 0, 'rl_ratio_power': 1, 'rl_start_epoch': 1, 'max_rl_ratio': 0.99, 'rl_reward_metric': 'acc', 'rl_wmd_ratio': 0, 'random_seed': 1234, 'shuffle': True, 'max_epochs': 10000, 'patience': 100, 'verbose': 20, 'print_every_epochs': 500, 'out_predictions': False, 'out_raw_learned_adj_path': 'cora_idgl_node_anchor_adj.npy', 'save_params': True, 'logging': True, 'no_cuda': False, 'cuda_id': 0}
=========================Training Starting=========================
**************** MODEL CONFIGURATION ****************
bignn                    -->   False
cuda_id                  -->   0
data_dir                 -->   ../data/cora/
data_type                -->   network
dataset_name             -->   cora
degree_ratio             -->   0.9406104344693624
dropout                  -->   0.6793098206091812
eary_stop_metric         -->   nloss
eps_adj                  -->   8.5e-05
feat_adj_dropout         -->   0.5159972470373695
gat_alpha                -->   0.2
gat_nhead                -->   8
gl_dropout               -->   0.608082426557282
grad_accumulated_steps   -->   5
grad_clipping            -->   None
graph_hops               -->   2
graph_include_self       -->   False
graph_learn              -->   True
graph_learn_epsilon      -->   0
graph_learn_hidden_size  -->   70
graph_learn_num_pers     -->   15
graph_learn_ratio        -->   0
graph_learn_regularization -->   True
graph_learn_topk         -->   None
graph_metric_type        -->   weighted_cosine
graph_module             -->   gcn
graph_skip_conn          -->   0.029522689305987893
graph_type               -->   dynamic
hidden_size              -->   30
learning_rate            -->   0.5357645894486907
logging                  -->   True
lr_patience              -->   1
lr_reduce_factor         -->   0.883536432231425
max_epochs               -->   10000
max_iter                 -->   10
max_rl_ratio             -->   0.99
model_name               -->   GraphClf
no_cuda                  -->   False
num_anchors              -->   5445
optimizer                -->   adam
out_dir                  -->   ../out/cora/idgl_anchor
out_predictions          -->   False
out_raw_learned_adj_path -->   cora_idgl_node_anchor_adj.npy
patience                 -->   100
pretrain_epoch           -->   0
pretrained               -->   None
print_every_epochs       -->   500
random_seed              -->   1234
rl_ratio                 -->   0
rl_ratio_power           -->   1
rl_reward_metric         -->   acc
rl_start_epoch           -->   1
rl_wmd_ratio             -->   0
save_params              -->   True
scalable_run             -->   True
seed                     -->   42
shuffle                  -->   True
smoothness_ratio         -->   0.41237873540878583
sparsity_ratio           -->   0.10293398861259362
task_type                -->   classification
update_adj_ratio         -->   0.38247554305996323
use_bert                 -->   False
verbose                  -->   20
weight_decay             -->   0.5961891791928413
**************** MODEL CONFIGURATION ****************
